{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle: \"I love your NaN(s)\" - (public score:143.368566, jallasatck1.csv)\n",
    "\n",
    "Rory Fitzgerald, roryf (540995), \n",
    "\n",
    "Henrik Horpedal, henrhorp (564667)\n",
    "\n",
    "Peter Pham, phpham (527659)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 69\n",
    "#np.random.seed(RANDOM_STATE)\n",
    "FOLDER_NAME = \"SHORT_NOTEBOOK2_CSV_FILES\"\n",
    "GLOBAL_VERBOSE = False\n",
    "PREPROCESSORS = [\"quarters\",\"statistical\", \"trimmedMean\"]\n",
    "LETTERS = [\"A\", \"B\", \"C\"]\n",
    "if not os.path.exists(FOLDER_NAME):\n",
    "    os.makedirs(FOLDER_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "# using a class to mimic a namespace:\n",
    "class pre:\n",
    "\n",
    "    def clean_NaN(df):\n",
    "        df = df.copy()\n",
    "        df.dropna(subset=['target'], inplace=True)\n",
    "        return df\n",
    "\n",
    "    def remove_long_sequences(df, col_name, seq_len):\n",
    "        df = df.copy()\n",
    "        # Identify sequences of zeros\n",
    "        df['group'] = (df[col_name] != 0).cumsum()\n",
    "        df['group_count'] = df.groupby('group')[col_name].transform('count')\n",
    "        \n",
    "        # Create a mask to identify rows with sequences longer than seq_len and isshadow lower than 1\n",
    "        mask = (df[col_name] == 0) & (df['group_count'] > seq_len) #& (df['is_in_shadow:idx'] < 1)\n",
    "        \n",
    "        # Remove rows with sequences longer than seq_len and isshadow lower than 1\n",
    "        df_cleaned = df[~mask].drop(columns=['group', 'group_count'])\n",
    "        return df_cleaned.copy()\n",
    "\n",
    "\n",
    "    def remove_repeating_nonzero(df, col_name, repeat_count=5):\n",
    "        df = df.copy()\n",
    "        # create a mask to identify rows with repeating nonzero values in the target column\n",
    "        mask = ((df[col_name] != 0) & (df[col_name].shift(1) == df[col_name]))\n",
    "        # create a mask to identify rows with repeating nonzero values that occur more than repeat_count times\n",
    "        repeat_mask = mask & (mask.groupby((~mask).cumsum()).cumcount() >= repeat_count)\n",
    "        # create a mask to identify the complete sequence of repeating nonzero values\n",
    "        seq_mask = repeat_mask | repeat_mask.shift(-5)\n",
    "        # remove rows with repeating nonzero values that occur more than repeat_count times\n",
    "        df = df[~seq_mask]\n",
    "        return df\n",
    "\n",
    "    def clean(df):\n",
    "        df = df.copy()\n",
    "        df=pre.clean_NaN(df)\n",
    "        df=pre.remove_long_sequences(df, 'target', 60)\n",
    "        df=pre.remove_repeating_nonzero(df, 'target')\n",
    "        return df\n",
    "\n",
    "\n",
    "    def encode(data, col, max_val):\n",
    "        data = data.copy()\n",
    "        data = data.copy()\n",
    "        data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "        data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "        return data\n",
    "\n",
    "    def create_time_features(df):\n",
    "        df = df.copy()\n",
    "        df[\"hour\"]=df.index.hour\n",
    "        df[\"dayofyear\"]=df.index.dayofyear\n",
    "        df[\"month\"]=df.index.month\n",
    "        df[\"week\"] = df.index.isocalendar().week\n",
    "\n",
    "        #zero indexing:\n",
    "        df[\"dayofyear\"]-=1\n",
    "        df[\"month\"]-=1\n",
    "        df[\"week\"]-=1\n",
    "\n",
    "\n",
    "        #Cycling the time features:\n",
    "        df = pre.encode(df, \"hour\", 24)\n",
    "        df = pre.encode(df, \"month\", 12)\n",
    "        df = pre.encode(df, \"week\", 53)\n",
    "        df = pre.encode(df, \"dayofyear\", 366)\n",
    "\n",
    "        df.drop(columns=[\"hour\", \"month\", \"week\", \"dayofyear\"], inplace=True)\n",
    "\n",
    "\n",
    "        df[\"mult1\"]=(1-df[\"is_in_shadow:idx\"])*df['direct_rad:W']\n",
    "        df[\"mult2\"]=(1-df[\"is_in_shadow:idx\"])*df['clear_sky_rad:W']\n",
    "        df[\"date_calc\"]=pd.to_datetime(df[\"date_calc\"])\n",
    "        df.index=pd.to_datetime(df.index)\n",
    "        df[\"uncertainty\"]=(df.index-df[\"date_calc\"]).apply(lambda x: x.total_seconds()/3600)\n",
    "        df[\"uncertainty\"].fillna(0, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def create_features(df):\n",
    "        df = df.copy()\n",
    "\n",
    "        df.dropna(subset=['absolute_humidity_2m:gm3'], inplace=True)\n",
    "        df[\"total_solar_rad\"]=df[\"direct_rad:W\"]+df[\"diffuse_rad:W\"]\n",
    "        #df[\"clear_sky_%\"]=df[\"total_solar_rad\"]/df[\"clear_sky_rad:W\"]*100\n",
    "        #df[\"clear_sky_%\"].fillna(0, inplace=True)\n",
    "        df[\"spec humid\"]=df[\"absolute_humidity_2m:gm3\"]/df[\"air_density_2m:kgm3\"]\n",
    "        df[\"temp*total_rad\"]=df[\"t_1000hPa:K\"]*df[\"total_solar_rad\"]\n",
    "        df[\"wind_angle\"]=(np.arctan2(df[\"wind_speed_u_10m:ms\"],df[\"wind_speed_v_10m:ms\"]))*180/np.pi\n",
    "        #df[\"total_snow_depth\"] = df[\"snow_depth:cm\"] + df[\"fresh_snow_1h:cm\"]\n",
    "        #df[\"total_precip_5min\"] = df[\"precip_5min:mm\"] + df[\"snow_melt_10min:mm\"]\n",
    "        #df[\"total_precip_type\"] = df[\"precip_type_5min:idx\"] + df[\"snow_water:kgm2\"]\n",
    "        df[\"total_pressure\"] = df[\"pressure_50m:hPa\"] + df[\"pressure_100m:hPa\"]\n",
    "        df[\"total_sun_angle\"] = df[\"sun_azimuth:d\"] + df[\"sun_elevation:d\"]\n",
    "        df[\"solar intensity\"]=1361*np.cos(np.radians(90-df[\"sun_elevation:d\"]))\n",
    "        df[\"solar intensity\"].clip(lower=0, inplace=True)\n",
    "        return df\n",
    "\n",
    "    def shift_target(df, target_col):\n",
    "        df = df.copy()\n",
    "        # Ensure the DataFrame is indexed by date\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        # Store the original indices\n",
    "        original_indices = df.index\n",
    "\n",
    "        # Reindex the DataFrame to include all 15-minute intervals\n",
    "        all_intervals = pd.date_range(start=df.index.min(), end=df.index.max(), freq='15T')\n",
    "        df = df.reindex(all_intervals)\n",
    "\n",
    "        # Shift the target variable by 1 period (15 minutes) forward and backward\n",
    "        df[target_col + '_shifted_forward'] = df[target_col].shift(-1)\n",
    "        df[target_col + '_shifted_backward'] = df[target_col].shift(1)\n",
    "\n",
    "        # Forward fill the missing values for the forward shift\n",
    "        df[target_col + '_shifted_forward'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "        # Backward fill the missing values for the backward shift\n",
    "        df[target_col + '_shifted_backward'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "        # Keep only the original indices\n",
    "        df = df.loc[original_indices]\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    def add_lagged_features(df):\n",
    "        df = df.copy()\n",
    "        features_to_lag = [ \"total_solar_rad\", \"temptotal_rad\", \"clear_sky_radW\", \"diffuse_radW\", \"direct_radW\",  \"total_cloud_coverp\", \"solarintensity\", \"total_sun_angle\", \"pressure_100mhPa\"] #these were the most important features, and therefore assumed to be the most important to lag \n",
    "        \n",
    "        for feature in features_to_lag:\n",
    "            df = pre.shift_target(df, feature)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "    #experiments showed that flaml preformed slightly better with fewer features, no lagged features:\n",
    "    def general_read_flaml(letter):\n",
    "        df = pd.read_parquet(f\"{letter}/X_train_observed.parquet\")\n",
    "        df2=pd.read_parquet(f\"{letter}/X_train_estimated.parquet\")\n",
    "        y = pd.read_parquet(f\"{letter}/train_targets.parquet\")\n",
    "        # set the index to date_forecast and group by hourly frequency\n",
    "        df.set_index(\"date_forecast\", inplace=True)\n",
    "        df2.set_index(\"date_forecast\", inplace=True)\n",
    "        y.set_index(\"time\", inplace=True)\n",
    "\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df2.index = pd.to_datetime(df2.index)\n",
    "        y.index = pd.to_datetime(y.index) \n",
    "        \n",
    "        df=pd.concat([df,df2],axis=0)\n",
    "\n",
    "        # truncate y to match the index of df\n",
    "        y = y.truncate(before=df.index[0], after=df.index[-1])\n",
    "        latest_y_time = y.index[-1]\n",
    "        latest_needed_df_time = latest_y_time + pd.Timedelta(minutes=45)\n",
    "        # Truncate y based on df\n",
    "        y = y.truncate(before=df.index[0], after=df.index[-1])\n",
    "        # Ensure df has all needed entries from the start of y to 45 minutes after the end of y\n",
    "        df = df.truncate(before=y.index[0], after=latest_needed_df_time)\n",
    "        y.rename(columns={\"pv_measurement\":\"target\"},inplace=True)\n",
    "        X = df.copy()\n",
    "        Y = y.copy()\n",
    "        #drop nan rows in Y\n",
    "        Y = pre.clean(Y)\n",
    "        X.index = pd.to_datetime(X.index)\n",
    "        Y.index = pd.to_datetime(Y.index)\n",
    "\n",
    "        X_filtered = X[X.index.floor('H').isin(Y.index)]\n",
    "\n",
    "        # Step 2: Ensure there are exactly four 15-min intervals for each hour\n",
    "        valid_indices = X_filtered.groupby(X_filtered.index.floor('H')).filter(lambda group: len(group) == 4).index\n",
    "\n",
    "        # Final filtered X\n",
    "        X_final = X[X.index.isin(valid_indices)]\n",
    "\n",
    "\n",
    "        #Troubleshooting: Find and print the hours with a mismatch\n",
    "        group_sizes = X_filtered.groupby(X_filtered.index.floor('H')).size()\n",
    "        mismatch_hours = group_sizes[group_sizes != 4]\n",
    "\n",
    "        #Additional troubleshooting: find hours in Y without four 15-min intervals in X\n",
    "        missing_hours_in_x = Y.index[~Y.index.isin(X_filtered.index.floor('H'))]\n",
    "\n",
    "\n",
    "        #Remove mismatched and missing hours from Y\n",
    "        all_issues = mismatch_hours.index.union(missing_hours_in_x)\n",
    "        Y_clean = Y[~Y.index.isin(all_issues)]\n",
    "\n",
    "        #dropping nan columns:\n",
    "        X_final = X_final.drop(columns=['cloud_base_agl:m'])\n",
    "        X_final = X_final.drop(columns=['ceiling_height_agl:m'])\n",
    "        X_final = X_final.drop(columns=['snow_density:kgm3'])\n",
    "\n",
    "        X_final = pre.create_features(X_final)\n",
    "        X_final = pre.create_time_features(X_final)\n",
    "        X_final.drop(columns=['date_calc'], inplace=True)\n",
    "\n",
    "        X_final = X_final.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "        Y_clean = Y_clean.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "        #X_final = add_lagged_features(X_final)\n",
    "\n",
    "        # Split X_final into a list of 4-row DataFrames\n",
    "        X_grouped = [group for _, group in X_final.groupby(X_final.index.floor('H')) if len(group) == 4]\n",
    "        \n",
    "        # Ensure we only take the groups of X corresponding to Y_clean\n",
    "        X_list = [X_grouped[i] for i in range(len(Y_clean))]\n",
    "\n",
    "        return X_list, Y_clean\n",
    "\n",
    "\n",
    "    def general_read(letter):\n",
    "\n",
    "        df = pd.read_parquet(f\"{letter}/X_train_observed.parquet\")\n",
    "        df2=pd.read_parquet(f\"{letter}/X_train_estimated.parquet\")\n",
    "        y = pd.read_parquet(f\"{letter}/train_targets.parquet\")\n",
    "        # set the index to date_forecast and group by hourly frequency\n",
    "        df.set_index(\"date_forecast\", inplace=True)\n",
    "        df2.set_index(\"date_forecast\", inplace=True)\n",
    "        y.set_index(\"time\", inplace=True)\n",
    "\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df2.index = pd.to_datetime(df2.index)\n",
    "        y.index = pd.to_datetime(y.index) \n",
    "        \n",
    "        df=pd.concat([df,df2],axis=0)\n",
    "\n",
    "        # truncate y to match the index of df\n",
    "        y = y.truncate(before=df.index[0], after=df.index[-1])\n",
    "        latest_y_time = y.index[-1]\n",
    "        latest_needed_df_time = latest_y_time + pd.Timedelta(minutes=45)\n",
    "        # Truncate y based on df\n",
    "        y = y.truncate(before=df.index[0], after=df.index[-1])\n",
    "        # Ensure df has all needed entries from the start of y to 45 minutes after the end of y\n",
    "        df = df.truncate(before=y.index[0], after=latest_needed_df_time)\n",
    "        y.rename(columns={\"pv_measurement\":\"target\"},inplace=True)\n",
    "        X = df.copy()\n",
    "        Y = y.copy()\n",
    "        #drop nan rows in Y\n",
    "        Y = pre.clean(Y)\n",
    "        X.index = pd.to_datetime(X.index)\n",
    "        Y.index = pd.to_datetime(Y.index)\n",
    "\n",
    "        X_filtered = X[X.index.floor('H').isin(Y.index)]\n",
    "\n",
    "        # Step 2: Ensure there are exactly four 15-min intervals for each hour\n",
    "        valid_indices = X_filtered.groupby(X_filtered.index.floor('H')).filter(lambda group: len(group) == 4).index\n",
    "\n",
    "        # Final filtered X\n",
    "        X_final = X[X.index.isin(valid_indices)]\n",
    "\n",
    "\n",
    "        #Troubleshooting: Find and print the hours with a mismatch\n",
    "        group_sizes = X_filtered.groupby(X_filtered.index.floor('H')).size()\n",
    "        mismatch_hours = group_sizes[group_sizes != 4]\n",
    "\n",
    "        #Additional troubleshooting: find hours in Y without four 15-min intervals in X\n",
    "        missing_hours_in_x = Y.index[~Y.index.isin(X_filtered.index.floor('H'))]\n",
    "\n",
    "\n",
    "        #Remove mismatched and missing hours from Y\n",
    "        all_issues = mismatch_hours.index.union(missing_hours_in_x)\n",
    "        Y_clean = Y[~Y.index.isin(all_issues)]\n",
    "\n",
    "        #dropping nan columns:\n",
    "        X_final = X_final.drop(columns=['cloud_base_agl:m'])\n",
    "        X_final = X_final.drop(columns=['ceiling_height_agl:m'])\n",
    "        X_final = X_final.drop(columns=['snow_density:kgm3'])\n",
    "\n",
    "        X_final = pre.create_features(X_final)\n",
    "        X_final = pre.create_time_features(X_final)\n",
    "        X_final.drop(columns=['date_calc'], inplace=True)\n",
    "\n",
    "        X_final = X_final.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "        Y_clean = Y_clean.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "        X_final = pre.add_lagged_features(X_final)\n",
    "\n",
    "        # Split X_final into a list of 4-row DataFrames\n",
    "        X_grouped = [group for _, group in X_final.groupby(X_final.index.floor('H')) if len(group) == 4]\n",
    "        \n",
    "        # Ensure we only take the groups of X corresponding to Y_clean\n",
    "        X_list = [X_grouped[i] for i in range(len(Y_clean))]\n",
    "\n",
    "        return X_list, Y_clean\n",
    "\n",
    "\n",
    "    #the general read function returns a list of 4-row DataFrames, that was in order to have the same lenght of X and Y, therefore this function was needed.\n",
    "    def concatenate_dfs(df_list):\n",
    "        \"\"\"\n",
    "        Concatenates a list of DataFrames into a single DataFrame.\n",
    "\n",
    "        Args:\n",
    "        df_list (list of pd.DataFrame): List of DataFrame objects to concatenate.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A single DataFrame containing all rows from the input DataFrames in the order they appear in the list.\n",
    "        \"\"\"\n",
    "        return pd.concat(df_list, ignore_index=False)\n",
    "\n",
    "    #preprocessor which could be used in a pipeline:\n",
    "    class QuartersAsColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "        \n",
    "        def transform(self, X, y=None):\n",
    "            # Ensure input is a DataFrame\n",
    "            X = X.copy()\n",
    "            assert isinstance(X, pd.DataFrame)\n",
    "            #make sure index is datetime:\n",
    "            X.index = pd.to_datetime(X.index)\n",
    "\n",
    "            original_index = X.index\n",
    "\n",
    "\n",
    "            X['hour'] = X.index.floor('H')\n",
    "            X['minute'] = X.index.minute\n",
    "\n",
    "            # Melt the DataFrame to long format\n",
    "            df_melted = pd.melt(X, id_vars=['hour', 'minute'], value_vars=X.columns[:-2]).copy()  # excluding 'hour' and 'minute'\n",
    "\n",
    "            # Create a multi-level column name combining variable and minute\n",
    "            df_melted['variable_minute'] = df_melted['variable'] + '_' + df_melted['minute'].astype(str) + 'min'\n",
    "\n",
    "            # Drop the 'variable_minute' column\n",
    "\n",
    "\n",
    "            # Pivot the data to get one row per hour and columns for each variable and minute\n",
    "            X = df_melted.pivot(index='hour', columns='variable_minute', values='value').copy()\n",
    "            #rename index to date_forecast:\n",
    "            X.index.rename(\"date_forecast\", inplace=True)\n",
    "\n",
    "\n",
    "            #drop irrelevant columns:\n",
    "            #hour_sin\thour_cos\tmonth_sin\tmonth_cos\tweek_sin\tweek_cos\tdayofyear_sin\tdayofyear_cos\tmult1\tmult2\tuncertainty\n",
    "\n",
    "\n",
    "            irrelevant_cols = [\"hour_sin\", \"hour_cos\", \"month_sin\", \"month_cos\", \"week_sin\", \"week_cos\", \"dayofyear_sin\", \"dayofyear_cos\", \"uncertainty\"]\n",
    "            variantes = [\"_0min\", \"_15min\", \"_30min\", \"_45min\"]\n",
    "            for variant in variantes:\n",
    "                for col in irrelevant_cols:\n",
    "                    if variant == \"_0min\":\n",
    "                        #remove _0min from column name;\n",
    "                        X.rename(columns={col+variant:col}, inplace=True)\n",
    "                    else:\n",
    "                        X.drop(columns=[col+variant], inplace=True)\n",
    "            \n",
    "\n",
    "            reindex_map = original_index.floor('H').unique()\n",
    "            X = X.reindex(reindex_map)\n",
    "            X.index = reindex_map\n",
    "\n",
    "            #drop hour_\n",
    "\n",
    "            if \"object\" in X.dtypes.unique():\n",
    "                print(\"waring: object in QuarterAsColumnsTransformer\")\n",
    "                print(X.dtypes.unique())\n",
    "                for col in X.columns:\n",
    "                    print(col)\n",
    "\n",
    "            #X = X.select_dtypes(include=[np.number])\n",
    "            return X\n",
    "        \n",
    "    #preprocessor which could be used in a pipeline:\n",
    "    class StatisticalFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "        def fit(self, X, y=None):\n",
    "            return self\n",
    "\n",
    "        def transform(self, X, y=None):\n",
    "            X_copy = X.copy()\n",
    "            X_copy.index = pd.to_datetime(X_copy.index)\n",
    "            X_copy['hour'] = X_copy.index.floor('H')\n",
    "            \n",
    "            # Compute mean, std\n",
    "            aggregated = X_copy.groupby('hour').agg(['mean', 'std'])\n",
    "            \n",
    "            # Filter hours with exactly 4 data points\n",
    "            valid_hours = X_copy.groupby('hour').size()\n",
    "            valid_hours = valid_hours[valid_hours == 4].index\n",
    "            \n",
    "            X_final = aggregated.loc[valid_hours]\n",
    "            \n",
    "            # Flatten the multi-index to form new column names\n",
    "            X_final.columns = ['_'.join(col).strip() for col in X_final.columns.values]\n",
    "            # for col in X_final.columns:\n",
    "            #     print(col)\n",
    "            #drop minute_mean and minute_std if they exist:\n",
    "            if \"minute_mean\" in X_final.columns:\n",
    "                X_final.drop(columns=[\"minute_mean\", \"minute_std\"], inplace=True)\n",
    "            \n",
    "            X_final = X_final.select_dtypes(include=[np.number])\n",
    "            # print(X_final.dtypes.unique())\n",
    "            # for col in X_final.columns:\n",
    "            #     print(col)\n",
    "\n",
    "\n",
    "            return X_final\n",
    "        \n",
    "    \n",
    "\n",
    "    class HourMonthTargetEncoder(BaseEstimator, TransformerMixin):\n",
    "        def __init__(self):\n",
    "            self.encoding_map = {}\n",
    "            self.y_ = None  # To store y during fit\n",
    "\n",
    "        def fit(self, X, y=None):\n",
    "            # Ensure X's index is a datetime index\n",
    "            if not isinstance(X.index, pd.DatetimeIndex):\n",
    "                raise ValueError(\"Index of input X must be a pandas DatetimeIndex\")\n",
    "\n",
    "            if y is None:\n",
    "                raise ValueError(\"y cannot be None for fitting the encoder\")\n",
    "\n",
    "            # Store the target values for encoding later\n",
    "            self.y_ = y\n",
    "\n",
    "            try:\n",
    "                # Extract hour and month from the index and use y provided during fit\n",
    "                df = pd.DataFrame({'target': self.y_, 'hour': X.index.hour, 'month': X.index.month})\n",
    "            except Exception as e:\n",
    "                raise e\n",
    "\n",
    "            # Compute mean target value for each hour of each month\n",
    "            self.encoding_map = df.groupby(['month', 'hour'])['target'].mean().to_dict()\n",
    "            return self\n",
    "\n",
    "        def transform(self, X):\n",
    "            # Ensure X's index is a datetime index\n",
    "            if not isinstance(X.index, pd.DatetimeIndex):\n",
    "                raise ValueError(\"Index of input X must be a pandas DatetimeIndex\")\n",
    "\n",
    "            if self.y_ is None:\n",
    "                raise ValueError(\"The encoder has not been fitted with target values\")\n",
    "\n",
    "            # Extract hour and month from the index\n",
    "            X_transformed = X.copy()\n",
    "            X_transformed['hour'] = X.index.hour\n",
    "            X_transformed['month'] = X.index.month\n",
    "\n",
    "            # Map the mean target values\n",
    "            X_transformed['target_encoded'] = X_transformed.apply(\n",
    "                lambda row: self.encoding_map.get((row['month'], row['hour']), np.nan), axis=1)\n",
    "\n",
    "            # Optionally drop 'hour' and 'month' if they're not needed\n",
    "            X_transformed.drop(['hour', 'month'], axis=1, inplace=True)\n",
    "\n",
    "            # Check for object dtypes and print warning if any\n",
    "            if \"object\" in X_transformed.dtypes.values:\n",
    "                print(\"Warning: object dtype in HourMonthTargetEncoder\")\n",
    "                print(X_transformed.dtypes)\n",
    "\n",
    "            # Ensure that only numeric types are returned\n",
    "            X_transformed = X_transformed.select_dtypes(include=[np.number])\n",
    "\n",
    "            return X_transformed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def apply_preprocessor(data, preprocessor_name):\n",
    "        data = data.copy()\n",
    "        # Assuming `pre.choose_transformer` returns a callable object that can be used to transform the data\n",
    "        preprocessor = pre.choose_transformer(preprocessor_name)\n",
    "        return preprocessor.transform(data)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    def train_test_split_may_june_july(X, y,letter):\n",
    "        \"\"\"\n",
    "        Splits the data based on a given date. Additionally, moves May, June and July data of split_date's year\n",
    "        from training set to test set.\n",
    "        \n",
    "        Parameters:\n",
    "        - X: Quarter-hourly input data with DateTime index.\n",
    "        - y: Hourly target data with DateTime index.\n",
    "        - split_date: Date (string or datetime object) to split the data on.\n",
    "        \n",
    "        Returns:\n",
    "        X_train, y_train, X_test, y_test\n",
    "        \"\"\"\n",
    "\n",
    "        if letter == \"A\":\n",
    "            year = 2022\n",
    "        elif letter == \"B\":\n",
    "            year = 2019\n",
    "        elif letter == \"C\":\n",
    "            year = 2020\n",
    "        \n",
    "        # Define conditions to move May and June of split_date's year from train to test\n",
    "        may_june_july_condition_X = ((X.index.month == 5) | (X.index.month == 6) | (X.index.month == 7)) & ((X.index.year == year))\n",
    "        may_june_july_condition_y = ((y.index.month == 5) | (y.index.month == 6) | (y.index.month == 7)) & ((y.index.year == year))\n",
    "        \n",
    "        X_may_june_july = X[may_june_july_condition_X]\n",
    "        y_may_june_july = y[may_june_july_condition_y]\n",
    "\n",
    "        # Remove May and June data from training set\n",
    "        X_train = X[~may_june_july_condition_X]\n",
    "        y_train = y[~may_june_july_condition_y]\n",
    "\n",
    "        return X_train, y_train, X_may_june_july, y_may_june_july\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def new_train_test_split(X, y,letter, split_date):\n",
    "        \"\"\"\n",
    "        Splits the data based on a given date. Additionally, moves May, June and July data of split_date's year\n",
    "        from training set to test set.\n",
    "        \n",
    "        Parameters:\n",
    "        - X: Quarter-hourly input data with DateTime index.\n",
    "        - y: Hourly target data with DateTime index.\n",
    "        - split_date: Date (string or datetime object) to split the data on.\n",
    "        \n",
    "        Returns:\n",
    "        X_train, y_train, X_test, y_test\n",
    "        \"\"\"\n",
    "        split_date = pd.Timestamp(split_date).normalize()\n",
    "        print(f\"Split date: {split_date}\")\n",
    "\n",
    "        if isinstance(split_date, str):\n",
    "            split_date = pd.Timestamp(split_date)\n",
    "        if letter == \"A\":\n",
    "            year = 2022\n",
    "        elif letter == \"B\":\n",
    "            year = 2019\n",
    "        elif letter == \"C\":\n",
    "            year = 2020\n",
    "\n",
    "        X_train = X[X.index.normalize() < split_date]\n",
    "        y_train = y[y.index.normalize() < split_date]\n",
    "\n",
    "        X_test = X[X.index.normalize() >= split_date]\n",
    "        y_test = y[y.index.normalize() >= split_date]\n",
    "        \n",
    "        # Define conditions to move May and June of split_date's year from train to test\n",
    "        may_june_july_condition_X = ((X.index.month == 5) | (X.index.month == 6) | (X.index.month == 7)) & ((X.index.year == year))\n",
    "        may_june_july_condition_y = ((y.index.month == 5) | (y.index.month == 6) | (y.index.month == 7)) & ((y.index.year == year))\n",
    "        \n",
    "        X_may_june_july = X[may_june_july_condition_X]\n",
    "        y_may_june_july = y[may_june_july_condition_y]\n",
    "\n",
    "        # Remove May and June data from training set\n",
    "        X_train = X[~may_june_july_condition_X]\n",
    "        y_train = y[~may_june_july_condition_y]\n",
    "\n",
    "        # Append May and June data to test set\n",
    "        X_test = pd.concat([X_may_june_july, X_test])\n",
    "        y_test = pd.concat([y_may_june_july, y_test])\n",
    "\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "    def choose_scaler(scaler_string):\n",
    "        if scaler_string == \"minmax\":\n",
    "            return MinMaxScaler()\n",
    "        elif scaler_string == \"standard\":\n",
    "            return StandardScaler()\n",
    "        elif scaler_string == \"robust\":\n",
    "            return RobustScaler()\n",
    "\n",
    "    def choose_transformer(transformer_string):\n",
    "        if transformer_string == \"quarters\":\n",
    "            return pre.QuartersAsColumnsTransformer()\n",
    "        elif transformer_string == \"statistical\":\n",
    "            return pre.StatisticalFeaturesTransformer()\n",
    "        elif transformer_string == \"trimmedMean\":\n",
    "            return pre.TrimmedMeanTransformer()\n",
    "\n",
    "    def choose_encoder(encoder_boolian):\n",
    "        if encoder_boolian == True:\n",
    "            return pre.HourMonthTargetEncoder()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def generate_predefined_split(X_train, X_val, y_train, y_val):\n",
    "        \"\"\"\n",
    "        This function takes in separate training and validation datasets, combines them,\n",
    "        and creates a PredefinedSplit object that can be used with sklearn's GridSearchCV\n",
    "        or other model selection utilities. This allows for specifying which samples are\n",
    "        used for training and which are used for validation.\n",
    "\n",
    "        Parameters:\n",
    "        X_train (array-like): Training features.\n",
    "        X_val (array-like): Validation features.\n",
    "        y_train (array-like): Training labels.\n",
    "        y_val (array-like): Validation labels.\n",
    "\n",
    "        Returns:\n",
    "        X (array-like): The combined dataset of features.\n",
    "        y (array-like): The combined dataset of labels.\n",
    "        split_index (PredefinedSplit): An instance of PredefinedSplit with the indices set.\n",
    "        \"\"\"\n",
    "\n",
    "        # Combine the training and validation sets\n",
    "        X = np.concatenate((X_train, X_val), axis=0)\n",
    "        y = np.concatenate((y_train, y_val), axis=0)\n",
    "\n",
    "        # Generate the indices array where -1 indicates the sample is part of the training set,\n",
    "        # and 0 indicates the sample is part of the validation set.\n",
    "        train_indices = -1 * np.ones(len(X_train))\n",
    "        val_indices = 0 * np.ones(len(X_val))\n",
    "        test_fold = np.concatenate((train_indices, val_indices))\n",
    "\n",
    "        # Create the PredefinedSplit object\n",
    "        predefined_split = PredefinedSplit(test_fold)\n",
    "\n",
    "        return X, y, predefined_split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ensPre:\n",
    "    def preptest(df,features_list,stats_dict):\n",
    "        df.drop(columns=[\"ceiling_height_agl:m\",\"snow_density:kgm3\",\"cloud_base_agl:m\"],inplace=True)\n",
    "        df=ensPre.create_features(df)\n",
    "        #df=unleash_hell(df)\n",
    "        df=ensPre.create_time_features(df)\n",
    "        #df=df[features_list[:-1]]\n",
    "        df=ensPre.cyclical_features(df)\n",
    "        df=ensPre.add_stats_features(df, stats_dict)\n",
    "        df=ensPre.shift_target(df,\"total_solar_rad\")\n",
    "        df.dropna(inplace=True)\n",
    "        df.columns = [\"\".join(c if c.isalnum() or c == '_' else '_' for c in str(x)) for x in df.columns]\n",
    "\n",
    "        return df\n",
    "    def readDataSet(letter):\n",
    "        # read X_train_observed.parquet file for the current letter\n",
    "        df = pd.read_parquet(f\"{letter}/X_train_observed.parquet\")\n",
    "        \n",
    "        df2=pd.read_parquet(f\"{letter}/X_train_estimated.parquet\")\n",
    "        \n",
    "        # set the index to date_forecast and group by hourly frequency\n",
    "        df.set_index(\"date_forecast\", inplace=True)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df = df.groupby(df.index.date).resample('H').max().reset_index(level=0, drop=True)\n",
    "        df2.set_index(\"date_forecast\", inplace=True)\n",
    "        df2.index = pd.to_datetime(df2.index)\n",
    "        df2 = df2.groupby(df2.index.date).resample('H').max().reset_index(level=0, drop=True)\n",
    "        y = pd.read_parquet(f\"{letter}/train_targets.parquet\")\n",
    "        y.set_index(\"time\", inplace=True)\n",
    "        y.index = pd.to_datetime(y.index)\n",
    "\n",
    "        df=pd.concat([df,df2],axis=0)\n",
    "\n",
    "        df = df.truncate(before=y.index[0], after=y.index[-1])\n",
    "        y=y.truncate(before=df.index[0], after=df.index[-1])\n",
    "        df=pd.concat([df,y],axis=1)\n",
    "        df.rename(columns={\"pv_measurement\":\"target\"},inplace=True)\n",
    "\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def readtest(letter):\n",
    "        df = pd.read_parquet(f\"{letter}/X_test_estimated.parquet\")\n",
    "        df.set_index(\"date_forecast\", inplace=True)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df = df.groupby(df.index.date).resample('H').max().reset_index(level=0, drop=True)\n",
    "        return df\n",
    "    def cleanNaN(df):\n",
    "        df.dropna(subset=['target'], inplace=True)\n",
    "        return df\n",
    "    # define a function to remove rows with sequences longer than 50 zeros\n",
    "    #remove NaN first to avoid NaN 0 sequence not being removed\n",
    "    def remove_long_sequences(df, col_name, seq_len):\n",
    "        # Identify sequences of zeros\n",
    "        df['group'] = (df[col_name] != 0).cumsum()\n",
    "        df['group_count'] = df.groupby('group')[col_name].transform('count')\n",
    "        \n",
    "        # Create a mask to identify rows with sequences longer than seq_len and isshadow lower than 1\n",
    "        mask = (df[col_name] == 0) & (df['group_count'] > seq_len) & (df['is_in_shadow:idx'] < 1)\n",
    "        \n",
    "        # Remove rows with sequences longer than seq_len and isshadow lower than 1\n",
    "        df_cleaned = df[~mask].drop(columns=['group', 'group_count'])\n",
    "        return df_cleaned.copy()\n",
    "    \n",
    "    def remove_repeating_nonzero(df, col_name, repeat_count=5):\n",
    "        # create a mask to identify rows with repeating nonzero values in the target column\n",
    "        mask = ((df[col_name] != 0) & (df[col_name].shift(1) == df[col_name]))\n",
    "        # create a mask to identify rows with repeating nonzero values that occur more than repeat_count times\n",
    "        repeat_mask = mask & (mask.groupby((~mask).cumsum()).cumcount() >= repeat_count)\n",
    "        # create a mask to identify the complete sequence of repeating nonzero values\n",
    "        seq_mask = repeat_mask | repeat_mask.shift(-5)\n",
    "        # remove rows with repeating nonzero values that occur more than repeat_count times\n",
    "        df = df[~seq_mask]\n",
    "        return df\n",
    "    def clean(df):\n",
    "        df=ensPre.cleanNaN(df)\n",
    "        df=ensPre.remove_long_sequences(df, 'target', 30)\n",
    "        df=ensPre.remove_repeating_nonzero(df, 'target')\n",
    "        #df=remove_outliers_hourly_and_month(df, 'target')\n",
    "        return df\n",
    "    def remove_outliers_hourly_and_month(df, target_col):\n",
    "        for month in range (1,13):\n",
    "            df_month = df[df.index.month == month]\n",
    "            for i in range(24):\n",
    "                df_hour=df_month[df_month.index.hour == i]\n",
    "                Q1 = df_hour[target_col].quantile(0.25)\n",
    "                Q3 = df_hour[target_col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                df_hour_rem = df_hour[(df_hour[target_col] >= lower_bound) & (df_hour[target_col] <= upper_bound)]\n",
    "                if i==0:\n",
    "                    df_rem=df_hour_rem\n",
    "                else:\n",
    "                    df_rem=pd.concat([df_rem,df_hour_rem],axis=0)\n",
    "            if month==1:\n",
    "                df_rem_month=df_rem\n",
    "            else:\n",
    "                df_rem_month=pd.concat([df_rem_month,df_rem],axis=0)\n",
    "        df_rem_month.sort_index(inplace=True)\n",
    "        return df_rem_month\n",
    "    def calculate_hourly_monthly_means(df):\n",
    "        # Ensure the DataFrame is indexed by date\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        # Create new columns for the hour and the month\n",
    "        df['hour'] = df.index.hour\n",
    "        df['month'] = df.index.month\n",
    "\n",
    "        # Calculate the mean of the target variable for each hour during each month\n",
    "        stats = df.groupby(['month', 'hour'])['target'].agg(['mean', 'std'])\n",
    "\n",
    "        # Convert the DataFrame to a dictionary of dictionaries\n",
    "        stats_dict = stats.to_dict('index')\n",
    "\n",
    "        return stats_dict\n",
    "\n",
    "    def add_stats_features(df, stats_dict):\n",
    "        df[\"month\"]=df.index.month\n",
    "        df[\"hour\"]=df.index.hour\n",
    "        df['mean'] = df.apply(lambda row: stats_dict[(row['month'], row['hour'])]['mean'], axis=1)\n",
    "        df['std'] = df.apply(lambda row: stats_dict[(row['month'], row['hour'])]['std'], axis=1)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def cyclical_features(df):\n",
    "        df[\"hour_sin\"] = np.sin(df.index.hour*(2.*np.pi/24))\n",
    "        df[\"hour_cos\"] = np.cos(df.index.hour*(2.*np.pi/24))\n",
    "        df[\"dayofyear_sin\"] = np.sin(df.index.dayofyear*(2.*np.pi/365))\n",
    "        df[\"dayofyear_cos\"] = np.cos(df.index.dayofyear*(2.*np.pi/365))\n",
    "        return df.copy()\n",
    "        \n",
    "\n",
    "\n",
    "    def create_time_features(df):\n",
    "        df[\"hour\"]=df.index.hour\n",
    "        #df[\"week\"]=df.index.isocalendar().week\n",
    "        df[\"dayofyear\"]=df.index.dayofyear\n",
    "        df[\"month\"]=df.index.month\n",
    "        df[\"mult1\"]=(1-df[\"is_in_shadow:idx\"])*df['direct_rad:W']\n",
    "        df[\"mult2\"]=(1-df[\"is_in_shadow:idx\"])*df['clear_sky_rad:W']\n",
    "        df[\"date_calc\"]=pd.to_datetime(df[\"date_calc\"])\n",
    "        df.index=pd.to_datetime(df.index)\n",
    "        df[\"uncertainty\"]=(df.index-df[\"date_calc\"]).apply(lambda x: x.total_seconds()/3600)\n",
    "        df[\"uncertainty\"].fillna(0, inplace=True)\n",
    "        df.drop(columns=[\"date_calc\"],inplace=True)\n",
    "        return df.copy()\n",
    "\n",
    "    def trim(df,features_list):\n",
    "        df.drop(columns=[\"ceiling_height_agl:m\",\"snow_density:kgm3\",\"cloud_base_agl:m\"],inplace=True)\n",
    "        df=ensPre.clean(df)\n",
    "        df=ensPre.create_features(df)\n",
    "        #df=unleash_hell(df)\n",
    "        df=ensPre.create_time_features(df)\n",
    "        #df=df[features_list]\n",
    "        df=ensPre.cyclical_features(df)\n",
    "        stats_dict=ensPre.calculate_hourly_monthly_means(df)\n",
    "        df=ensPre.add_stats_features(df, stats_dict)\n",
    "        df=ensPre.shift_target(df,\"total_solar_rad\")\n",
    "\n",
    "        df.dropna(inplace=True)\n",
    "        #df = df[~df.index.month.isin([1, 2, 11, 12])]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def create_features(df):\n",
    "\n",
    "        df.dropna(subset=['absolute_humidity_2m:gm3'], inplace=True)\n",
    "\n",
    "        df[\"total_solar_rad\"]=df[\"direct_rad:W\"]+df[\"diffuse_rad:W\"]\n",
    "\n",
    "        #df[\"clear_sky_%\"]=df[\"total_solar_rad\"]/df[\"clear_sky_rad:W\"]*100\n",
    "        #df[\"clear_sky_%\"].fillna(0, inplace=True)\n",
    "        df[\"spec humid\"]=df[\"absolute_humidity_2m:gm3\"]/df[\"air_density_2m:kgm3\"]\n",
    "        df[\"temp*total_rad\"]=df[\"t_1000hPa:K\"]*df[\"total_solar_rad\"]\n",
    "        df[\"wind_angle\"]=(np.arctan2(df[\"wind_speed_u_10m:ms\"],df[\"wind_speed_v_10m:ms\"]))*180/np.pi\n",
    "        #df[\"total_snow_depth\"] = df[\"snow_depth:cm\"] + df[\"fresh_snow_1h:cm\"]\n",
    "        #df[\"total_precip_5min\"] = df[\"precip_5min:mm\"] + df[\"snow_melt_10min:mm\"]\n",
    "        #df[\"total_precip_type\"] = df[\"precip_type_5min:idx\"] + df[\"snow_water:kgm2\"]\n",
    "        df[\"total_pressure\"] = df[\"pressure_50m:hPa\"] + df[\"pressure_100m:hPa\"]\n",
    "        df[\"total_sun_angle\"] = df[\"sun_azimuth:d\"] + df[\"sun_elevation:d\"]\n",
    "        df[\"solar intensity\"]=1361*np.cos(np.radians(90-df[\"sun_elevation:d\"]))\n",
    "        df[\"solar intensity\"].clip(lower=0, inplace=True)\n",
    "        df[\"cloud\"]=df[\"clear_sky_rad:W\"]-df[\"total_solar_rad\"]\n",
    "        df[\"cloud2\"]=df[\"clear_sky_rad:W\"]*(1-df[\"effective_cloud_cover:p\"])\n",
    "        df['temp*total_rad_squared'] = df['temp*total_rad']**2\n",
    "        df['total_solar_rad_squared']=df['total_solar_rad']**2\n",
    "        df['t_1000hPa:K_daystd']=df['t_1000hPa:K'].groupby(df.index.date).transform('std')\n",
    "        df['wind_angle_squared']=df['wind_angle']**2\n",
    "\n",
    "        return df.copy()\n",
    "\n",
    "    def unleash_hell(df):\n",
    "        cols=df.columns\n",
    "        new_cols=[]\n",
    "        for col in cols:\n",
    "            if col==\"target\" or col==\"date_calc\":\n",
    "                continue\n",
    "            new_cols.append(df[col].groupby(df.index.date).transform('max').rename(f\"{col}_daymax\"))\n",
    "            new_cols.append(df[col].groupby(df.index.date).transform('min').rename(f\"{col}_daymin\"))\n",
    "            new_cols.append(df[col].groupby(df.index.date).transform('mean').rename(f\"{col}_daymean\"))\n",
    "            new_cols.append(df[col].groupby(df.index.date).transform('std').rename(f\"{col}_daystd\"))\n",
    "            new_cols.append(df[col].groupby(df.index.date).transform('sum').rename(f\"{col}_daysum\"))\n",
    "            #new_cols.append(pd.Series(np.log(1+df[col].values + 1e-8), index=df.index, name=f\"{col}_log\")) # convert numpy array to pandas Series\n",
    "            new_cols.append((df[col]**2).rename(f\"{col}_squared\"))\n",
    "        \"\"\"\n",
    "        for col1, col2 in itertools.combinations(cols, 2):\n",
    "            new_cols.append((df[col1] + df[col2]).rename(f\"{col1}+{col2}\"))\n",
    "            new_cols.append((df[col1] - df[col2]).rename(f\"{col1}-{col2}\"))\n",
    "            new_cols.append((df[col1] * df[col2]).rename(f\"{col1}*{col2}\"))\n",
    "            new_cols.append((df[col1] / df[col2]).rename(f\"{col1}/{col2}\"))\n",
    "        \"\"\"\n",
    "        df = pd.concat([df] + new_cols, axis=1)\n",
    "        return df.copy()\n",
    "            \n",
    "    def shift_target(df, target_col):\n",
    "        # Ensure the DataFrame is indexed by date\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "\n",
    "        # Store the original indices\n",
    "        original_indices = df.index\n",
    "\n",
    "        # Reindex the DataFrame to include all hours\n",
    "        all_hours = pd.date_range(start=df.index.min(), end=df.index.max(), freq='H')\n",
    "        df = df.reindex(all_hours)\n",
    "\n",
    "        # Shift the target variable by 1 hour forward and backward\n",
    "        df[target_col + '_shifted_forward'] = df[target_col].shift(-1)\n",
    "        df[target_col + '_shifted_backward'] = df[target_col].shift(1)\n",
    "\n",
    "        # Forward fill the missing values for the forward shift\n",
    "        df[target_col + '_shifted_forward'].ffill(inplace=True)\n",
    "\n",
    "        # Backward fill the missing values for the backward shift\n",
    "        df[target_col + '_shifted_backward'].bfill(inplace=True)\n",
    "\n",
    "        # Keep only the original indices\n",
    "        df = df.loc[original_indices]\n",
    "\n",
    "        return df\n",
    "    \n",
    "    \n",
    "    def new_train_test_split(X, y,letter,holdout=False):\n",
    "        \"\"\"\n",
    "        Splits the data based on a given date. Additionally, moves May, June and July data of split_date's year\n",
    "        from training set to test set.\n",
    "        \n",
    "        Parameters:\n",
    "        - X: Quarter-hourly input data with DateTime index.\n",
    "        - y: Hourly target data with DateTime index.\n",
    "        - split_date: Date (string or datetime object) to split the data on.\n",
    "        \n",
    "        Returns:\n",
    "        X_train, y_train, X_test, y_test\n",
    "        \"\"\"\n",
    "        Len=len(X)\n",
    "        Lensum=len(X[(X.index.month == 5) | (X.index.month == 6) | (X.index.month == 7)])\n",
    "        X=pd.concat([X,y],axis=1)\n",
    "    \n",
    "\n",
    "        # Convert index to DatetimeIndex object\n",
    "        X.index = pd.to_datetime(X.index)\n",
    "\n",
    "        num_samples = int(0.05 * len(X))\n",
    "        fraction = num_samples / len(X[(X.index.month == 5) | (X.index.month == 6) | (X.index.month == 7)])\n",
    "        X_test = X[(X.index.month == 5) | (X.index.month == 6) | (X.index.month == 7)].sample(frac=fraction, random_state=69)\n",
    "\n",
    "        X = X.drop(X_test.index)\n",
    "\n",
    "        if holdout:\n",
    "            X_holdout=X[(X.index.month == 5) | (X.index.month == 6) | (X.index.month == 7)].sample(frac=fraction*2, random_state=69)\n",
    "            X_train = X.drop(X_holdout.index)\n",
    "            y_holdout=X_holdout[\"target\"]\n",
    "            X_holdout=X_holdout.drop(columns=[\"target\"])\n",
    "        else:\n",
    "            X_train = X\n",
    "            y_holdout = None\n",
    "            X_holdout = None\n",
    "\n",
    "        \n",
    "\n",
    "        # Remove May and June data from training set\n",
    "        y_train=X_train[\"target\"]\n",
    "        y_test=X_test[\"target\"]\n",
    "        X_train=X_train.drop(columns=[\"target\"])\n",
    "        X_test=X_test.drop(columns=[\"target\"])\n",
    "\n",
    "        return X_train, X_test, y_train, y_test, X_holdout, y_holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "\n",
    "\n",
    "class post:    \n",
    "    def readRawTest(letter):\n",
    "        df = pd.read_parquet(f\"{letter}/X_test_estimated.parquet\")\n",
    "        df.set_index(\"date_forecast\", inplace=True)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        return df\n",
    "\n",
    "    def readAndBasicPreprocess(letter):\n",
    "        X = post.readRawTest(letter)\n",
    "        X.drop(columns=['cloud_base_agl:m'], inplace=True)\n",
    "        X.drop(columns=['ceiling_height_agl:m'], inplace=True)\n",
    "        X.drop(columns=['snow_density:kgm3'], inplace=True)\n",
    "        X=pre.create_features(X)\n",
    "        X=pre.create_time_features(X)\n",
    "        X.drop(columns=['date_calc'], inplace=True)\n",
    "        X = X.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "        X = pre.add_lagged_features(X)\n",
    "        return X\n",
    "\n",
    "    def makePrediction(A_model, B_model, C_model, filename):\n",
    "        A_x_test = post.readAndBasicPreprocess(\"A\")\n",
    "        A_y_pred=A_model.predict(A_x_test)\n",
    "        A_y_pred=pd.DataFrame(A_y_pred, index=range(0,720), columns=['prediction'])\n",
    "\n",
    "        B_x_test= post.readAndBasicPreprocess(\"B\")\n",
    "        B_y_pred=B_model.predict(B_x_test)\n",
    "        B_y_pred=pd.DataFrame(B_y_pred, index=range(720,1440), columns=['prediction'])\n",
    "\n",
    "        C_x_test= post.readAndBasicPreprocess(\"C\")\n",
    "        C_y_pred=C_model.predict(C_x_test)\n",
    "        C_y_pred=pd.DataFrame(C_y_pred, index=range(1440,2160), columns=['prediction'])\n",
    "\n",
    "        combined_pred = pd.concat([A_y_pred, B_y_pred, C_y_pred], axis=0)\n",
    "        combined_pred[\"prediction\"] = combined_pred[\"prediction\"].clip(lower=0)\n",
    "        combined_pred.index.name = \"id\"\n",
    "        combined_pred.to_csv(filename, index=True)\n",
    "\n",
    "    \n",
    "    def make_dnn_prediction(A_model, A_preprocessing, A_target_scaling, B_model, B_preprocessing, B_target_scaling, C_model, C_preprocessing, C_target_scaling, filename):\n",
    "        A_X_test = post.readAndBasicPreprocess(\"A\")\n",
    "        A_X_test_dnn = pd.DataFrame(A_preprocessing.transform(A_X_test))\n",
    "        A_y_pred_dnn = A_model.predict(A_X_test_dnn)\n",
    "        A_y_pred_dnn = A_target_scaling.inverse_transform(A_y_pred_dnn).reshape(-1)\n",
    "        A_y_pred = pd.DataFrame(A_y_pred_dnn, index=range(0,720), columns=['prediction'])\n",
    "\n",
    "        B_X_test = post.readAndBasicPreprocess(\"B\")\n",
    "        B_X_test_dnn = pd.DataFrame(B_preprocessing.transform(B_X_test))\n",
    "        B_y_pred_dnn = B_model.predict(B_X_test_dnn)\n",
    "        B_y_pred_dnn = B_target_scaling.inverse_transform(B_y_pred_dnn).reshape(-1)\n",
    "        B_y_pred = pd.DataFrame(B_y_pred_dnn, index=range(720,1440), columns=['prediction'])\n",
    "\n",
    "        C_X_test = post.readAndBasicPreprocess(\"C\")\n",
    "        C_X_test_dnn = pd.DataFrame(C_preprocessing.transform(C_X_test))\n",
    "        C_y_pred_dnn = C_model.predict(C_X_test_dnn)\n",
    "        C_y_pred_dnn = C_target_scaling.inverse_transform(C_y_pred_dnn).reshape(-1)\n",
    "        C_y_pred = pd.DataFrame(C_y_pred_dnn, index=range(1440,2160), columns=['prediction'])\n",
    "\n",
    "        combined_pred = pd.concat([A_y_pred, B_y_pred, C_y_pred], axis=0)\n",
    "        combined_pred[\"prediction\"] = combined_pred[\"prediction\"].clip(lower=0)\n",
    "        combined_pred.index.name = \"id\"\n",
    "        combined_pred.to_csv(filename, index=True)\n",
    "\n",
    "\n",
    "\n",
    "    def compute_mae(ser1, ser2):\n",
    "        \"\"\"Compute Mean Absolute Error between two Series.\"\"\"\n",
    "        return np.abs(ser1 - ser2).mean()\n",
    "\n",
    "    def plot_mae_grid(dataframes_dict):\n",
    "        \"\"\"Plot a grid of MAE values for a dictionary of DataFrames.\"\"\"\n",
    "        \n",
    "        labels = list(dataframes_dict.keys())\n",
    "        dataframes = list(dataframes_dict.values())\n",
    "        n = len(dataframes)\n",
    "        \n",
    "        mae_grid = np.zeros((n, n))\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j:\n",
    "                    mae_grid[i][j] = post.compute_mae(dataframes[i][\"prediction\"], dataframes[j][\"prediction\"])\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        cax = ax.matshow(mae_grid, cmap=\"viridis\")\n",
    "        \n",
    "        ax.grid(False)\n",
    "        plt.xticks(range(n), labels, rotation=45)\n",
    "        plt.yticks(range(n), labels)\n",
    "        \n",
    "        # Add annotations\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                text = ax.text(j, i, f\"{mae_grid[i, j]:.2f}\",\n",
    "                            ha=\"center\", va=\"center\", color=\"w\" if mae_grid[i, j] > (mae_grid.max() / 2) else \"black\")\n",
    "        \n",
    "        plt.colorbar(cax)\n",
    "        plt.title('MAE Between DataFrames on \"prediction\" Column', pad=20)\n",
    "        plt.show()\n",
    "\n",
    "    def makePredictionWithModelAndPreprocessor(A_model, B_model, C_model, preprocessor, filename):\n",
    "        \"\"\"\n",
    "        Assumes same preprocessing for all locations\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        A_X_test = post.readAndBasicPreprocess(\"A\")\n",
    "        A_X_test = preprocessor.transform(A_X_test)\n",
    "        A_y_pred = A_model.predict(A_X_test)\n",
    "        A_y_pred = pd.DataFrame(A_y_pred, index=range(0,720), columns=['prediction'])\n",
    "\n",
    "        B_X_test = post.readAndBasicPreprocess(\"B\")\n",
    "        B_X_test = preprocessor.transform(B_X_test)\n",
    "        B_y_pred = B_model.predict(B_X_test)\n",
    "        B_y_pred = pd.DataFrame(B_y_pred, index=range(720,1440), columns=['prediction'])\n",
    "\n",
    "        C_X_test = post.readAndBasicPreprocess(\"C\")\n",
    "        C_X_test = preprocessor.transform(C_X_test)\n",
    "        C_y_pred = C_model.predict(C_X_test)\n",
    "        C_y_pred = pd.DataFrame(C_y_pred, index=range(1440,2160), columns=['prediction'])\n",
    "\n",
    "        combined_pred = pd.concat([A_y_pred, B_y_pred, C_y_pred], axis=0)\n",
    "        combined_pred[\"prediction\"] = combined_pred[\"prediction\"].clip(lower=0)\n",
    "        combined_pred.index.name = \"id\"\n",
    "        combined_pred.to_csv(filename, index=True)\n",
    "\n",
    "\n",
    "\n",
    "    def make_average_prediction(preds_dict,filename):\n",
    "        \"\"\"\n",
    "        Generates a prediction by taking the average of the predictions in preds_dict.\n",
    "        \"\"\"\n",
    "        lenght = len(preds_dict)\n",
    "        data = 0\n",
    "        for value in preds_dict.values():\n",
    "            data += value[\"prediction\"]\n",
    "        data = data / lenght\n",
    "        data = pd.DataFrame(data, columns=['prediction'])\n",
    "        data.index.name = \"id\"\n",
    "        data[\"prediction\"] = data['prediction'].apply(lambda x: 0 if x < 0.1 else x)\n",
    "        data.loc[(data.index % 24).isin([22, 23, 0]), \"prediction\"] = 0\n",
    "        data.to_csv(filename, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Neural Network with tuned hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining The DNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#impoting lightning:\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "#import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset as DataSet\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "import numpy as np\n",
    "import random\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "SEED = 69\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = SEED\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "class SolarForecastingDataset(DataSet):\n",
    "    def __init__(self, features_df, target_series):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with features and target labels.\n",
    "\n",
    "        :param features_df: DataFrame containing the features.\n",
    "        :param target_series: Series containing the target labels.\n",
    "        \"\"\"\n",
    "        self.features = features_df\n",
    "        self.targets = target_series\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Extracting the features and the target label for the given index\n",
    "        feature_vector = self.features.iloc[index].values\n",
    "        target_label = self.targets.iloc[index]\n",
    "\n",
    "        return {\n",
    "            \"feature_vector\": torch.tensor(feature_vector, dtype=torch.float),\n",
    "            \"target_label\": torch.tensor(target_label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "class SolarForecastingDatasetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_features_df, train_targets_series, test_features_df, test_targets_series, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.train_features_df = train_features_df\n",
    "        self.train_targets_series = train_targets_series\n",
    "        self.test_features_df = test_features_df\n",
    "        self.test_targets_series = test_targets_series\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = SolarForecastingDataset(self.train_features_df, self.train_targets_series)\n",
    "        self.test_dataset = SolarForecastingDataset(self.test_features_df, self.test_targets_series)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size,worker_init_fn=seed_worker, generator=g, shuffle=True,)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, shuffle=False, worker_init_fn=seed_worker, generator=g)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, shuffle=False, worker_init_fn=seed_worker, generator=g)\n",
    "\n",
    "class FullyConnectedDNN(nn.Module):\n",
    "    def __init__(self, input_size, layer_sizes, output_size, dropout_prob=0.1):\n",
    "        super(FullyConnectedDNN, self).__init__()\n",
    "        # Create fully connected layers\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        for i in range(len(layer_sizes)):\n",
    "            in_features = input_size if i == 0 else layer_sizes[i - 1]\n",
    "            out_features = layer_sizes[i]\n",
    "            self.fc_layers.append(nn.Linear(in_features, out_features))\n",
    "\n",
    "        self.output_layer = nn.Linear(layer_sizes[-1], output_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.fc_layers:\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "def weighted_mae_loss(input, target, exponent=1, constant=1):\n",
    "    assert input.size() == target.size()\n",
    "\n",
    "    # Calculate the absolute error\n",
    "    absolute_errors = torch.abs(input - target)\n",
    "\n",
    "    # Apply exponential scaling with a constant\n",
    "    adjusted_target = target + constant\n",
    "    weighted_errors = absolute_errors * (adjusted_target ** exponent)\n",
    "\n",
    "    return weighted_errors.mean()\n",
    "\n",
    "\n",
    "class SolarPowerProductionPredictor(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, input_size, layer_sizes, output_size, weight_decay=1e-5, dropout_prob=0.1, learning_rate=0.01, verbose=True, loss_exponent=1.0, loss_beta=1.0):\n",
    "        super().__init__()\n",
    "        self.model = FullyConnectedDNN(input_size, layer_sizes, output_size, dropout_prob=dropout_prob)\n",
    "        self.criterion = self.criterion = lambda input, target: weighted_mae_loss(input, target, exponent=loss_exponent, constant=1)\n",
    "        #self.criterion = CustomMAELoss(loss_alpha, loss_beta)\n",
    "\n",
    "        self.weight_decay = weight_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def forward(self, x, labels=None):\n",
    "        output = self.model(x)\n",
    "        loss = 0\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels)\n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        features, labels = batch[\"feature_vector\"], batch[\"target_label\"]\n",
    "        loss, outputs = self(features, labels) \n",
    "        self.log(\"train_loss\", loss, prog_bar=self.verbose, logger=False)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        features, labels = batch[\"feature_vector\"], batch[\"target_label\"]\n",
    "        loss, outputs = self(features, labels) \n",
    "        self.log(\"val_loss\", loss, prog_bar=self.verbose, logger=False)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        features, labels = batch[\"feature_vector\"], batch[\"target_label\"]\n",
    "        loss, outputs = self(features, labels) \n",
    "        self.log(\"test_loss\", loss, prog_bar=self.verbose, logger=False)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "\n",
    "\n",
    "\n",
    "class CustomModelCheckpoint(ModelCheckpoint):\n",
    "    def on_save_checkpoint(self, trainer, pl_module, checkpoint):\n",
    "        # Save the best model path to the pl_module\n",
    "        pl_module.best_model_path = self.best_model_path\n",
    "\n",
    "def get_predictions(model, dataloader):\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch[\"feature_vector\"], batch[\"target_label\"]\n",
    "            predictions = model(features)[1]  \n",
    "            if not isinstance(predictions, torch.Tensor):\n",
    "                raise TypeError(\"Model output is not a tensor. Got type: {}\".format(type(predictions)))\n",
    "            \n",
    "            all_predictions.append(predictions)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    # Check for tensor types before concatenation\n",
    "    if not all(isinstance(p, torch.Tensor) for p in all_predictions):\n",
    "        raise TypeError(\"Not all elements in predictions are tensors.\")\n",
    "\n",
    "    if not all(isinstance(l, torch.Tensor) for l in all_labels):\n",
    "        raise TypeError(\"Not all elements in labels are tensors.\")\n",
    "\n",
    "    all_predictions_tensor = torch.cat(all_predictions, dim=0)\n",
    "    all_labels_tensor = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    all_predictions_np = all_predictions_tensor.cpu().numpy()\n",
    "    all_labels_np = all_labels_tensor.cpu().numpy()\n",
    "    \n",
    "    return all_predictions_np, all_labels_np\n",
    "\n",
    "class HenrikDNN:\n",
    "\n",
    "    def __init__(self,n_features = None, layer_sizes = [100,50], output_size = 1, drop_out_prob = 0.1, learning_rate = 0.01, weight_decay = 1e-5, max_epochs = 100, paitience = 5, batch_size = 16, val_chack_interval = 1, pruning_callback = None, verbose = True, loss_expontent = 1):\n",
    "\n",
    "        self.n_features = n_features\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.verbose = verbose\n",
    "        self.output_size = output_size\n",
    "        self.drop_out_prob = drop_out_prob\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.loss_expontent = loss_expontent\n",
    "        self.paitience = paitience\n",
    "        self.batch_size = batch_size\n",
    "        self.max_epochs = max_epochs\n",
    "        self.val_chack_interval = val_chack_interval\n",
    "        self.pruning_callback = pruning_callback\n",
    "        SEED = 69\n",
    "        torch.manual_seed(SEED)\n",
    "        np.random.seed(SEED)\n",
    "        random.seed(SEED)\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(SEED)\n",
    "\n",
    "\n",
    "        self.pl_model = SolarPowerProductionPredictor(self.n_features, self.layer_sizes, self.output_size, weight_decay=self.weight_decay, dropout_prob=self.drop_out_prob, learning_rate=self.learning_rate, verbose=self.verbose, loss_exponent=self.loss_expontent)\n",
    "\n",
    "        self.checkpoint_callback = CustomModelCheckpoint(\n",
    "            dirpath='HenrikDNN_checkpoints',\n",
    "            save_top_k=1,\n",
    "            verbose=self.verbose,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            filename='model-{epoch:02d}-{val_loss:.2f}'\n",
    "        )\n",
    "\n",
    "        self.early_stopping_callback = EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=self.paitience\n",
    "        )\n",
    "\n",
    "\n",
    "        self.callbacks = [self.early_stopping_callback, self.checkpoint_callback]\n",
    "        if self.pruning_callback is not None:\n",
    "            self.callbacks.append(self.pruning_callback)\n",
    "        seed_everything(69, workers=True)\n",
    "\n",
    "        self.trainer = pl.Trainer(\n",
    "            max_epochs=self.max_epochs,\n",
    "            callbacks=self.callbacks,\n",
    "            enable_progress_bar=self.verbose,\n",
    "            accelerator=\"cpu\",\n",
    "            check_val_every_n_epoch = 2,\n",
    "            deterministic=True\n",
    "\n",
    "            #val_check_interval=self.val_chack_interval\n",
    "        )\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X_train: Training df with datetime index. \n",
    "            y_train: Training df, with datetime index. Each row in y_train corresponds to four rows in X_train.\n",
    "    \n",
    "        \"\"\"\n",
    "        #print the seed:\n",
    "        SEED = 69\n",
    "        print(\"hei\")\n",
    "        torch.manual_seed(SEED)\n",
    "        np.random.seed(SEED)\n",
    "        random.seed(SEED)\n",
    "        torch.use_deterministic_algorithms(True)\n",
    "        g = torch.Generator()\n",
    "        g.manual_seed(SEED)\n",
    "\n",
    "        self.data_module = SolarForecastingDatasetDataModule(X_train, y_train, X_val, y_val, batch_size=self.batch_size)\n",
    "        self.trainer.fit(self.pl_model, self.data_module)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        trained_model = SolarPowerProductionPredictor.load_from_checkpoint(\n",
    "            self.pl_model.best_model_path,\n",
    "            input_size=self.n_features,\n",
    "            layer_sizes=self.layer_sizes,\n",
    "            output_size=self.output_size,\n",
    "            dropout_prob=self.drop_out_prob,\n",
    "            learning_rate=self.learning_rate,\n",
    "            weight_decay=self.weight_decay,\n",
    "            verbose=self.verbose,\n",
    "            loss_exponent=self.loss_expontent\n",
    "        )\n",
    "\n",
    "        X_dataloader = torch.utils.data.DataLoader(\n",
    "            SolarForecastingDataset(X, pd.Series(np.zeros(X.shape[0]))),\n",
    "            batch_size=1,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            worker_init_fn=seed_worker,\n",
    "            generator=g\n",
    "        )\n",
    "\n",
    "        predictions, _ = get_predictions(trained_model, X_dataloader)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "\n",
    "def train_test_split_on_specific_day_May_june(X, y, split_date):\n",
    "    \"\"\"\n",
    "    Splits the data based on a given date. Additionally, moves May, June and July data of split_date's year\n",
    "    from training set to test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Quarter-hourly input data with DateTime index.\n",
    "    - y: Hourly target data with DateTime index.\n",
    "    - split_date: Date (string or datetime object) to split the data on.\n",
    "    \n",
    "    Returns:\n",
    "    X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    split_date = pd.Timestamp(split_date).normalize()\n",
    "\n",
    "    # Ensure split_date is a datetime object\n",
    "    if isinstance(split_date, str):\n",
    "        split_date = pd.Timestamp(split_date)\n",
    "\n",
    "    print(f\"Split date: {split_date}\")\n",
    "\n",
    "    # Split the data based on the provided date\n",
    "    X_train = X[X.index.normalize() < split_date]\n",
    "    y_train = y[y.index.normalize() < split_date]\n",
    "\n",
    "    X_test = X[X.index.normalize() >= split_date]\n",
    "    y_test = y[y.index.normalize() >= split_date]\n",
    "\n",
    "    # Define conditions to move May and June of split_date's year from train to test\n",
    "    may_june_condition_X = ((X_train.index.month == 5) | (X_train.index.month == 6) | (X_train.index.month == 7)) & (X_train.index.year == split_date.year)\n",
    "    may_june_condition_y = ((y_train.index.month == 5) | (y_train.index.month == 6) | (y_train.index.month == 7)) & (y_train.index.year == split_date.year)\n",
    "    \n",
    "    X_may_june = X_train[may_june_condition_X]\n",
    "    y_may_june = y_train[may_june_condition_y]\n",
    "\n",
    "    # Remove May and June data from training set\n",
    "    X_train = X_train[~may_june_condition_X]\n",
    "    y_train = y_train[~may_june_condition_y]\n",
    "\n",
    "    # Append May and June data to test set\n",
    "    X_test = pd.concat([X_may_june, X_test])\n",
    "    y_test = pd.concat([y_may_june, y_test])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training A, iteration 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 17:56:29.448479: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-12 17:56:29.476150: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-12 17:56:29.891322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 46.4 K\n",
      "--------------------------------------------\n",
      "46.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "46.4 K    Total params\n",
      "0.185     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE DNN location A: 286.5414860651279\n",
      "new best score for A: 286.5414860651279\n",
      "training A, iteration 2 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 46.4 K\n",
      "--------------------------------------------\n",
      "46.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "46.4 K    Total params\n",
      "0.185     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location A: 288.68237908470246\n",
      "training A, iteration 3 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 46.4 K\n",
      "--------------------------------------------\n",
      "46.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "46.4 K    Total params\n",
      "0.185     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location A: 289.1929559876062\n",
      "training A, iteration 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 46.4 K\n",
      "--------------------------------------------\n",
      "46.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "46.4 K    Total params\n",
      "0.185     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location A: 289.4235650342097\n",
      "training A, iteration 5 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 46.4 K\n",
      "--------------------------------------------\n",
      "46.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "46.4 K    Total params\n",
      "0.185     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location A: 290.3333862642418\n",
      "training A, iteration 6 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 46.4 K\n",
      "--------------------------------------------\n",
      "46.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "46.4 K    Total params\n",
      "0.185     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location A: 287.4641432328177\n",
      "training A, iteration 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 46.4 K\n",
      "--------------------------------------------\n",
      "46.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "46.4 K    Total params\n",
      "0.185     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location A: 293.1902655576716\n",
      "training B, iteration 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 67.8 K\n",
      "--------------------------------------------\n",
      "67.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "67.8 K    Total params\n",
      "0.271     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location B: 66.26056107655843\n",
      "new best score for B: 66.26056107655843\n",
      "training B, iteration 2 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 67.8 K\n",
      "--------------------------------------------\n",
      "67.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "67.8 K    Total params\n",
      "0.271     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location B: 66.18475673490728\n",
      "new best score for B: 66.18475673490728\n",
      "training B, iteration 3 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 67.8 K\n",
      "--------------------------------------------\n",
      "67.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "67.8 K    Total params\n",
      "0.271     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location B: 65.80722993227957\n",
      "new best score for B: 65.80722993227957\n",
      "training B, iteration 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 67.8 K\n",
      "--------------------------------------------\n",
      "67.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "67.8 K    Total params\n",
      "0.271     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location B: 66.13701551589087\n",
      "training B, iteration 5 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 67.8 K\n",
      "--------------------------------------------\n",
      "67.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "67.8 K    Total params\n",
      "0.271     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location B: 66.09520563131474\n",
      "training B, iteration 6 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 67.8 K\n",
      "--------------------------------------------\n",
      "67.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "67.8 K    Total params\n",
      "0.271     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location B: 66.20781233880216\n",
      "training B, iteration 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 67.8 K\n",
      "--------------------------------------------\n",
      "67.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "67.8 K    Total params\n",
      "0.271     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location B: 65.70001195192403\n",
      "new best score for B: 65.70001195192403\n",
      "training C, iteration 1 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 60.5 K\n",
      "--------------------------------------------\n",
      "60.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 K    Total params\n",
      "0.242     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location C: 52.05439660056946\n",
      "new best score for C: 52.05439660056946\n",
      "training C, iteration 2 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 60.5 K\n",
      "--------------------------------------------\n",
      "60.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 K    Total params\n",
      "0.242     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location C: 53.571651111596466\n",
      "training C, iteration 3 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 60.5 K\n",
      "--------------------------------------------\n",
      "60.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 K    Total params\n",
      "0.242     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location C: 52.84903817735908\n",
      "training C, iteration 4 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 60.5 K\n",
      "--------------------------------------------\n",
      "60.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 K    Total params\n",
      "0.242     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location C: 53.383526802383685\n",
      "training C, iteration 5 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 60.5 K\n",
      "--------------------------------------------\n",
      "60.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 K    Total params\n",
      "0.242     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location C: 54.76077917599066\n",
      "training C, iteration 6 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 60.5 K\n",
      "--------------------------------------------\n",
      "60.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 K    Total params\n",
      "0.242     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location C: 52.49614753744029\n",
      "training C, iteration 7 of 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 69\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:634: Checkpoint directory HenrikDNN_checkpoints exists and is not empty.\n",
      "\n",
      "  | Name  | Type              | Params\n",
      "--------------------------------------------\n",
      "0 | model | FullyConnectedDNN | 60.5 K\n",
      "--------------------------------------------\n",
      "60.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "60.5 K    Total params\n",
      "0.242     Total estimated model params size (MB)\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "/home/student/Downloads/test_short_notebok/sui/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hei\n",
      "MAE DNN location C: 52.6386769562155\n"
     ]
    }
   ],
   "source": [
    "def trainDNN(letter):\n",
    "    X, y = pre.general_read(letter)\n",
    "    X = pre.concatenate_dfs(X)\n",
    "    X_train, y_train,X_val, y_val = pre.train_test_split_may_june_july(X,y , letter)\n",
    "    y_train = y_train[\"target\"]\n",
    "    y_val = y_val[\"target\"]\n",
    "\n",
    "    if letter == \"A\":\n",
    "\n",
    "        dnn_params = {\n",
    "            'layer_sizes': [119,101], #<----- from opta hyper parameter tuning\n",
    "            'drop_out_prob': 0.03, #<----- from opta hyper parameter tuning\n",
    "            'learning_rate': 0.0000969995972939842, #<----- from opta hyper parameter tuning\n",
    "            'loss_expontent': 0.9702228408589507, #<----- from opta hyper parameter tuning\n",
    "            'max_epochs': 300, #\n",
    "            'paitience': 15, #\n",
    "            'batch_size': 128, #\n",
    "            'val_chack_interval': 0.5, #\n",
    "            'verbose': False,\n",
    "            'weight_decay': 2.499126185711371e-8 #<----- from opta hyper parameter tuning\n",
    "        }\n",
    "\n",
    "        dnn_feature_scaler = 'minmax' #<----- from opta hyper parameter tuning\n",
    "        dnn_target_scaler = 'minmax' #<----- from opta hyper parameter tuning\n",
    "        dnn_preprocessor = 'quarters' #<----- from opta hyper parameter tuning\n",
    "        dnn_target_encoder = True #<----- from opta hyper parameter tuning\n",
    "    \n",
    "    elif letter == \"B\":\n",
    "        \n",
    "        dnn_params = {\n",
    "            'layer_sizes': [200,180], #<----- from opta hyper parameter tuning\n",
    "            'drop_out_prob': 0.03, #<----- from opta hyper parameter tuning\n",
    "            'learning_rate': 0.000018846485346070986, #<----- from opta hyper parameter tuning\n",
    "            'loss_expontent': 0.963895316469423, #<----- from opta hyper parameter tuning\n",
    "            'max_epochs': 300, #\n",
    "            'paitience': 15, #\n",
    "            'batch_size': 128, #\n",
    "            'val_chack_interval': 0.5, #\n",
    "            'verbose': False,\n",
    "            'weight_decay': 6.586949775384596e-7 #<----- from opta hyper parameter tuning\n",
    "        }\n",
    "        \n",
    "        dnn_feature_scaler = 'minmax'\n",
    "        dnn_target_scaler = 'minmax'\n",
    "        dnn_preprocessor = 'statistical'\n",
    "        dnn_target_encoder = False\n",
    "    \n",
    "    elif letter == \"C\":\n",
    "        #52.31801357204807\tquarters\ttrue\t144\t131\t0.000060363753946263044\t-1.5104000124283146\t2.335809622586189e-7\n",
    "        dnn_params = {\n",
    "            'layer_sizes': [144,131], #<----- from opta hyper parameter tuning\n",
    "            'drop_out_prob': 0.03, #<----- from opta hyper parameter tuning\n",
    "            'learning_rate': 0.000060363753946263044, #<----- from opta hyper parameter tuning\n",
    "            'loss_expontent': -1.5104000124283146, #<----- from opta hyper parameter tuning\n",
    "            'max_epochs': 300, #\n",
    "            'paitience': 15, #\n",
    "            'batch_size': 128, #\n",
    "            'val_chack_interval': 0.5, #\n",
    "            'verbose': False,\n",
    "            'weight_decay': 2.335809622586189e-7 #<----- from opta hyper parameter tuning\n",
    "        }\n",
    "\n",
    "        dnn_feature_scaler = 'minmax'\n",
    "        dnn_target_scaler = 'minmax'\n",
    "        dnn_preprocessor = 'quarters'\n",
    "        dnn_target_encoder = True\n",
    "\n",
    "    dnn_feature_scaler = pre.choose_scaler(dnn_feature_scaler)\n",
    "    dnn_target_scaler = pre.choose_scaler(dnn_target_scaler)\n",
    "    dnn_preprocessor = pre.choose_transformer(dnn_preprocessor)\n",
    "    dnn_target_encoder = pre.choose_encoder(dnn_target_encoder)\n",
    "    \n",
    "    dnn_preprocessing = Pipeline([\n",
    "        ('custom_transformer', dnn_preprocessor),\n",
    "        ('target_encoder', dnn_target_encoder), \n",
    "        ('feature_scaler', dnn_feature_scaler)\n",
    "    ])\n",
    "\n",
    "    dnn_target_preprocessing = Pipeline([\n",
    "        ('target_scaler', dnn_target_scaler)\n",
    "    ])\n",
    "\n",
    "    #fit the preprocessing:\n",
    "    dnn_preprocessing.fit(X_train, y_train)\n",
    "    dnn_target_preprocessing.fit(pd.DataFrame(y_train))\n",
    "\n",
    "    #transform the data:\n",
    "    X_train_dnn = pd.DataFrame((dnn_preprocessing.transform(X_train)))\n",
    "    y_train_dnn = pd.DataFrame(dnn_target_preprocessing.transform(pd.DataFrame(y_train)))\n",
    "    X_val_dnn = pd.DataFrame(dnn_preprocessing.transform(X_val))\n",
    "    y_val_dnn = pd.DataFrame(dnn_target_preprocessing.transform(pd.DataFrame(y_val)))\n",
    "\n",
    "    #fit the model:\n",
    "    dnn_model = HenrikDNN(n_features =X_train_dnn.shape[1] , **dnn_params)\n",
    "    dnn_model.train(X_train_dnn, y_train_dnn, X_val_dnn, y_val_dnn)\n",
    "    #predict:\n",
    "    dnn_pred = dnn_model.predict(X_val_dnn)\n",
    "    #scale back:\n",
    "    dnn_pred = dnn_target_preprocessing.inverse_transform(dnn_pred).reshape(-1)\n",
    "\n",
    "    print(f\"MAE DNN location {letter}: {mean_absolute_error(y_val, dnn_pred)}\")\n",
    "\n",
    "    return dnn_model, dnn_preprocessing, dnn_target_preprocessing, mean_absolute_error(y_val, dnn_pred)\n",
    "\n",
    "\n",
    "models = {\"A\": \n",
    "          {\"best_score\": 10000, \"best_model\": None, \"best_preprocessor\": None, \"best_target_preprocessor\": None},\n",
    "          \"B\": \n",
    "          {\"best_score\": 10000, \"best_model\": None, \"best_preprocessor\": None, \"best_target_preprocessor\": None},\n",
    "          \"C\": \n",
    "          {\"best_score\": 10000, \"best_model\": None, \"best_preprocessor\": None, \"best_target_preprocessor\": None}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "num_iterations = 7\n",
    "\n",
    "\n",
    "for letter in [\"A\", \"B\", \"C\"]:\n",
    "    for i in range(num_iterations):\n",
    "        print(f\"training {letter}, iteration {i+1} of {num_iterations}\")\n",
    "        model, preprocessor, target_preprocessor, score = trainDNN(letter)\n",
    "        if score < models[letter][\"best_score\"]:\n",
    "            print(f\"new best score for {letter}: {score}\")\n",
    "            models[letter][\"best_score\"] = score\n",
    "            models[letter][\"best_model\"] = model\n",
    "            models[letter][\"best_preprocessor\"] = preprocessor\n",
    "            models[letter][\"best_target_preprocessor\"] = target_preprocessor\n",
    "\n",
    "post.make_dnn_prediction(models[\"A\"][\"best_model\"],\n",
    "                         models[\"A\"][\"best_preprocessor\"],\n",
    "                         models[\"A\"][\"best_target_preprocessor\"],\n",
    "                         models[\"B\"][\"best_model\"],\n",
    "                         models[\"B\"][\"best_preprocessor\"],\n",
    "                         models[\"B\"][\"best_target_preprocessor\"],\n",
    "                         models[\"C\"][\"best_model\"],\n",
    "                         models[\"C\"][\"best_preprocessor\"],\n",
    "                         models[\"C\"][\"best_target_preprocessor\"],\n",
    "                         f\"{FOLDER_NAME}/DNN.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flask's AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flaml.automl.logger: 11-12 20:04:39] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 11-12 20:04:39] {1687} INFO - Data split method: uniform\n",
      "[flaml.automl.logger: 11-12 20:04:39] {1690} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 11-12 20:04:39] {1788} INFO - Minimizing error metric: mae\n",
      "[flaml.automl.logger: 11-12 20:04:39] {1900} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 11-12 20:04:39] {2218} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:39] {2344} INFO - Estimated sufficient time budget=2267s. Estimated necessary time budget=19s.\n",
      "[flaml.automl.logger: 11-12 20:04:39] {2391} INFO -  at 1.3s,\testimator lgbm's best error=721.2925,\tbest estimator lgbm's best error=721.2925\n",
      "[flaml.automl.logger: 11-12 20:04:39] {2218} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:39] {2391} INFO -  at 1.5s,\testimator lgbm's best error=647.8535,\tbest estimator lgbm's best error=647.8535\n",
      "[flaml.automl.logger: 11-12 20:04:39] {2218} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2391} INFO -  at 1.7s,\testimator lgbm's best error=647.8535,\tbest estimator lgbm's best error=647.8535\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2218} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2391} INFO -  at 1.8s,\testimator lgbm's best error=635.6789,\tbest estimator lgbm's best error=635.6789\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2218} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2391} INFO -  at 2.0s,\testimator lgbm's best error=472.8438,\tbest estimator lgbm's best error=472.8438\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2218} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2391} INFO -  at 2.2s,\testimator lgbm's best error=363.8583,\tbest estimator lgbm's best error=363.8583\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2218} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2391} INFO -  at 2.4s,\testimator lgbm's best error=363.8583,\tbest estimator lgbm's best error=363.8583\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2218} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2391} INFO -  at 2.6s,\testimator lgbm's best error=363.8583,\tbest estimator lgbm's best error=363.8583\n",
      "[flaml.automl.logger: 11-12 20:04:40] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:04:41] {2391} INFO -  at 2.7s,\testimator xgboost's best error=715.6926,\tbest estimator lgbm's best error=363.8583\n",
      "[flaml.automl.logger: 11-12 20:04:41] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:04:41] {2391} INFO -  at 2.9s,\testimator xgboost's best error=645.5103,\tbest estimator lgbm's best error=363.8583\n",
      "[flaml.automl.logger: 11-12 20:04:41] {2218} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:41] {2391} INFO -  at 3.1s,\testimator lgbm's best error=346.0072,\tbest estimator lgbm's best error=346.0072\n",
      "[flaml.automl.logger: 11-12 20:04:41] {2218} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:04:41] {2391} INFO -  at 3.3s,\testimator extra_tree's best error=421.1442,\tbest estimator lgbm's best error=346.0072\n",
      "[flaml.automl.logger: 11-12 20:04:41] {2218} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:04:42] {2391} INFO -  at 3.7s,\testimator extra_tree's best error=408.7660,\tbest estimator lgbm's best error=346.0072\n",
      "[flaml.automl.logger: 11-12 20:04:42] {2218} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:04:42] {2391} INFO -  at 4.6s,\testimator rf's best error=433.5866,\tbest estimator lgbm's best error=346.0072\n",
      "[flaml.automl.logger: 11-12 20:04:42] {2218} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:43] {2391} INFO -  at 4.9s,\testimator lgbm's best error=335.2427,\tbest estimator lgbm's best error=335.2427\n",
      "[flaml.automl.logger: 11-12 20:04:43] {2218} INFO - iteration 15, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:43] {2391} INFO -  at 5.1s,\testimator lgbm's best error=335.2427,\tbest estimator lgbm's best error=335.2427\n",
      "[flaml.automl.logger: 11-12 20:04:43] {2218} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:43] {2391} INFO -  at 5.3s,\testimator lgbm's best error=334.5931,\tbest estimator lgbm's best error=334.5931\n",
      "[flaml.automl.logger: 11-12 20:04:43] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:04:43] {2391} INFO -  at 5.4s,\testimator xgboost's best error=645.5103,\tbest estimator lgbm's best error=334.5931\n",
      "[flaml.automl.logger: 11-12 20:04:43] {2218} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:44] {2391} INFO -  at 5.6s,\testimator lgbm's best error=321.4361,\tbest estimator lgbm's best error=321.4361\n",
      "[flaml.automl.logger: 11-12 20:04:44] {2218} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:44] {2391} INFO -  at 6.0s,\testimator lgbm's best error=316.5987,\tbest estimator lgbm's best error=316.5987\n",
      "[flaml.automl.logger: 11-12 20:04:44] {2218} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:44] {2391} INFO -  at 6.2s,\testimator lgbm's best error=316.5987,\tbest estimator lgbm's best error=316.5987\n",
      "[flaml.automl.logger: 11-12 20:04:44] {2218} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:44] {2391} INFO -  at 6.6s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:44] {2218} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:45] {2391} INFO -  at 6.9s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:45] {2218} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:45] {2391} INFO -  at 7.5s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:45] {2218} INFO - iteration 24, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:04:47] {2391} INFO -  at 9.1s,\testimator rf's best error=433.5866,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:47] {2218} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:04:47] {2391} INFO -  at 9.4s,\testimator extra_tree's best error=384.1186,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:47] {2218} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:50] {2391} INFO -  at 11.9s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:50] {2218} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:04:50] {2391} INFO -  at 12.3s,\testimator extra_tree's best error=351.5905,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:50] {2218} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:04:51] {2391} INFO -  at 12.7s,\testimator extra_tree's best error=351.5905,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:51] {2218} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:04:51] {2391} INFO -  at 13.1s,\testimator extra_tree's best error=351.5905,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:51] {2218} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:51] {2391} INFO -  at 13.3s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:51] {2218} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:52] {2391} INFO -  at 13.9s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:52] {2218} INFO - iteration 32, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:04:53] {2391} INFO -  at 15.1s,\testimator rf's best error=376.4654,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:53] {2218} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:04:54] {2391} INFO -  at 15.9s,\testimator extra_tree's best error=335.0027,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:54] {2218} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:04:54] {2391} INFO -  at 16.1s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:54] {2218} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:04:54] {2391} INFO -  at 16.3s,\testimator xgboost's best error=645.5103,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:54] {2218} INFO - iteration 36, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:04:56] {2391} INFO -  at 18.0s,\testimator catboost's best error=320.4814,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:56] {2218} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:04:56] {2391} INFO -  at 18.5s,\testimator extra_tree's best error=329.5534,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:56] {2218} INFO - iteration 38, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:04:59] {2391} INFO -  at 21.6s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:04:59] {2218} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:00] {2391} INFO -  at 22.0s,\testimator xgboost's best error=363.8470,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:00] {2218} INFO - iteration 40, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:01] {2391} INFO -  at 22.7s,\testimator xgboost's best error=363.8470,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:01] {2218} INFO - iteration 41, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:01] {2391} INFO -  at 23.0s,\testimator xgboost's best error=346.0393,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:01] {2218} INFO - iteration 42, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:05:02] {2391} INFO -  at 23.8s,\testimator extra_tree's best error=329.5534,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:02] {2218} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:02] {2391} INFO -  at 24.2s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:02] {2218} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:02] {2391} INFO -  at 24.4s,\testimator xgboost's best error=346.0393,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:02] {2218} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:05:03] {2391} INFO -  at 24.6s,\testimator extra_tree's best error=329.5534,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:03] {2218} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:03] {2391} INFO -  at 25.2s,\testimator xgboost's best error=346.0393,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:03] {2218} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:05:05] {2391} INFO -  at 26.7s,\testimator rf's best error=348.9441,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:05] {2218} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:05] {2391} INFO -  at 26.9s,\testimator xgboost's best error=346.0393,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:05] {2218} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:05] {2391} INFO -  at 27.2s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:05] {2218} INFO - iteration 50, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:05:06] {2391} INFO -  at 28.5s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:06] {2218} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:05:07] {2391} INFO -  at 29.4s,\testimator extra_tree's best error=325.3105,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:07] {2218} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:05:09] {2391} INFO -  at 31.3s,\testimator rf's best error=348.9441,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:09] {2218} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:05:10] {2391} INFO -  at 32.6s,\testimator rf's best error=348.9441,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:10] {2218} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:11] {2391} INFO -  at 33.0s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:11] {2218} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:11] {2391} INFO -  at 33.5s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:11] {2218} INFO - iteration 56, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:12] {2391} INFO -  at 34.1s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:12] {2218} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:05:15] {2391} INFO -  at 37.0s,\testimator rf's best error=339.4236,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:15] {2218} INFO - iteration 58, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:05:17] {2391} INFO -  at 38.7s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:17] {2218} INFO - iteration 59, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:05:18] {2391} INFO -  at 39.8s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:18] {2218} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:18] {2391} INFO -  at 40.4s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:18] {2218} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:19] {2391} INFO -  at 41.0s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:19] {2218} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:19] {2391} INFO -  at 41.5s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:19] {2218} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:20] {2391} INFO -  at 42.0s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:20] {2218} INFO - iteration 64, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:23] {2391} INFO -  at 44.9s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:23] {2218} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:23] {2391} INFO -  at 45.1s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:23] {2218} INFO - iteration 66, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:05:25] {2391} INFO -  at 47.1s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:25] {2218} INFO - iteration 67, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:25] {2391} INFO -  at 47.3s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:25] {2218} INFO - iteration 68, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:05:27] {2391} INFO -  at 48.9s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:27] {2218} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:28] {2391} INFO -  at 49.7s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:28] {2218} INFO - iteration 70, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:05:31] {2391} INFO -  at 53.6s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:31] {2218} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:32] {2391} INFO -  at 54.0s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:32] {2218} INFO - iteration 72, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:05:39] {2391} INFO -  at 60.6s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:39] {2218} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:05:40] {2391} INFO -  at 62.0s,\testimator extra_tree's best error=322.7558,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:40] {2218} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:41] {2391} INFO -  at 63.1s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:41] {2218} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:05:42] {2391} INFO -  at 63.9s,\testimator extra_tree's best error=322.7558,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:42] {2218} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:44] {2391} INFO -  at 65.7s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:44] {2218} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:44] {2391} INFO -  at 65.9s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:44] {2218} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:05:45] {2391} INFO -  at 67.4s,\testimator extra_tree's best error=322.7558,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:45] {2218} INFO - iteration 79, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:05:47] {2391} INFO -  at 69.6s,\testimator rf's best error=332.6824,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:47] {2218} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:05:49] {2391} INFO -  at 70.9s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:49] {2218} INFO - iteration 81, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:05:50] {2391} INFO -  at 71.9s,\testimator extra_tree's best error=321.4442,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:50] {2218} INFO - iteration 82, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:05:53] {2391} INFO -  at 74.8s,\testimator rf's best error=332.6824,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:53] {2218} INFO - iteration 83, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:05:59] {2391} INFO -  at 81.1s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:05:59] {2218} INFO - iteration 84, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:06:03] {2391} INFO -  at 85.2s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:03] {2218} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:06:04] {2391} INFO -  at 86.3s,\testimator extra_tree's best error=321.4442,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:04] {2218} INFO - iteration 86, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:06:08] {2391} INFO -  at 90.5s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:08] {2218} INFO - iteration 87, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:06:16] {2391} INFO -  at 97.8s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:16] {2218} INFO - iteration 88, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:16] {2391} INFO -  at 98.0s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:16] {2218} INFO - iteration 89, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:18] {2391} INFO -  at 99.7s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:18] {2218} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:06:19] {2391} INFO -  at 100.8s,\testimator extra_tree's best error=321.4442,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:19] {2218} INFO - iteration 91, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:06:20] {2391} INFO -  at 101.7s,\testimator rf's best error=332.6824,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:20] {2218} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:06:20] {2391} INFO -  at 102.6s,\testimator extra_tree's best error=321.4442,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:20] {2218} INFO - iteration 93, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:06:25] {2391} INFO -  at 106.9s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:25] {2218} INFO - iteration 94, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:06:27] {2391} INFO -  at 109.0s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:27] {2218} INFO - iteration 95, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:27] {2391} INFO -  at 109.2s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:27] {2218} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:06:29] {2391} INFO -  at 110.9s,\testimator extra_tree's best error=319.3442,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:29] {2218} INFO - iteration 97, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:06:32] {2391} INFO -  at 114.5s,\testimator rf's best error=326.3850,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:32] {2218} INFO - iteration 98, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:06:36] {2391} INFO -  at 117.9s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:36] {2218} INFO - iteration 99, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:06:41] {2391} INFO -  at 123.2s,\testimator rf's best error=325.1574,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:41] {2218} INFO - iteration 100, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:42] {2391} INFO -  at 124.6s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:42] {2218} INFO - iteration 101, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:43] {2391} INFO -  at 124.8s,\testimator xgb_limitdepth's best error=333.3793,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:43] {2218} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:43] {2391} INFO -  at 125.2s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:43] {2218} INFO - iteration 103, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:43] {2391} INFO -  at 125.4s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:43] {2218} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:43] {2391} INFO -  at 125.6s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:43] {2218} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:44] {2391} INFO -  at 125.8s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:44] {2218} INFO - iteration 106, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:46] {2391} INFO -  at 127.6s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:46] {2218} INFO - iteration 107, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:46] {2391} INFO -  at 128.3s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:46] {2218} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:46] {2391} INFO -  at 128.5s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:46] {2218} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:06:48] {2391} INFO -  at 129.7s,\testimator extra_tree's best error=319.3442,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:48] {2218} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:48] {2391} INFO -  at 129.9s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:48] {2218} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:49] {2391} INFO -  at 130.8s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:49] {2218} INFO - iteration 112, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:49] {2391} INFO -  at 131.2s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:49] {2218} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:49] {2391} INFO -  at 131.4s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:49] {2218} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:50] {2391} INFO -  at 132.6s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:50] {2218} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:51] {2391} INFO -  at 133.0s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:51] {2218} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:51] {2391} INFO -  at 133.4s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:51] {2218} INFO - iteration 117, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:52] {2391} INFO -  at 134.3s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:52] {2218} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:52] {2391} INFO -  at 134.6s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:52] {2218} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:54] {2391} INFO -  at 135.7s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:54] {2218} INFO - iteration 120, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:54] {2391} INFO -  at 136.1s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:54] {2218} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:54] {2391} INFO -  at 136.3s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:54] {2218} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:54] {2391} INFO -  at 136.6s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:54] {2218} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:55] {2391} INFO -  at 137.0s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:55] {2218} INFO - iteration 124, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:06:57] {2391} INFO -  at 138.7s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:57] {2218} INFO - iteration 125, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:57] {2391} INFO -  at 138.9s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:57] {2218} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:58] {2391} INFO -  at 139.7s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:58] {2218} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:59] {2391} INFO -  at 140.7s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:59] {2218} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:06:59] {2391} INFO -  at 140.9s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:06:59] {2218} INFO - iteration 129, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:07:02] {2391} INFO -  at 144.1s,\testimator rf's best error=325.1574,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:02] {2218} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:07:02] {2391} INFO -  at 144.3s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:02] {2218} INFO - iteration 131, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:07:05] {2391} INFO -  at 147.3s,\testimator extra_tree's best error=318.5533,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:05] {2218} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:07:07] {2391} INFO -  at 149.1s,\testimator extra_tree's best error=318.5533,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:07] {2218} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:07:07] {2391} INFO -  at 149.4s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:07] {2218} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:08] {2391} INFO -  at 150.6s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:08] {2218} INFO - iteration 135, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:07:11] {2391} INFO -  at 152.7s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:11] {2218} INFO - iteration 136, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:07:11] {2391} INFO -  at 153.3s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:11] {2218} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:07:11] {2391} INFO -  at 153.6s,\testimator xgb_limitdepth's best error=320.6676,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:11] {2218} INFO - iteration 138, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:07:17] {2391} INFO -  at 159.3s,\testimator extra_tree's best error=318.4289,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:17] {2218} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:17] {2391} INFO -  at 159.5s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:17] {2218} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:07:18] {2391} INFO -  at 160.0s,\testimator xgb_limitdepth's best error=319.3298,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:18] {2218} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:18] {2391} INFO -  at 160.4s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:18] {2218} INFO - iteration 142, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:18] {2391} INFO -  at 160.6s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:18] {2218} INFO - iteration 143, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:19] {2391} INFO -  at 160.9s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:19] {2218} INFO - iteration 144, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:19] {2391} INFO -  at 161.2s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:19] {2218} INFO - iteration 145, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:21] {2391} INFO -  at 163.4s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:21] {2218} INFO - iteration 146, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:07:24] {2391} INFO -  at 165.9s,\testimator catboost's best error=316.2325,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:24] {2218} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:24] {2391} INFO -  at 166.6s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:24] {2218} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:25] {2391} INFO -  at 167.3s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:25] {2218} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:26] {2391} INFO -  at 167.6s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:26] {2218} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:26] {2391} INFO -  at 168.2s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:26] {2218} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:27] {2391} INFO -  at 168.7s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:27] {2218} INFO - iteration 152, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:27] {2391} INFO -  at 169.0s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:27] {2218} INFO - iteration 153, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:27] {2391} INFO -  at 169.5s,\testimator xgboost's best error=331.9281,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:27] {2218} INFO - iteration 154, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:07:38] {2391} INFO -  at 180.6s,\testimator catboost's best error=315.9494,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:38] {2218} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:39] {2391} INFO -  at 181.2s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:39] {2218} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:39] {2391} INFO -  at 181.5s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:39] {2218} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:07:40] {2391} INFO -  at 182.0s,\testimator xgb_limitdepth's best error=319.3298,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:40] {2218} INFO - iteration 158, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:41] {2391} INFO -  at 182.9s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:41] {2218} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:41] {2391} INFO -  at 183.2s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:41] {2218} INFO - iteration 160, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:41] {2391} INFO -  at 183.6s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:41] {2218} INFO - iteration 161, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:43] {2391} INFO -  at 184.7s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:43] {2218} INFO - iteration 162, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:43] {2391} INFO -  at 185.1s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:43] {2218} INFO - iteration 163, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:44] {2391} INFO -  at 186.0s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:44] {2218} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:07:44] {2391} INFO -  at 186.6s,\testimator xgb_limitdepth's best error=319.3298,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:44] {2218} INFO - iteration 165, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:47] {2391} INFO -  at 189.0s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:47] {2218} INFO - iteration 166, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:47] {2391} INFO -  at 189.4s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:47] {2218} INFO - iteration 167, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:48] {2391} INFO -  at 189.8s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:48] {2218} INFO - iteration 168, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:49] {2391} INFO -  at 190.7s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:49] {2218} INFO - iteration 169, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:50] {2391} INFO -  at 191.8s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:50] {2218} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:50] {2391} INFO -  at 192.3s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:50] {2218} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:50] {2391} INFO -  at 192.6s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:50] {2218} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:07:51] {2391} INFO -  at 193.2s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:51] {2218} INFO - iteration 173, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:54] {2391} INFO -  at 196.1s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:54] {2218} INFO - iteration 174, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:54] {2391} INFO -  at 196.5s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:54] {2218} INFO - iteration 175, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:07:57] {2391} INFO -  at 198.9s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:07:57] {2218} INFO - iteration 176, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:08:02] {2391} INFO -  at 204.5s,\testimator rf's best error=325.1574,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:02] {2218} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:04] {2391} INFO -  at 205.9s,\testimator xgb_limitdepth's best error=319.3298,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:04] {2218} INFO - iteration 178, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:04] {2391} INFO -  at 206.4s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:04] {2218} INFO - iteration 179, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:08] {2391} INFO -  at 210.4s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:08] {2218} INFO - iteration 180, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:09] {2391} INFO -  at 210.7s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:09] {2218} INFO - iteration 181, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:09] {2391} INFO -  at 211.3s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:09] {2218} INFO - iteration 182, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:10] {2391} INFO -  at 212.6s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:10] {2218} INFO - iteration 183, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:08:11] {2391} INFO -  at 213.0s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:11] {2218} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:08:12] {2391} INFO -  at 213.7s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:12] {2218} INFO - iteration 185, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:08:15] {2391} INFO -  at 217.6s,\testimator rf's best error=325.1574,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:15] {2218} INFO - iteration 186, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:16] {2391} INFO -  at 218.0s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:16] {2218} INFO - iteration 187, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:08:16] {2391} INFO -  at 218.3s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:16] {2218} INFO - iteration 188, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:19] {2391} INFO -  at 221.6s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:19] {2218} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:08:20] {2391} INFO -  at 222.0s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:20] {2218} INFO - iteration 190, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:08:20] {2391} INFO -  at 222.4s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:20] {2218} INFO - iteration 191, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:21] {2391} INFO -  at 222.9s,\testimator xgboost's best error=318.3222,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:21] {2218} INFO - iteration 192, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:08:22] {2391} INFO -  at 223.9s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:22] {2218} INFO - iteration 193, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:24] {2391} INFO -  at 225.8s,\testimator xgboost's best error=317.2078,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:24] {2218} INFO - iteration 194, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:08:24] {2391} INFO -  at 226.0s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:24] {2218} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:24] {2391} INFO -  at 226.3s,\testimator xgb_limitdepth's best error=319.3298,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:24] {2218} INFO - iteration 196, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:08:24] {2391} INFO -  at 226.4s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:24] {2218} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:08:28] {2391} INFO -  at 229.7s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:28] {2218} INFO - iteration 198, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:29] {2391} INFO -  at 231.3s,\testimator xgboost's best error=317.2078,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:29] {2218} INFO - iteration 199, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:08:31] {2391} INFO -  at 233.6s,\testimator xgboost's best error=317.2078,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:31] {2218} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:32] {2391} INFO -  at 234.2s,\testimator xgb_limitdepth's best error=319.3298,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:32] {2218} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:33] {2391} INFO -  at 234.7s,\testimator xgb_limitdepth's best error=316.5932,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:33] {2218} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:08:33] {2391} INFO -  at 235.0s,\testimator lgbm's best error=314.4265,\tbest estimator lgbm's best error=314.4265\n",
      "[flaml.automl.logger: 11-12 20:08:33] {2218} INFO - iteration 203, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:34] {2391} INFO -  at 236.6s,\testimator xgb_limitdepth's best error=314.0676,\tbest estimator xgb_limitdepth's best error=314.0676\n",
      "[flaml.automl.logger: 11-12 20:08:34] {2218} INFO - iteration 204, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:35] {2391} INFO -  at 237.1s,\testimator xgb_limitdepth's best error=314.0676,\tbest estimator xgb_limitdepth's best error=314.0676\n",
      "[flaml.automl.logger: 11-12 20:08:35] {2218} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:38] {2391} INFO -  at 240.0s,\testimator xgb_limitdepth's best error=314.0676,\tbest estimator xgb_limitdepth's best error=314.0676\n",
      "[flaml.automl.logger: 11-12 20:08:38] {2218} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:39] {2391} INFO -  at 240.8s,\testimator xgb_limitdepth's best error=314.0676,\tbest estimator xgb_limitdepth's best error=314.0676\n",
      "[flaml.automl.logger: 11-12 20:08:39] {2218} INFO - iteration 207, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:48] {2391} INFO -  at 250.2s,\testimator xgb_limitdepth's best error=314.0676,\tbest estimator xgb_limitdepth's best error=314.0676\n",
      "[flaml.automl.logger: 11-12 20:08:48] {2218} INFO - iteration 208, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:48] {2391} INFO -  at 250.6s,\testimator xgb_limitdepth's best error=314.0676,\tbest estimator xgb_limitdepth's best error=314.0676\n",
      "[flaml.automl.logger: 11-12 20:08:48] {2218} INFO - iteration 209, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:49] {2391} INFO -  at 251.6s,\testimator xgb_limitdepth's best error=314.0676,\tbest estimator xgb_limitdepth's best error=314.0676\n",
      "[flaml.automl.logger: 11-12 20:08:49] {2218} INFO - iteration 210, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:52] {2391} INFO -  at 253.8s,\testimator xgb_limitdepth's best error=311.6356,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:08:52] {2218} INFO - iteration 211, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:08:52] {2391} INFO -  at 254.5s,\testimator xgb_limitdepth's best error=311.6356,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:08:52] {2218} INFO - iteration 212, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:09:00] {2391} INFO -  at 261.9s,\testimator xgb_limitdepth's best error=311.6356,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:09:00] {2218} INFO - iteration 213, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:09:01] {2391} INFO -  at 263.2s,\testimator xgb_limitdepth's best error=311.6356,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:09:01] {2218} INFO - iteration 214, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:09:05] {2391} INFO -  at 267.1s,\testimator xgb_limitdepth's best error=311.6356,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:09:05] {2218} INFO - iteration 215, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:09:07] {2391} INFO -  at 269.1s,\testimator xgb_limitdepth's best error=311.6356,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:09:07] {2218} INFO - iteration 216, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:09:09] {2391} INFO -  at 271.5s,\testimator xgb_limitdepth's best error=311.6356,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:09:09] {2218} INFO - iteration 217, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:09:10] {2391} INFO -  at 272.0s,\testimator xgb_limitdepth's best error=311.6356,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:09:10] {2218} INFO - iteration 218, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:09:14] {2391} INFO -  at 275.6s,\testimator rf's best error=325.1574,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:09:14] {2218} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:09:14] {2391} INFO -  at 276.1s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:09:14] {2218} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:09:14] {2391} INFO -  at 276.3s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=311.6356\n",
      "[flaml.automl.logger: 11-12 20:09:14] {2218} INFO - iteration 221, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:09:27] {2391} INFO -  at 288.9s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:09:27] {2218} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:09:28] {2391} INFO -  at 289.7s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:09:28] {2218} INFO - iteration 223, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:10:02] {2391} INFO -  at 324.3s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:10:02] {2218} INFO - iteration 224, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:10:07] {2391} INFO -  at 329.6s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:10:07] {2218} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:10:08] {2391} INFO -  at 329.8s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:10:08] {2218} INFO - iteration 226, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:10:09] {2391} INFO -  at 330.9s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:10:09] {2218} INFO - iteration 227, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:10:11] {2391} INFO -  at 333.4s,\testimator extra_tree's best error=318.4289,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:10:11] {2218} INFO - iteration 228, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:10:12] {2391} INFO -  at 334.1s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:10:12] {2218} INFO - iteration 229, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:10:32] {2391} INFO -  at 354.2s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:10:32] {2218} INFO - iteration 230, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:10:33] {2391} INFO -  at 354.8s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:10:33] {2218} INFO - iteration 231, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:10:40] {2391} INFO -  at 362.6s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:10:40] {2218} INFO - iteration 232, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:10:59] {2391} INFO -  at 380.8s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:10:59] {2218} INFO - iteration 233, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:11:07] {2391} INFO -  at 389.2s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:11:07] {2218} INFO - iteration 234, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:11:51] {2391} INFO -  at 433.0s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:11:51] {2218} INFO - iteration 235, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:11:55] {2391} INFO -  at 436.6s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:11:55] {2218} INFO - iteration 236, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:12:07] {2391} INFO -  at 448.9s,\testimator catboost's best error=315.2590,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:12:07] {2218} INFO - iteration 237, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:12:14] {2391} INFO -  at 455.9s,\testimator catboost's best error=314.5636,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:12:14] {2218} INFO - iteration 238, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:12:29] {2391} INFO -  at 471.1s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:12:29] {2218} INFO - iteration 239, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:12:41] {2391} INFO -  at 483.4s,\testimator catboost's best error=314.5636,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:12:41] {2218} INFO - iteration 240, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:12:51] {2391} INFO -  at 493.0s,\testimator catboost's best error=312.8698,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:12:51] {2218} INFO - iteration 241, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:12:58] {2391} INFO -  at 499.9s,\testimator catboost's best error=312.8698,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:12:58] {2218} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:12:58] {2391} INFO -  at 500.2s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:12:58] {2218} INFO - iteration 243, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:13:30] {2391} INFO -  at 531.8s,\testimator catboost's best error=312.8698,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:13:30] {2218} INFO - iteration 244, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:13:36] {2391} INFO -  at 537.9s,\testimator catboost's best error=312.8698,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:13:36] {2218} INFO - iteration 245, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:13:47] {2391} INFO -  at 549.6s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:13:47] {2218} INFO - iteration 246, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:13:53] {2391} INFO -  at 554.8s,\testimator rf's best error=322.5125,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:13:53] {2218} INFO - iteration 247, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:13:58] {2391} INFO -  at 560.3s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:13:58] {2218} INFO - iteration 248, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:14:06] {2391} INFO -  at 567.8s,\testimator catboost's best error=312.8698,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:14:06] {2218} INFO - iteration 249, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:14:06] {2391} INFO -  at 568.3s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:14:06] {2218} INFO - iteration 250, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:14:34] {2391} INFO -  at 596.6s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:14:34] {2218} INFO - iteration 251, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:14:50] {2391} INFO -  at 611.9s,\testimator catboost's best error=312.4900,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:14:50] {2218} INFO - iteration 252, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:14:50] {2391} INFO -  at 612.2s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:14:50] {2218} INFO - iteration 253, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:14:54] {2391} INFO -  at 616.1s,\testimator rf's best error=322.5125,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:14:54] {2218} INFO - iteration 254, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:15:02] {2391} INFO -  at 623.8s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:15:02] {2218} INFO - iteration 255, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:15:06] {2391} INFO -  at 627.7s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:15:06] {2218} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:15:06] {2391} INFO -  at 628.0s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:15:06] {2218} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:15:44] {2391} INFO -  at 666.1s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:15:44] {2218} INFO - iteration 258, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:15:51] {2391} INFO -  at 673.1s,\testimator rf's best error=322.2414,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:15:51] {2218} INFO - iteration 259, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:16:18] {2391} INFO -  at 700.0s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:16:18] {2218} INFO - iteration 260, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:16:22] {2391} INFO -  at 704.2s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:16:22] {2218} INFO - iteration 261, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:16:28] {2391} INFO -  at 710.6s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:16:28] {2218} INFO - iteration 262, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:16:37] {2391} INFO -  at 718.7s,\testimator catboost's best error=312.4900,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:16:37] {2218} INFO - iteration 263, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:16:37] {2391} INFO -  at 719.5s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:16:37] {2218} INFO - iteration 264, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:16:38] {2391} INFO -  at 720.2s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:16:38] {2218} INFO - iteration 265, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:16:47] {2391} INFO -  at 729.1s,\testimator catboost's best error=312.4900,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:16:47] {2218} INFO - iteration 266, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:17:00] {2391} INFO -  at 742.5s,\testimator extra_tree's best error=317.7185,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:17:00] {2218} INFO - iteration 267, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:17:38] {2391} INFO -  at 780.1s,\testimator xgb_limitdepth's best error=310.5988,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:17:38] {2218} INFO - iteration 268, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:17:46] {2391} INFO -  at 788.2s,\testimator extra_tree's best error=317.7185,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:17:46] {2218} INFO - iteration 269, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:18:04] {2391} INFO -  at 806.6s,\testimator extra_tree's best error=317.0293,\tbest estimator xgb_limitdepth's best error=310.5988\n",
      "[flaml.automl.logger: 11-12 20:18:04] {2218} INFO - iteration 270, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:18:09] {2391} INFO -  at 810.8s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:09] {2218} INFO - iteration 271, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:18:09] {2391} INFO -  at 811.6s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:10] {2218} INFO - iteration 272, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:18:18] {2391} INFO -  at 820.4s,\testimator extra_tree's best error=317.0293,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:18] {2218} INFO - iteration 273, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:18:23] {2391} INFO -  at 824.7s,\testimator rf's best error=322.2414,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:23] {2218} INFO - iteration 274, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:18:23] {2391} INFO -  at 825.0s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:23] {2218} INFO - iteration 275, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:18:39] {2391} INFO -  at 841.2s,\testimator rf's best error=322.2414,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:39] {2218} INFO - iteration 276, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:18:39] {2391} INFO -  at 841.4s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:39] {2218} INFO - iteration 277, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:18:41] {2391} INFO -  at 843.0s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:41] {2218} INFO - iteration 278, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:18:45] {2391} INFO -  at 847.4s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:45] {2218} INFO - iteration 279, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:18:50] {2391} INFO -  at 851.9s,\testimator rf's best error=322.2414,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:50] {2218} INFO - iteration 280, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:18:52] {2391} INFO -  at 853.8s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:18:52] {2218} INFO - iteration 281, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:19:34] {2391} INFO -  at 895.9s,\testimator extra_tree's best error=316.5789,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:19:34] {2218} INFO - iteration 282, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:19:34] {2391} INFO -  at 896.6s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:19:34] {2218} INFO - iteration 283, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:19:49] {2391} INFO -  at 911.0s,\testimator rf's best error=322.2414,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:19:49] {2218} INFO - iteration 284, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:19:49] {2391} INFO -  at 911.3s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:19:49] {2218} INFO - iteration 285, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:19:58] {2391} INFO -  at 920.4s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:19:58] {2218} INFO - iteration 286, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:19:59] {2391} INFO -  at 920.9s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:19:59] {2218} INFO - iteration 287, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:20:44] {2391} INFO -  at 966.2s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:20:44] {2218} INFO - iteration 288, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:22:54] {2391} INFO -  at 1096.4s,\testimator extra_tree's best error=316.0479,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:22:54] {2218} INFO - iteration 289, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:22:55] {2391} INFO -  at 1096.7s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:22:55] {2218} INFO - iteration 290, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:22:55] {2391} INFO -  at 1097.4s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:22:55] {2218} INFO - iteration 291, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:22:59] {2391} INFO -  at 1101.2s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:22:59] {2218} INFO - iteration 292, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:23:00] {2391} INFO -  at 1102.0s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:00] {2218} INFO - iteration 293, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:23:04] {2391} INFO -  at 1106.1s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:04] {2218} INFO - iteration 294, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:23:06] {2391} INFO -  at 1108.4s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:06] {2218} INFO - iteration 295, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:23:08] {2391} INFO -  at 1110.6s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:08] {2218} INFO - iteration 296, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:23:24] {2391} INFO -  at 1126.2s,\testimator catboost's best error=312.4900,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:24] {2218} INFO - iteration 297, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:23:32] {2391} INFO -  at 1133.9s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:32] {2218} INFO - iteration 298, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:23:33] {2391} INFO -  at 1135.5s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:33] {2218} INFO - iteration 299, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:23:41] {2391} INFO -  at 1142.7s,\testimator catboost's best error=312.4900,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:41] {2218} INFO - iteration 300, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:23:41] {2391} INFO -  at 1143.0s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:41] {2218} INFO - iteration 301, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:23:41] {2391} INFO -  at 1143.6s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:41] {2218} INFO - iteration 302, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:23:42] {2391} INFO -  at 1144.0s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:42] {2218} INFO - iteration 303, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:23:42] {2391} INFO -  at 1144.3s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:42] {2218} INFO - iteration 304, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:23:53] {2391} INFO -  at 1155.1s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:53] {2218} INFO - iteration 305, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:23:53] {2391} INFO -  at 1155.5s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:53] {2218} INFO - iteration 306, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:23:55] {2391} INFO -  at 1157.1s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:55] {2218} INFO - iteration 307, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:23:59] {2391} INFO -  at 1160.7s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:23:59] {2218} INFO - iteration 308, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:24:03] {2391} INFO -  at 1165.6s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:24:03] {2218} INFO - iteration 309, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:24:12] {2391} INFO -  at 1174.5s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:24:12] {2218} INFO - iteration 310, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:24:13] {2391} INFO -  at 1175.0s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:24:13] {2218} INFO - iteration 311, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:24:21] {2391} INFO -  at 1183.3s,\testimator catboost's best error=312.4900,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:24:21] {2218} INFO - iteration 312, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:24:21] {2391} INFO -  at 1183.6s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:24:21] {2218} INFO - iteration 313, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:24:22] {2391} INFO -  at 1184.5s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:24:22] {2218} INFO - iteration 314, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:24:23] {2391} INFO -  at 1185.0s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:24:23] {2218} INFO - iteration 315, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:24:24] {2391} INFO -  at 1186.1s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:24:24] {2218} INFO - iteration 316, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:24:24] {2391} INFO -  at 1186.5s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:24:24] {2218} INFO - iteration 317, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:25:17] {2391} INFO -  at 1239.2s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:17] {2218} INFO - iteration 318, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:25:17] {2391} INFO -  at 1239.5s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:17] {2218} INFO - iteration 319, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:25:19] {2391} INFO -  at 1241.3s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:19] {2218} INFO - iteration 320, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:25:19] {2391} INFO -  at 1241.5s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:19] {2218} INFO - iteration 321, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:25:26] {2391} INFO -  at 1247.8s,\testimator catboost's best error=312.4900,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:26] {2218} INFO - iteration 322, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:25:46] {2391} INFO -  at 1268.2s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:46] {2218} INFO - iteration 323, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:25:47] {2391} INFO -  at 1268.8s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:47] {2218} INFO - iteration 324, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:25:47] {2391} INFO -  at 1269.1s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:47] {2218} INFO - iteration 325, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:25:48] {2391} INFO -  at 1270.0s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:48] {2218} INFO - iteration 326, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:25:49] {2391} INFO -  at 1270.8s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:49] {2218} INFO - iteration 327, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:25:50] {2391} INFO -  at 1272.1s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:50] {2218} INFO - iteration 328, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:25:50] {2391} INFO -  at 1272.3s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:50] {2218} INFO - iteration 329, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:25:51] {2391} INFO -  at 1272.8s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:51] {2218} INFO - iteration 330, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:25:53] {2391} INFO -  at 1275.2s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:53] {2218} INFO - iteration 331, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:25:59] {2391} INFO -  at 1281.6s,\testimator catboost's best error=312.4900,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:25:59] {2218} INFO - iteration 332, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:26:00] {2391} INFO -  at 1281.9s,\testimator lgbm's best error=314.4265,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:26:00] {2218} INFO - iteration 333, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:26:38] {2391} INFO -  at 1319.8s,\testimator extra_tree's best error=315.4868,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:26:38] {2218} INFO - iteration 334, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:26:39] {2391} INFO -  at 1320.8s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:26:39] {2218} INFO - iteration 335, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:27:03] {2391} INFO -  at 1344.9s,\testimator extra_tree's best error=315.4868,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:03] {2218} INFO - iteration 336, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:27:04] {2391} INFO -  at 1345.8s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:04] {2218} INFO - iteration 337, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:27:05] {2391} INFO -  at 1346.8s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:05] {2218} INFO - iteration 338, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:27:05] {2391} INFO -  at 1347.6s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:05] {2218} INFO - iteration 339, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:27:09] {2391} INFO -  at 1351.2s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:09] {2218} INFO - iteration 340, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:27:34] {2391} INFO -  at 1375.9s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:34] {2218} INFO - iteration 341, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:27:35] {2391} INFO -  at 1376.8s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:35] {2218} INFO - iteration 342, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:27:35] {2391} INFO -  at 1377.1s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:35] {2218} INFO - iteration 343, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:27:48] {2391} INFO -  at 1389.8s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:48] {2218} INFO - iteration 344, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:27:49] {2391} INFO -  at 1391.3s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:49] {2218} INFO - iteration 345, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:27:50] {2391} INFO -  at 1391.9s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:50] {2218} INFO - iteration 346, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:27:53] {2391} INFO -  at 1394.8s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:53] {2218} INFO - iteration 347, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:27:59] {2391} INFO -  at 1401.0s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:27:59] {2218} INFO - iteration 348, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:28:04] {2391} INFO -  at 1405.8s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:28:04] {2218} INFO - iteration 349, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:28:07] {2391} INFO -  at 1409.3s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:28:07] {2218} INFO - iteration 350, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:28:09] {2391} INFO -  at 1411.0s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:28:09] {2218} INFO - iteration 351, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:28:26] {2391} INFO -  at 1428.1s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:28:26] {2218} INFO - iteration 352, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:28:27] {2391} INFO -  at 1429.2s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:28:27] {2218} INFO - iteration 353, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:29:16] {2391} INFO -  at 1478.5s,\testimator extra_tree's best error=315.4868,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:29:16] {2218} INFO - iteration 354, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:29:24] {2391} INFO -  at 1485.9s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:29:24] {2218} INFO - iteration 355, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:29:24] {2391} INFO -  at 1486.6s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:29:24] {2218} INFO - iteration 356, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:29:27] {2391} INFO -  at 1488.9s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:29:27] {2218} INFO - iteration 357, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:29:28] {2391} INFO -  at 1490.0s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:29:28] {2218} INFO - iteration 358, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:29:29] {2391} INFO -  at 1490.8s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:29:29] {2218} INFO - iteration 359, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:29:29] {2391} INFO -  at 1491.1s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:29:29] {2218} INFO - iteration 360, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:30:21] {2391} INFO -  at 1542.9s,\testimator extra_tree's best error=315.4868,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:30:21] {2218} INFO - iteration 361, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:30:24] {2391} INFO -  at 1545.9s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:30:24] {2218} INFO - iteration 362, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:30:56] {2391} INFO -  at 1578.1s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:30:56] {2218} INFO - iteration 363, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:31:11] {2391} INFO -  at 1592.7s,\testimator catboost's best error=312.4900,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:31:11] {2218} INFO - iteration 364, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:31:16] {2391} INFO -  at 1598.0s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:31:16] {2218} INFO - iteration 365, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:31:28] {2391} INFO -  at 1610.0s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:31:28] {2218} INFO - iteration 366, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:31:28] {2391} INFO -  at 1610.5s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:31:28] {2218} INFO - iteration 367, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:31:30] {2391} INFO -  at 1612.2s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:31:30] {2218} INFO - iteration 368, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:31:33] {2391} INFO -  at 1615.5s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:31:33] {2218} INFO - iteration 369, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:31:41] {2391} INFO -  at 1622.6s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:31:41] {2218} INFO - iteration 370, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:31:45] {2391} INFO -  at 1627.6s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:31:45] {2218} INFO - iteration 371, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:31:57] {2391} INFO -  at 1639.0s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:31:57] {2218} INFO - iteration 372, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:31:59] {2391} INFO -  at 1640.7s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:31:59] {2218} INFO - iteration 373, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:32:02] {2391} INFO -  at 1643.8s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:02] {2218} INFO - iteration 374, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:32:03] {2391} INFO -  at 1644.9s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:03] {2218} INFO - iteration 375, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:32:04] {2391} INFO -  at 1645.7s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:04] {2218} INFO - iteration 376, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:32:04] {2391} INFO -  at 1646.3s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:04] {2218} INFO - iteration 377, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:32:05] {2391} INFO -  at 1647.2s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:05] {2218} INFO - iteration 378, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:32:06] {2391} INFO -  at 1647.7s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:06] {2218} INFO - iteration 379, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:32:08] {2391} INFO -  at 1650.2s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:08] {2218} INFO - iteration 380, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:32:08] {2391} INFO -  at 1650.6s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:08] {2218} INFO - iteration 381, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:32:11] {2391} INFO -  at 1653.3s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:11] {2218} INFO - iteration 382, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:32:17] {2391} INFO -  at 1659.3s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:17] {2218} INFO - iteration 383, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:32:21] {2391} INFO -  at 1663.0s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:21] {2218} INFO - iteration 384, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:32:25] {2391} INFO -  at 1666.9s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:25] {2218} INFO - iteration 385, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:32:25] {2391} INFO -  at 1667.2s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:25] {2218} INFO - iteration 386, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:32:35] {2391} INFO -  at 1677.0s,\testimator catboost's best error=312.4900,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:32:35] {2218} INFO - iteration 387, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:33:00] {2391} INFO -  at 1702.0s,\testimator extra_tree's best error=315.4868,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:33:00] {2218} INFO - iteration 388, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:33:10] {2391} INFO -  at 1712.2s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:33:10] {2218} INFO - iteration 389, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:33:14] {2391} INFO -  at 1715.9s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:33:14] {2218} INFO - iteration 390, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:33:14] {2391} INFO -  at 1716.5s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:33:14] {2218} INFO - iteration 391, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:33:16] {2391} INFO -  at 1718.0s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:33:16] {2218} INFO - iteration 392, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:33:18] {2391} INFO -  at 1719.9s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:33:18] {2218} INFO - iteration 393, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:33:25] {2391} INFO -  at 1727.0s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:33:25] {2218} INFO - iteration 394, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:33:26] {2391} INFO -  at 1727.7s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:33:26] {2218} INFO - iteration 395, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:33:26] {2391} INFO -  at 1728.3s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:33:26] {2218} INFO - iteration 396, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:33:27] {2391} INFO -  at 1729.1s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:33:27] {2218} INFO - iteration 397, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:34:07] {2391} INFO -  at 1769.4s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:34:07] {2218} INFO - iteration 398, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:08] {2391} INFO -  at 1770.1s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:34:08] {2218} INFO - iteration 399, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:09] {2391} INFO -  at 1770.7s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:34:09] {2218} INFO - iteration 400, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:34:09] {2391} INFO -  at 1771.6s,\testimator xgboost's best error=317.2078,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:34:09] {2218} INFO - iteration 401, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:34:10] {2391} INFO -  at 1772.1s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:34:10] {2218} INFO - iteration 402, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:16] {2391} INFO -  at 1777.7s,\testimator lgbm's best error=312.8840,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:34:16] {2218} INFO - iteration 403, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:34:16] {2391} INFO -  at 1778.6s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:34:16] {2218} INFO - iteration 404, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:34:20] {2391} INFO -  at 1782.6s,\testimator xgboost's best error=316.5309,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:34:20] {2218} INFO - iteration 405, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:34:21] {2391} INFO -  at 1783.1s,\testimator xgboost's best error=316.5309,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:34:21] {2218} INFO - iteration 406, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:34:38] {2391} INFO -  at 1799.9s,\testimator xgb_limitdepth's best error=309.1906,\tbest estimator xgb_limitdepth's best error=309.1906\n",
      "[flaml.automl.logger: 11-12 20:34:38] {2493} INFO - selected model: XGBRegressor(base_score=None, booster=None, callbacks=[],\n",
      "             colsample_bylevel=0.8739309022559869, colsample_bynode=None,\n",
      "             colsample_bytree=0.8148494129779046, device=None,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.017836142105572647, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "             min_child_weight=0.07451980054061333, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=589,\n",
      "             n_jobs=-1, num_parallel_tree=None, random_state=None, ...)\n",
      "[flaml.automl.logger: 11-12 20:34:38] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-12 20:34:38] {1931} INFO - Time taken to find the best model: 810.8299508094788\n",
      "[flaml.automl.logger: 11-12 20:34:57] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 11-12 20:34:57] {1687} INFO - Data split method: uniform\n",
      "[flaml.automl.logger: 11-12 20:34:57] {1690} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 11-12 20:34:57] {1788} INFO - Minimizing error metric: mae\n",
      "[flaml.automl.logger: 11-12 20:34:57] {1900} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2218} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2344} INFO - Estimated sufficient time budget=1456s. Estimated necessary time budget=12s.\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2391} INFO -  at 1.0s,\testimator lgbm's best error=173.3460,\tbest estimator lgbm's best error=173.3460\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2218} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2391} INFO -  at 1.1s,\testimator lgbm's best error=155.8314,\tbest estimator lgbm's best error=155.8314\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2218} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2391} INFO -  at 1.3s,\testimator lgbm's best error=155.8314,\tbest estimator lgbm's best error=155.8314\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2218} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2391} INFO -  at 1.4s,\testimator lgbm's best error=152.3728,\tbest estimator lgbm's best error=152.3728\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2218} INFO - iteration 4, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2391} INFO -  at 1.5s,\testimator xgboost's best error=173.6956,\tbest estimator lgbm's best error=152.3728\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2218} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2391} INFO -  at 1.7s,\testimator lgbm's best error=111.8476,\tbest estimator lgbm's best error=111.8476\n",
      "[flaml.automl.logger: 11-12 20:34:57] {2218} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2391} INFO -  at 1.8s,\testimator lgbm's best error=78.0171,\tbest estimator lgbm's best error=78.0171\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2218} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2391} INFO -  at 2.0s,\testimator lgbm's best error=78.0171,\tbest estimator lgbm's best error=78.0171\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2218} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2391} INFO -  at 2.1s,\testimator lgbm's best error=78.0171,\tbest estimator lgbm's best error=78.0171\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2391} INFO -  at 2.2s,\testimator xgboost's best error=156.1478,\tbest estimator lgbm's best error=78.0171\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2218} INFO - iteration 10, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2391} INFO -  at 2.4s,\testimator extra_tree's best error=83.8868,\tbest estimator lgbm's best error=78.0171\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2218} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2391} INFO -  at 2.5s,\testimator xgboost's best error=156.1478,\tbest estimator lgbm's best error=78.0171\n",
      "[flaml.automl.logger: 11-12 20:34:58] {2218} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:34:59] {2391} INFO -  at 2.8s,\testimator extra_tree's best error=83.3841,\tbest estimator lgbm's best error=78.0171\n",
      "[flaml.automl.logger: 11-12 20:34:59] {2218} INFO - iteration 13, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:34:59] {2391} INFO -  at 3.6s,\testimator rf's best error=89.5367,\tbest estimator lgbm's best error=78.0171\n",
      "[flaml.automl.logger: 11-12 20:34:59] {2218} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:34:59] {2391} INFO -  at 3.7s,\testimator lgbm's best error=71.9364,\tbest estimator lgbm's best error=71.9364\n",
      "[flaml.automl.logger: 11-12 20:34:59] {2218} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2391} INFO -  at 5.0s,\testimator rf's best error=88.7012,\tbest estimator lgbm's best error=71.9364\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2218} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2391} INFO -  at 5.1s,\testimator lgbm's best error=71.9364,\tbest estimator lgbm's best error=71.9364\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2218} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2391} INFO -  at 5.3s,\testimator xgboost's best error=156.1478,\tbest estimator lgbm's best error=71.9364\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2218} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2391} INFO -  at 5.4s,\testimator lgbm's best error=71.9364,\tbest estimator lgbm's best error=71.9364\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2218} INFO - iteration 19, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2391} INFO -  at 5.6s,\testimator lgbm's best error=71.9364,\tbest estimator lgbm's best error=71.9364\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2218} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2391} INFO -  at 5.7s,\testimator lgbm's best error=70.6582,\tbest estimator lgbm's best error=70.6582\n",
      "[flaml.automl.logger: 11-12 20:35:01] {2218} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:02] {2391} INFO -  at 5.9s,\testimator lgbm's best error=70.6582,\tbest estimator lgbm's best error=70.6582\n",
      "[flaml.automl.logger: 11-12 20:35:02] {2218} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:02] {2391} INFO -  at 6.1s,\testimator lgbm's best error=70.6582,\tbest estimator lgbm's best error=70.6582\n",
      "[flaml.automl.logger: 11-12 20:35:02] {2218} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:02] {2391} INFO -  at 6.3s,\testimator lgbm's best error=70.6582,\tbest estimator lgbm's best error=70.6582\n",
      "[flaml.automl.logger: 11-12 20:35:02] {2218} INFO - iteration 24, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:02] {2391} INFO -  at 6.4s,\testimator lgbm's best error=70.6582,\tbest estimator lgbm's best error=70.6582\n",
      "[flaml.automl.logger: 11-12 20:35:02] {2218} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:02] {2391} INFO -  at 6.7s,\testimator extra_tree's best error=74.1033,\tbest estimator lgbm's best error=70.6582\n",
      "[flaml.automl.logger: 11-12 20:35:02] {2218} INFO - iteration 26, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:03] {2391} INFO -  at 6.9s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:03] {2218} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:03] {2391} INFO -  at 7.3s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:03] {2218} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:03] {2391} INFO -  at 7.5s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:03] {2218} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:04] {2391} INFO -  at 8.0s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:04] {2218} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:04] {2391} INFO -  at 8.2s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:04] {2218} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:04] {2391} INFO -  at 8.4s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:04] {2218} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:05] {2391} INFO -  at 8.8s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:05] {2218} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:05] {2391} INFO -  at 9.0s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:05] {2218} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:05] {2391} INFO -  at 9.2s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:05] {2218} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:05] {2391} INFO -  at 9.5s,\testimator xgboost's best error=80.8189,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:05] {2218} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:06] {2391} INFO -  at 9.9s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:06] {2218} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:06] {2391} INFO -  at 10.5s,\testimator xgboost's best error=80.8189,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:06] {2218} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:06] {2391} INFO -  at 10.7s,\testimator xgboost's best error=75.8379,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:06] {2218} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:07] {2391} INFO -  at 10.8s,\testimator xgboost's best error=75.8379,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:07] {2218} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:07] {2391} INFO -  at 11.0s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:07] {2218} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:07] {2391} INFO -  at 11.5s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:07] {2218} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:07] {2391} INFO -  at 11.7s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:07] {2218} INFO - iteration 43, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:35:09] {2391} INFO -  at 13.4s,\testimator catboost's best error=71.2566,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:09] {2218} INFO - iteration 44, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:10] {2391} INFO -  at 13.8s,\testimator xgboost's best error=75.8379,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:10] {2218} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:10] {2391} INFO -  at 14.2s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:10] {2218} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:10] {2391} INFO -  at 14.4s,\testimator xgboost's best error=75.8379,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:10] {2218} INFO - iteration 47, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:35:11] {2391} INFO -  at 15.7s,\testimator catboost's best error=71.1061,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:11] {2218} INFO - iteration 48, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:12] {2391} INFO -  at 15.9s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:12] {2218} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:12] {2391} INFO -  at 16.1s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:12] {2218} INFO - iteration 50, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:12] {2391} INFO -  at 16.5s,\testimator xgboost's best error=74.4525,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:12] {2218} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:13] {2391} INFO -  at 16.9s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:13] {2218} INFO - iteration 52, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:13] {2391} INFO -  at 17.1s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:13] {2218} INFO - iteration 53, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:13] {2391} INFO -  at 17.3s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:13] {2218} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:13] {2391} INFO -  at 17.4s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:13] {2218} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:13] {2391} INFO -  at 17.6s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:13] {2218} INFO - iteration 56, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:14] {2391} INFO -  at 17.8s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:14] {2218} INFO - iteration 57, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:14] {2391} INFO -  at 18.0s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:14] {2218} INFO - iteration 58, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:14] {2391} INFO -  at 18.2s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:14] {2218} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:14] {2391} INFO -  at 18.7s,\testimator xgboost's best error=74.4525,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:14] {2218} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:15] {2391} INFO -  at 18.8s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:15] {2218} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:15] {2391} INFO -  at 19.3s,\testimator xgboost's best error=74.4525,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:15] {2218} INFO - iteration 62, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:15] {2391} INFO -  at 19.5s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:15] {2218} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:17] {2391} INFO -  at 21.6s,\testimator xgboost's best error=73.1234,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:17] {2218} INFO - iteration 64, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:18] {2391} INFO -  at 21.9s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:18] {2218} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:18] {2391} INFO -  at 22.3s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:18] {2218} INFO - iteration 66, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:35:19] {2391} INFO -  at 23.7s,\testimator catboost's best error=71.1061,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:19] {2218} INFO - iteration 67, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:20] {2391} INFO -  at 24.0s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:20] {2218} INFO - iteration 68, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:35:21] {2391} INFO -  at 25.0s,\testimator rf's best error=74.4666,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:21] {2218} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:21] {2391} INFO -  at 25.2s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:21] {2218} INFO - iteration 70, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:35:22] {2391} INFO -  at 26.3s,\testimator rf's best error=72.7419,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:22] {2218} INFO - iteration 71, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:22] {2391} INFO -  at 26.8s,\testimator xgboost's best error=73.1234,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:22] {2218} INFO - iteration 72, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:35:24] {2391} INFO -  at 28.2s,\testimator rf's best error=72.7419,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:24] {2218} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:24] {2391} INFO -  at 28.5s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:24] {2218} INFO - iteration 74, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:26] {2391} INFO -  at 29.8s,\testimator xgboost's best error=73.1234,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:26] {2218} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:26] {2391} INFO -  at 30.2s,\testimator extra_tree's best error=70.0520,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:26] {2218} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:26] {2391} INFO -  at 30.5s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:26] {2218} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:26] {2391} INFO -  at 30.7s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0520\n",
      "[flaml.automl.logger: 11-12 20:35:26] {2218} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:27] {2391} INFO -  at 30.9s,\testimator extra_tree's best error=70.0201,\tbest estimator extra_tree's best error=70.0201\n",
      "[flaml.automl.logger: 11-12 20:35:27] {2218} INFO - iteration 79, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:35:28] {2391} INFO -  at 31.9s,\testimator rf's best error=72.1834,\tbest estimator extra_tree's best error=70.0201\n",
      "[flaml.automl.logger: 11-12 20:35:28] {2218} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:28] {2391} INFO -  at 32.3s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=70.0201\n",
      "[flaml.automl.logger: 11-12 20:35:28] {2218} INFO - iteration 81, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:28] {2391} INFO -  at 32.6s,\testimator extra_tree's best error=69.6817,\tbest estimator extra_tree's best error=69.6817\n",
      "[flaml.automl.logger: 11-12 20:35:28] {2218} INFO - iteration 82, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:29] {2391} INFO -  at 32.9s,\testimator extra_tree's best error=69.6817,\tbest estimator extra_tree's best error=69.6817\n",
      "[flaml.automl.logger: 11-12 20:35:29] {2218} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:29] {2391} INFO -  at 33.3s,\testimator extra_tree's best error=69.6817,\tbest estimator extra_tree's best error=69.6817\n",
      "[flaml.automl.logger: 11-12 20:35:29] {2218} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:29] {2391} INFO -  at 33.7s,\testimator extra_tree's best error=69.6817,\tbest estimator extra_tree's best error=69.6817\n",
      "[flaml.automl.logger: 11-12 20:35:29] {2218} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:30] {2391} INFO -  at 34.2s,\testimator extra_tree's best error=69.6525,\tbest estimator extra_tree's best error=69.6525\n",
      "[flaml.automl.logger: 11-12 20:35:30] {2218} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:30] {2391} INFO -  at 34.5s,\testimator extra_tree's best error=69.5768,\tbest estimator extra_tree's best error=69.5768\n",
      "[flaml.automl.logger: 11-12 20:35:30] {2218} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:31] {2391} INFO -  at 35.0s,\testimator extra_tree's best error=69.5768,\tbest estimator extra_tree's best error=69.5768\n",
      "[flaml.automl.logger: 11-12 20:35:31] {2218} INFO - iteration 88, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:31] {2391} INFO -  at 35.4s,\testimator extra_tree's best error=69.5768,\tbest estimator extra_tree's best error=69.5768\n",
      "[flaml.automl.logger: 11-12 20:35:31] {2218} INFO - iteration 89, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:32] {2391} INFO -  at 35.9s,\testimator extra_tree's best error=69.5768,\tbest estimator extra_tree's best error=69.5768\n",
      "[flaml.automl.logger: 11-12 20:35:32] {2218} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:32] {2391} INFO -  at 36.4s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:32] {2218} INFO - iteration 91, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:33] {2391} INFO -  at 36.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:33] {2218} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:33] {2391} INFO -  at 37.4s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:33] {2218} INFO - iteration 93, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:34] {2391} INFO -  at 37.9s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:34] {2218} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:34] {2391} INFO -  at 38.5s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:34] {2218} INFO - iteration 95, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:35:36] {2391} INFO -  at 40.3s,\testimator rf's best error=71.4177,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:36] {2218} INFO - iteration 96, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:36] {2391} INFO -  at 40.7s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:36] {2218} INFO - iteration 97, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:37] {2391} INFO -  at 41.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:37] {2218} INFO - iteration 98, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:38] {2391} INFO -  at 41.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:38] {2218} INFO - iteration 99, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:35:42] {2391} INFO -  at 45.8s,\testimator xgboost's best error=73.1234,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:42] {2218} INFO - iteration 100, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:35:43] {2391} INFO -  at 47.2s,\testimator rf's best error=71.4177,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:43] {2218} INFO - iteration 101, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:44] {2391} INFO -  at 47.9s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:44] {2218} INFO - iteration 102, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:44] {2391} INFO -  at 48.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:44] {2218} INFO - iteration 103, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:44] {2391} INFO -  at 48.5s,\testimator lgbm's best error=70.6582,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:44] {2218} INFO - iteration 104, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:45] {2391} INFO -  at 48.9s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:45] {2218} INFO - iteration 105, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:35:47] {2391} INFO -  at 51.4s,\testimator rf's best error=71.4177,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:47] {2218} INFO - iteration 106, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:48] {2391} INFO -  at 52.0s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:48] {2218} INFO - iteration 107, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:48] {2391} INFO -  at 52.5s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:48] {2218} INFO - iteration 108, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:35:51] {2391} INFO -  at 55.1s,\testimator catboost's best error=71.1061,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:51] {2218} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:51] {2391} INFO -  at 55.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:51] {2218} INFO - iteration 110, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:52] {2391} INFO -  at 56.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:52] {2218} INFO - iteration 111, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:52] {2391} INFO -  at 56.5s,\testimator lgbm's best error=70.2960,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:52] {2218} INFO - iteration 112, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:53] {2391} INFO -  at 57.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:53] {2218} INFO - iteration 113, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:53] {2391} INFO -  at 57.7s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:53] {2218} INFO - iteration 114, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:54] {2391} INFO -  at 58.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:54] {2218} INFO - iteration 115, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:35:55] {2391} INFO -  at 59.5s,\testimator rf's best error=71.4177,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:55] {2218} INFO - iteration 116, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:35:55] {2391} INFO -  at 59.6s,\testimator lgbm's best error=70.2960,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:55] {2218} INFO - iteration 117, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:56] {2391} INFO -  at 60.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:56] {2218} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:35:56] {2391} INFO -  at 60.5s,\testimator xgb_limitdepth's best error=74.3243,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:56] {2218} INFO - iteration 119, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:35:56] {2391} INFO -  at 60.7s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:56] {2218} INFO - iteration 120, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:35:57] {2391} INFO -  at 61.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:57] {2218} INFO - iteration 121, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:35:57] {2391} INFO -  at 61.5s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:57] {2218} INFO - iteration 122, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:35:57] {2391} INFO -  at 61.6s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:57] {2218} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:35:59] {2391} INFO -  at 63.1s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:59] {2218} INFO - iteration 124, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:35:59] {2391} INFO -  at 63.7s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:35:59] {2218} INFO - iteration 125, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:36:03] {2391} INFO -  at 66.8s,\testimator rf's best error=70.7076,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:03] {2218} INFO - iteration 126, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:04] {2391} INFO -  at 67.8s,\testimator lgbm's best error=70.2960,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:04] {2218} INFO - iteration 127, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:04] {2391} INFO -  at 68.2s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:04] {2218} INFO - iteration 128, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:05] {2391} INFO -  at 68.9s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:05] {2218} INFO - iteration 129, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:05] {2391} INFO -  at 69.3s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:05] {2218} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:05] {2391} INFO -  at 69.4s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:05] {2218} INFO - iteration 131, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:06] {2391} INFO -  at 70.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:06] {2218} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:06] {2391} INFO -  at 70.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:06] {2218} INFO - iteration 133, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:06] {2391} INFO -  at 70.7s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:06] {2218} INFO - iteration 134, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:07] {2391} INFO -  at 71.0s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:07] {2218} INFO - iteration 135, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:36:11] {2391} INFO -  at 74.8s,\testimator rf's best error=70.4979,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:11] {2218} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:11] {2391} INFO -  at 75.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:11] {2218} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:12] {2391} INFO -  at 76.1s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:12] {2218} INFO - iteration 138, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:12] {2391} INFO -  at 76.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:12] {2218} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:13] {2391} INFO -  at 77.3s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:13] {2218} INFO - iteration 140, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:13] {2391} INFO -  at 77.5s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:13] {2218} INFO - iteration 141, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:14] {2391} INFO -  at 78.4s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:14] {2218} INFO - iteration 142, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:15] {2391} INFO -  at 79.4s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:15] {2218} INFO - iteration 143, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:36:39] {2391} INFO -  at 103.6s,\testimator xgboost's best error=72.4405,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:39] {2218} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:40] {2391} INFO -  at 103.9s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:40] {2218} INFO - iteration 145, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:40] {2391} INFO -  at 104.2s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:40] {2218} INFO - iteration 146, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:41] {2391} INFO -  at 104.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:41] {2218} INFO - iteration 147, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:41] {2391} INFO -  at 105.0s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:41] {2218} INFO - iteration 148, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:42] {2391} INFO -  at 106.3s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:42] {2218} INFO - iteration 149, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:42] {2391} INFO -  at 106.6s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:42] {2218} INFO - iteration 150, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:43] {2391} INFO -  at 107.1s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:43] {2218} INFO - iteration 151, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:43] {2391} INFO -  at 107.4s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:43] {2218} INFO - iteration 152, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:36:46] {2391} INFO -  at 109.8s,\testimator rf's best error=70.4979,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:46] {2218} INFO - iteration 153, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:46] {2391} INFO -  at 110.7s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:46] {2218} INFO - iteration 154, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:47] {2391} INFO -  at 111.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:47] {2218} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:47] {2391} INFO -  at 111.6s,\testimator lgbm's best error=69.8087,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:47] {2218} INFO - iteration 156, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:48] {2391} INFO -  at 112.2s,\testimator lgbm's best error=69.5091,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:48] {2218} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:48] {2391} INFO -  at 112.4s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:48] {2218} INFO - iteration 158, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:49] {2391} INFO -  at 112.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:49] {2218} INFO - iteration 159, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:50] {2391} INFO -  at 114.1s,\testimator lgbm's best error=69.2009,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:50] {2218} INFO - iteration 160, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:51] {2391} INFO -  at 115.2s,\testimator lgbm's best error=69.2009,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:51] {2218} INFO - iteration 161, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:52] {2391} INFO -  at 115.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:52] {2218} INFO - iteration 162, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:54] {2391} INFO -  at 118.6s,\testimator lgbm's best error=69.2009,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:54] {2218} INFO - iteration 163, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:55] {2391} INFO -  at 119.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:55] {2218} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:55] {2391} INFO -  at 119.3s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:55] {2218} INFO - iteration 165, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:55] {2391} INFO -  at 119.7s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:55] {2218} INFO - iteration 166, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:36:56] {2391} INFO -  at 120.5s,\testimator lgbm's best error=69.2009,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:56] {2218} INFO - iteration 167, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:57] {2391} INFO -  at 121.0s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:57] {2218} INFO - iteration 168, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:36:57] {2391} INFO -  at 121.5s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:57] {2218} INFO - iteration 169, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:36:59] {2391} INFO -  at 123.0s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:36:59] {2218} INFO - iteration 170, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:37:01] {2391} INFO -  at 125.4s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:01] {2218} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:37:04] {2391} INFO -  at 127.8s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:04] {2218} INFO - iteration 172, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:37:07] {2391} INFO -  at 131.3s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:07] {2218} INFO - iteration 173, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:08] {2391} INFO -  at 131.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:08] {2218} INFO - iteration 174, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:08] {2391} INFO -  at 132.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:08] {2218} INFO - iteration 175, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:09] {2391} INFO -  at 132.9s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:09] {2218} INFO - iteration 176, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:37:09] {2391} INFO -  at 133.7s,\testimator catboost's best error=71.1061,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:09] {2218} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:10] {2391} INFO -  at 133.8s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:10] {2218} INFO - iteration 178, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:10] {2391} INFO -  at 134.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:10] {2218} INFO - iteration 179, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:11] {2391} INFO -  at 134.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:11] {2218} INFO - iteration 180, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:11] {2391} INFO -  at 135.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:11] {2218} INFO - iteration 181, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:11] {2391} INFO -  at 135.5s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:11] {2218} INFO - iteration 182, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:12] {2391} INFO -  at 136.0s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:12] {2218} INFO - iteration 183, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:37:16] {2391} INFO -  at 140.1s,\testimator rf's best error=70.4979,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:16] {2218} INFO - iteration 184, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:37:19] {2391} INFO -  at 142.8s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:19] {2218} INFO - iteration 185, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:19] {2391} INFO -  at 143.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:19] {2218} INFO - iteration 186, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:20] {2391} INFO -  at 143.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:20] {2218} INFO - iteration 187, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:37:23] {2391} INFO -  at 146.8s,\testimator rf's best error=70.3506,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:23] {2218} INFO - iteration 188, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:23] {2391} INFO -  at 147.3s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:23] {2218} INFO - iteration 189, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:37:26] {2391} INFO -  at 150.3s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:26] {2218} INFO - iteration 190, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:37:29] {2391} INFO -  at 152.9s,\testimator catboost's best error=71.1061,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:29] {2218} INFO - iteration 191, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:29] {2391} INFO -  at 153.2s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:29] {2218} INFO - iteration 192, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:37:32] {2391} INFO -  at 156.5s,\testimator rf's best error=70.3506,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:32] {2218} INFO - iteration 193, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:33] {2391} INFO -  at 156.9s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:33] {2218} INFO - iteration 194, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:33] {2391} INFO -  at 157.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:33] {2218} INFO - iteration 195, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:34] {2391} INFO -  at 158.0s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:34] {2218} INFO - iteration 196, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:37:35] {2391} INFO -  at 159.0s,\testimator catboost's best error=70.1624,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:35] {2218} INFO - iteration 197, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:37:39] {2391} INFO -  at 163.2s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:39] {2218} INFO - iteration 198, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:39] {2391} INFO -  at 163.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:39] {2218} INFO - iteration 199, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:40] {2391} INFO -  at 163.9s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:40] {2218} INFO - iteration 200, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:40] {2391} INFO -  at 164.2s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:40] {2218} INFO - iteration 201, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:41] {2391} INFO -  at 164.8s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:41] {2218} INFO - iteration 202, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:37:42] {2391} INFO -  at 166.2s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:42] {2218} INFO - iteration 203, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:37:44] {2391} INFO -  at 167.9s,\testimator catboost's best error=70.1624,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:44] {2218} INFO - iteration 204, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:44] {2391} INFO -  at 168.5s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:44] {2218} INFO - iteration 205, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:44] {2391} INFO -  at 168.7s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:44] {2218} INFO - iteration 206, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:45] {2391} INFO -  at 169.0s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:45] {2218} INFO - iteration 207, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:45] {2391} INFO -  at 169.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:45] {2218} INFO - iteration 208, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:46] {2391} INFO -  at 169.9s,\testimator xgb_limitdepth's best error=71.9602,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:46] {2218} INFO - iteration 209, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:46] {2391} INFO -  at 170.4s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:46] {2218} INFO - iteration 210, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:37:48] {2391} INFO -  at 172.3s,\testimator catboost's best error=70.1624,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:48] {2218} INFO - iteration 211, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:48] {2391} INFO -  at 172.7s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:48] {2218} INFO - iteration 212, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:49] {2391} INFO -  at 173.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:49] {2218} INFO - iteration 213, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:49] {2391} INFO -  at 173.7s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:49] {2218} INFO - iteration 214, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:50] {2391} INFO -  at 174.4s,\testimator xgb_limitdepth's best error=71.2665,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:50] {2218} INFO - iteration 215, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:37:50] {2391} INFO -  at 174.7s,\testimator xgb_limitdepth's best error=71.2641,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:50] {2218} INFO - iteration 216, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:37:51] {2391} INFO -  at 175.5s,\testimator catboost's best error=70.1624,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:51] {2218} INFO - iteration 217, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:37:52] {2391} INFO -  at 176.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:52] {2218} INFO - iteration 218, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:37:55] {2391} INFO -  at 179.3s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:55] {2218} INFO - iteration 219, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:37:57] {2391} INFO -  at 181.0s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:37:57] {2218} INFO - iteration 220, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:38:04] {2391} INFO -  at 187.8s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:04] {2218} INFO - iteration 221, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:38:06] {2391} INFO -  at 189.8s,\testimator catboost's best error=70.1624,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:06] {2218} INFO - iteration 222, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:38:06] {2391} INFO -  at 190.6s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:06] {2218} INFO - iteration 223, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:38:07] {2391} INFO -  at 191.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:07] {2218} INFO - iteration 224, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:38:07] {2391} INFO -  at 191.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:07] {2218} INFO - iteration 225, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:38:10] {2391} INFO -  at 193.9s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:10] {2218} INFO - iteration 226, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:38:13] {2391} INFO -  at 196.9s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:13] {2218} INFO - iteration 227, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:38:15] {2391} INFO -  at 199.2s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:15] {2218} INFO - iteration 228, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:38:19] {2391} INFO -  at 203.7s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:19] {2218} INFO - iteration 229, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:38:20] {2391} INFO -  at 204.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:20] {2218} INFO - iteration 230, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:38:22] {2391} INFO -  at 206.0s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:22] {2218} INFO - iteration 231, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:38:22] {2391} INFO -  at 206.5s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:22] {2218} INFO - iteration 232, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:38:24] {2391} INFO -  at 208.1s,\testimator catboost's best error=70.1624,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:24] {2218} INFO - iteration 233, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:38:24] {2391} INFO -  at 208.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:24] {2218} INFO - iteration 234, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:38:25] {2391} INFO -  at 209.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:25] {2218} INFO - iteration 235, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:38:25] {2391} INFO -  at 209.7s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:25] {2218} INFO - iteration 236, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:38:27] {2391} INFO -  at 211.6s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:27] {2218} INFO - iteration 237, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:38:30] {2391} INFO -  at 214.5s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:30] {2218} INFO - iteration 238, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:38:31] {2391} INFO -  at 215.0s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:31] {2218} INFO - iteration 239, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:38:37] {2391} INFO -  at 220.9s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:37] {2218} INFO - iteration 240, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:38:38] {2391} INFO -  at 222.3s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:38] {2218} INFO - iteration 241, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:38:40] {2391} INFO -  at 224.5s,\testimator xgboost's best error=72.4405,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:40] {2218} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:38:43] {2391} INFO -  at 227.0s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:43] {2218} INFO - iteration 243, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:38:49] {2391} INFO -  at 232.9s,\testimator xgboost's best error=71.7493,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:49] {2218} INFO - iteration 244, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:38:50] {2391} INFO -  at 234.1s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:50] {2218} INFO - iteration 245, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:38:50] {2391} INFO -  at 234.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:50] {2218} INFO - iteration 246, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:38:52] {2391} INFO -  at 236.5s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:52] {2218} INFO - iteration 247, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:38:53] {2391} INFO -  at 237.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:38:53] {2218} INFO - iteration 248, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:39:17] {2391} INFO -  at 261.1s,\testimator xgboost's best error=71.7493,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:17] {2218} INFO - iteration 249, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:39:22] {2391} INFO -  at 266.3s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:22] {2218} INFO - iteration 250, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:23] {2391} INFO -  at 266.9s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:23] {2218} INFO - iteration 251, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:23] {2391} INFO -  at 267.4s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:23] {2218} INFO - iteration 252, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:39:32] {2391} INFO -  at 275.8s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:32] {2218} INFO - iteration 253, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:39:36] {2391} INFO -  at 280.6s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:36] {2218} INFO - iteration 254, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:37] {2391} INFO -  at 281.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:37] {2218} INFO - iteration 255, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:37] {2391} INFO -  at 281.7s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:37] {2218} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:39:39] {2391} INFO -  at 282.8s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:39] {2218} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:39:39] {2391} INFO -  at 283.3s,\testimator xgb_limitdepth's best error=71.2641,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:39] {2218} INFO - iteration 258, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:39:41] {2391} INFO -  at 284.9s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:41] {2218} INFO - iteration 259, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:41] {2391} INFO -  at 285.4s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:41] {2218} INFO - iteration 260, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:42] {2391} INFO -  at 286.0s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:42] {2218} INFO - iteration 261, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:42] {2391} INFO -  at 286.5s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:42] {2218} INFO - iteration 262, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:39:46] {2391} INFO -  at 289.9s,\testimator xgboost's best error=71.7493,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:46] {2218} INFO - iteration 263, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:46] {2391} INFO -  at 290.5s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:46] {2218} INFO - iteration 264, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:39:48] {2391} INFO -  at 292.0s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:48] {2218} INFO - iteration 265, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:48] {2391} INFO -  at 292.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:48] {2218} INFO - iteration 266, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:49] {2391} INFO -  at 293.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:49] {2218} INFO - iteration 267, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:49] {2391} INFO -  at 293.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:49] {2218} INFO - iteration 268, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:50] {2391} INFO -  at 294.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:50] {2218} INFO - iteration 269, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:50] {2391} INFO -  at 294.7s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:50] {2218} INFO - iteration 270, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:51] {2391} INFO -  at 295.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:51] {2218} INFO - iteration 271, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:39:58] {2391} INFO -  at 301.8s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:58] {2218} INFO - iteration 272, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:39:58] {2391} INFO -  at 302.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:39:58] {2218} INFO - iteration 273, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:40:06] {2391} INFO -  at 310.4s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:06] {2218} INFO - iteration 274, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:40:07] {2391} INFO -  at 311.7s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:07] {2218} INFO - iteration 275, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:40:11] {2391} INFO -  at 315.0s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:11] {2218} INFO - iteration 276, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:40:17] {2391} INFO -  at 321.2s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:17] {2218} INFO - iteration 277, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:40:19] {2391} INFO -  at 323.2s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:19] {2218} INFO - iteration 278, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:19] {2391} INFO -  at 323.7s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:19] {2218} INFO - iteration 279, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:40:21] {2391} INFO -  at 325.7s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:21] {2218} INFO - iteration 280, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:22] {2391} INFO -  at 326.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:22] {2218} INFO - iteration 281, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:22] {2391} INFO -  at 326.7s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:22] {2218} INFO - iteration 282, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:40:27] {2391} INFO -  at 331.1s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:27] {2218} INFO - iteration 283, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:40:28] {2391} INFO -  at 332.7s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:28] {2218} INFO - iteration 284, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:40:30] {2391} INFO -  at 334.6s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:30] {2218} INFO - iteration 285, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:31] {2391} INFO -  at 335.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:31] {2218} INFO - iteration 286, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:31] {2391} INFO -  at 335.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:31] {2218} INFO - iteration 287, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:32] {2391} INFO -  at 336.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:32] {2218} INFO - iteration 288, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:32] {2391} INFO -  at 336.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:32] {2218} INFO - iteration 289, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:40:37] {2391} INFO -  at 341.1s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:37] {2218} INFO - iteration 290, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:40:43] {2391} INFO -  at 347.2s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:43] {2218} INFO - iteration 291, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:43] {2391} INFO -  at 347.7s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:43] {2218} INFO - iteration 292, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:40:54] {2391} INFO -  at 358.0s,\testimator xgboost's best error=71.1814,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:54] {2218} INFO - iteration 293, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:54] {2391} INFO -  at 358.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:54] {2218} INFO - iteration 294, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:55] {2391} INFO -  at 359.0s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:55] {2218} INFO - iteration 295, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:40:55] {2391} INFO -  at 359.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:40:55] {2218} INFO - iteration 296, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:41:06] {2391} INFO -  at 370.6s,\testimator xgboost's best error=71.0327,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:06] {2218} INFO - iteration 297, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:41:07] {2391} INFO -  at 371.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:07] {2218} INFO - iteration 298, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:41:07] {2391} INFO -  at 371.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:07] {2218} INFO - iteration 299, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:41:11] {2391} INFO -  at 375.4s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:11] {2218} INFO - iteration 300, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:41:13] {2391} INFO -  at 377.3s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:13] {2218} INFO - iteration 301, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:41:13] {2391} INFO -  at 377.7s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:13] {2218} INFO - iteration 302, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:41:21] {2391} INFO -  at 385.1s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:21] {2218} INFO - iteration 303, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:41:37] {2391} INFO -  at 401.7s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:37] {2218} INFO - iteration 304, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:41:38] {2391} INFO -  at 402.2s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:38] {2218} INFO - iteration 305, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:41:41] {2391} INFO -  at 405.1s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:41] {2218} INFO - iteration 306, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:41:41] {2391} INFO -  at 405.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:41] {2218} INFO - iteration 307, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:41:42] {2391} INFO -  at 406.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:42] {2218} INFO - iteration 308, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:41:42] {2391} INFO -  at 406.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:42] {2218} INFO - iteration 309, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:41:43] {2391} INFO -  at 407.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:43] {2218} INFO - iteration 310, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:41:46] {2391} INFO -  at 410.2s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:41:46] {2218} INFO - iteration 311, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:42:15] {2391} INFO -  at 439.5s,\testimator xgboost's best error=70.9721,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:15] {2218} INFO - iteration 312, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:42:19] {2391} INFO -  at 443.1s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:19] {2218} INFO - iteration 313, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:42:21] {2391} INFO -  at 445.4s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:21] {2218} INFO - iteration 314, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:22] {2391} INFO -  at 446.0s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:22] {2218} INFO - iteration 315, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:42:24] {2391} INFO -  at 448.7s,\testimator rf's best error=69.6418,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:24] {2218} INFO - iteration 316, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:25] {2391} INFO -  at 449.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:25] {2218} INFO - iteration 317, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:26] {2391} INFO -  at 449.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:26] {2218} INFO - iteration 318, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:42:29] {2391} INFO -  at 453.3s,\testimator rf's best error=69.4455,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:29] {2218} INFO - iteration 319, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:42:32] {2391} INFO -  at 455.8s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:32] {2218} INFO - iteration 320, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:42:38] {2391} INFO -  at 462.5s,\testimator rf's best error=69.4455,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:38] {2218} INFO - iteration 321, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:39] {2391} INFO -  at 463.0s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:39] {2218} INFO - iteration 322, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:39] {2391} INFO -  at 463.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:39] {2218} INFO - iteration 323, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:42:41] {2391} INFO -  at 465.4s,\testimator rf's best error=69.4455,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:41] {2218} INFO - iteration 324, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:42:43] {2391} INFO -  at 467.5s,\testimator rf's best error=69.4455,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:43] {2218} INFO - iteration 325, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:44] {2391} INFO -  at 468.0s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:44] {2218} INFO - iteration 326, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:44] {2391} INFO -  at 468.6s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:44] {2218} INFO - iteration 327, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:45] {2391} INFO -  at 469.1s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:45] {2218} INFO - iteration 328, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:42:50] {2391} INFO -  at 474.1s,\testimator rf's best error=69.4455,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:50] {2218} INFO - iteration 329, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:42:52] {2391} INFO -  at 476.8s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:52] {2218} INFO - iteration 330, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:53] {2391} INFO -  at 477.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:53] {2218} INFO - iteration 331, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:53] {2391} INFO -  at 477.8s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:53] {2218} INFO - iteration 332, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:42:54] {2391} INFO -  at 478.7s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:54] {2218} INFO - iteration 333, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:55] {2391} INFO -  at 479.3s,\testimator extra_tree's best error=68.9260,\tbest estimator extra_tree's best error=68.9260\n",
      "[flaml.automl.logger: 11-12 20:42:55] {2218} INFO - iteration 334, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:56] {2391} INFO -  at 479.9s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:42:56] {2218} INFO - iteration 335, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:56] {2391} INFO -  at 480.4s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:42:56] {2218} INFO - iteration 336, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:42:58] {2391} INFO -  at 482.3s,\testimator rf's best error=69.4437,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:42:58] {2218} INFO - iteration 337, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:42:59] {2391} INFO -  at 482.9s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:42:59] {2218} INFO - iteration 338, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:43:11] {2391} INFO -  at 495.7s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:11] {2218} INFO - iteration 339, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:12] {2391} INFO -  at 496.1s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:12] {2218} INFO - iteration 340, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:13] {2391} INFO -  at 496.8s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:13] {2218} INFO - iteration 341, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:43:19] {2391} INFO -  at 503.6s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:19] {2218} INFO - iteration 342, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:20] {2391} INFO -  at 504.1s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:20] {2218} INFO - iteration 343, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:20] {2391} INFO -  at 504.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:20] {2218} INFO - iteration 344, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:21] {2391} INFO -  at 505.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:21] {2218} INFO - iteration 345, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:21] {2391} INFO -  at 505.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:21] {2218} INFO - iteration 346, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:22] {2391} INFO -  at 506.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:22] {2218} INFO - iteration 347, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:23] {2391} INFO -  at 506.8s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:23] {2218} INFO - iteration 348, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:23] {2391} INFO -  at 507.4s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:23] {2218} INFO - iteration 349, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:24] {2391} INFO -  at 507.9s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:24] {2218} INFO - iteration 350, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:43:24] {2391} INFO -  at 508.5s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:24] {2218} INFO - iteration 351, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:25] {2391} INFO -  at 509.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:25] {2218} INFO - iteration 352, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:25] {2391} INFO -  at 509.5s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:25] {2218} INFO - iteration 353, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:26] {2391} INFO -  at 510.1s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:26] {2218} INFO - iteration 354, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:26] {2391} INFO -  at 510.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:26] {2218} INFO - iteration 355, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:43:36] {2391} INFO -  at 519.9s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:36] {2218} INFO - iteration 356, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:36] {2391} INFO -  at 520.4s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:36] {2218} INFO - iteration 357, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:37] {2391} INFO -  at 521.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:37] {2218} INFO - iteration 358, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:37] {2391} INFO -  at 521.4s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:37] {2218} INFO - iteration 359, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:38] {2391} INFO -  at 522.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:38] {2218} INFO - iteration 360, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:38] {2391} INFO -  at 522.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:38] {2218} INFO - iteration 361, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:39] {2391} INFO -  at 523.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:39] {2218} INFO - iteration 362, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:39] {2391} INFO -  at 523.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:39] {2218} INFO - iteration 363, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:40] {2391} INFO -  at 524.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:40] {2218} INFO - iteration 364, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:40] {2391} INFO -  at 524.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:40] {2218} INFO - iteration 365, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:43:41] {2391} INFO -  at 524.9s,\testimator xgb_limitdepth's best error=71.2641,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:41] {2218} INFO - iteration 366, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:41] {2391} INFO -  at 525.5s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:41] {2218} INFO - iteration 367, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:43:44] {2391} INFO -  at 528.5s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:44] {2218} INFO - iteration 368, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:45] {2391} INFO -  at 529.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:45] {2218} INFO - iteration 369, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:45] {2391} INFO -  at 529.5s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:45] {2218} INFO - iteration 370, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:46] {2391} INFO -  at 530.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:46] {2218} INFO - iteration 371, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:46] {2391} INFO -  at 530.5s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:46] {2218} INFO - iteration 372, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:43:47] {2391} INFO -  at 531.8s,\testimator xgb_limitdepth's best error=71.2641,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:47] {2218} INFO - iteration 373, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:48] {2391} INFO -  at 532.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:48] {2218} INFO - iteration 374, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:49] {2391} INFO -  at 532.9s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:49] {2218} INFO - iteration 375, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:43:57] {2391} INFO -  at 540.9s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:57] {2218} INFO - iteration 376, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:43:57] {2391} INFO -  at 541.5s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:43:57] {2218} INFO - iteration 377, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:44:02] {2391} INFO -  at 546.2s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:02] {2218} INFO - iteration 378, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:44:06] {2391} INFO -  at 550.7s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:06] {2218} INFO - iteration 379, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:07] {2391} INFO -  at 551.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:07] {2218} INFO - iteration 380, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:44:08] {2391} INFO -  at 552.6s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:08] {2218} INFO - iteration 381, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:09] {2391} INFO -  at 553.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:09] {2218} INFO - iteration 382, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:09] {2391} INFO -  at 553.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:09] {2218} INFO - iteration 383, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:10] {2391} INFO -  at 554.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:10] {2218} INFO - iteration 384, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:11] {2391} INFO -  at 554.9s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:11] {2218} INFO - iteration 385, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:44:16] {2391} INFO -  at 559.8s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:16] {2218} INFO - iteration 386, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:16] {2391} INFO -  at 560.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:16] {2218} INFO - iteration 387, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:16] {2391} INFO -  at 560.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:16] {2218} INFO - iteration 388, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:17] {2391} INFO -  at 561.4s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:17] {2218} INFO - iteration 389, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:44:22] {2391} INFO -  at 566.5s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:22] {2218} INFO - iteration 390, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:23] {2391} INFO -  at 567.1s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:23] {2218} INFO - iteration 391, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:23] {2391} INFO -  at 567.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:23] {2218} INFO - iteration 392, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:24] {2391} INFO -  at 568.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:24] {2218} INFO - iteration 393, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:24] {2391} INFO -  at 568.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:24] {2218} INFO - iteration 394, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:44:30] {2391} INFO -  at 574.7s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:30] {2218} INFO - iteration 395, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:31] {2391} INFO -  at 575.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:31] {2218} INFO - iteration 396, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:44:42] {2391} INFO -  at 586.4s,\testimator xgboost's best error=70.9721,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:42] {2218} INFO - iteration 397, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:43] {2391} INFO -  at 587.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:43] {2218} INFO - iteration 398, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:43] {2391} INFO -  at 587.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:43] {2218} INFO - iteration 399, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:44:45] {2391} INFO -  at 589.0s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:45] {2218} INFO - iteration 400, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:45] {2391} INFO -  at 589.4s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:45] {2218} INFO - iteration 401, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:46] {2391} INFO -  at 590.1s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:46] {2218} INFO - iteration 402, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:46] {2391} INFO -  at 590.5s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:46] {2218} INFO - iteration 403, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:47] {2391} INFO -  at 591.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:47] {2218} INFO - iteration 404, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:47] {2391} INFO -  at 591.5s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:47] {2218} INFO - iteration 405, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:48] {2391} INFO -  at 592.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:48] {2218} INFO - iteration 406, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:48] {2391} INFO -  at 592.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:48] {2218} INFO - iteration 407, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:49] {2391} INFO -  at 593.1s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:49] {2218} INFO - iteration 408, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:44:50] {2391} INFO -  at 594.6s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:50] {2218} INFO - iteration 409, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:51] {2391} INFO -  at 595.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:51] {2218} INFO - iteration 410, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:51] {2391} INFO -  at 595.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:51] {2218} INFO - iteration 411, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:52] {2391} INFO -  at 596.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:52] {2218} INFO - iteration 412, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:52] {2391} INFO -  at 596.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:52] {2218} INFO - iteration 413, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:53] {2391} INFO -  at 597.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:53] {2218} INFO - iteration 414, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:44:57] {2391} INFO -  at 601.4s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:57] {2218} INFO - iteration 415, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:44:58] {2391} INFO -  at 601.9s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:44:58] {2218} INFO - iteration 416, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:45:05] {2391} INFO -  at 609.1s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:05] {2218} INFO - iteration 417, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:05] {2391} INFO -  at 609.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:05] {2218} INFO - iteration 418, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:06] {2391} INFO -  at 610.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:06] {2218} INFO - iteration 419, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:06] {2391} INFO -  at 610.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:06] {2218} INFO - iteration 420, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:07] {2391} INFO -  at 611.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:07] {2218} INFO - iteration 421, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:07] {2391} INFO -  at 611.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:07] {2218} INFO - iteration 422, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:08] {2391} INFO -  at 612.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:08] {2218} INFO - iteration 423, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:08] {2391} INFO -  at 612.8s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:08] {2218} INFO - iteration 424, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:09] {2391} INFO -  at 613.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:09] {2218} INFO - iteration 425, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:10] {2391} INFO -  at 613.8s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:10] {2218} INFO - iteration 426, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:45:13] {2391} INFO -  at 617.7s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:13] {2218} INFO - iteration 427, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:45:23] {2391} INFO -  at 626.9s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:23] {2218} INFO - iteration 428, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:45:23] {2391} INFO -  at 627.7s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:23] {2218} INFO - iteration 429, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:45:24] {2391} INFO -  at 628.2s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:24] {2218} INFO - iteration 430, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:24] {2391} INFO -  at 628.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:24] {2218} INFO - iteration 431, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:45:26] {2391} INFO -  at 630.3s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:26] {2218} INFO - iteration 432, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:45:41] {2391} INFO -  at 644.9s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:41] {2218} INFO - iteration 433, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:41] {2391} INFO -  at 645.5s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:41] {2218} INFO - iteration 434, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:42] {2391} INFO -  at 645.9s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:42] {2218} INFO - iteration 435, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:42] {2391} INFO -  at 646.5s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:42] {2218} INFO - iteration 436, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:43] {2391} INFO -  at 647.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:43] {2218} INFO - iteration 437, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:43] {2391} INFO -  at 647.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:43] {2218} INFO - iteration 438, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:44] {2391} INFO -  at 648.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:44] {2218} INFO - iteration 439, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:44] {2391} INFO -  at 648.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:44] {2218} INFO - iteration 440, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:45] {2391} INFO -  at 649.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:45] {2218} INFO - iteration 441, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:46] {2391} INFO -  at 649.8s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:46] {2218} INFO - iteration 442, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:46] {2391} INFO -  at 650.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:46] {2218} INFO - iteration 443, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:45:52] {2391} INFO -  at 655.8s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:52] {2218} INFO - iteration 444, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:52] {2391} INFO -  at 656.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:52] {2218} INFO - iteration 445, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:45:57] {2391} INFO -  at 661.7s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:57] {2218} INFO - iteration 446, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:45:58] {2391} INFO -  at 662.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:58] {2218} INFO - iteration 447, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:45:59] {2391} INFO -  at 663.5s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:45:59] {2218} INFO - iteration 448, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:00] {2391} INFO -  at 664.1s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:00] {2218} INFO - iteration 449, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:46:01] {2391} INFO -  at 665.6s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:01] {2218} INFO - iteration 450, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:02] {2391} INFO -  at 666.1s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:02] {2218} INFO - iteration 451, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:02] {2391} INFO -  at 666.6s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:02] {2218} INFO - iteration 452, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:03] {2391} INFO -  at 667.1s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:03] {2218} INFO - iteration 453, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:03] {2391} INFO -  at 667.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:03] {2218} INFO - iteration 454, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:46:10] {2391} INFO -  at 674.5s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:10] {2218} INFO - iteration 455, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:46:12] {2391} INFO -  at 676.3s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:12] {2218} INFO - iteration 456, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:12] {2391} INFO -  at 676.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:12] {2218} INFO - iteration 457, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:13] {2391} INFO -  at 677.4s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:13] {2218} INFO - iteration 458, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:14] {2391} INFO -  at 678.0s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:14] {2218} INFO - iteration 459, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:14] {2391} INFO -  at 678.5s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:14] {2218} INFO - iteration 460, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:15] {2391} INFO -  at 679.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:15] {2218} INFO - iteration 461, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:15] {2391} INFO -  at 679.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:15] {2218} INFO - iteration 462, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:16] {2391} INFO -  at 680.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:16] {2218} INFO - iteration 463, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:17] {2391} INFO -  at 680.8s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:17] {2218} INFO - iteration 464, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:17] {2391} INFO -  at 681.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:17] {2218} INFO - iteration 465, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:46:41] {2391} INFO -  at 704.8s,\testimator xgboost's best error=70.9721,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:41] {2218} INFO - iteration 466, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:46:44] {2391} INFO -  at 708.6s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:44] {2218} INFO - iteration 467, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:45] {2391} INFO -  at 709.1s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:45] {2218} INFO - iteration 468, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:46:49] {2391} INFO -  at 713.7s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:49] {2218} INFO - iteration 469, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:50] {2391} INFO -  at 714.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:50] {2218} INFO - iteration 470, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:50] {2391} INFO -  at 714.7s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:50] {2218} INFO - iteration 471, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:51] {2391} INFO -  at 715.2s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:51] {2218} INFO - iteration 472, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:52] {2391} INFO -  at 715.8s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:52] {2218} INFO - iteration 473, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:52] {2391} INFO -  at 716.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:52] {2218} INFO - iteration 474, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:53] {2391} INFO -  at 716.8s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:53] {2218} INFO - iteration 475, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:53] {2391} INFO -  at 717.3s,\testimator extra_tree's best error=68.8126,\tbest estimator extra_tree's best error=68.8126\n",
      "[flaml.automl.logger: 11-12 20:46:53] {2218} INFO - iteration 476, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:54] {2391} INFO -  at 717.9s,\testimator extra_tree's best error=68.7784,\tbest estimator extra_tree's best error=68.7784\n",
      "[flaml.automl.logger: 11-12 20:46:54] {2218} INFO - iteration 477, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:54] {2391} INFO -  at 718.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:46:54] {2218} INFO - iteration 478, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:55] {2391} INFO -  at 719.2s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:46:55] {2218} INFO - iteration 479, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:56] {2391} INFO -  at 719.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:46:56] {2218} INFO - iteration 480, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:56] {2391} INFO -  at 720.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:46:56] {2218} INFO - iteration 481, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:57] {2391} INFO -  at 721.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:46:57] {2218} INFO - iteration 482, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:58] {2391} INFO -  at 721.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:46:58] {2218} INFO - iteration 483, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:58] {2391} INFO -  at 722.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:46:58] {2218} INFO - iteration 484, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:46:59] {2391} INFO -  at 723.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:46:59] {2218} INFO - iteration 485, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:00] {2391} INFO -  at 723.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:00] {2218} INFO - iteration 486, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:00] {2391} INFO -  at 724.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:00] {2218} INFO - iteration 487, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:01] {2391} INFO -  at 725.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:01] {2218} INFO - iteration 488, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:01] {2391} INFO -  at 725.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:01] {2218} INFO - iteration 489, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:02] {2391} INFO -  at 726.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:02] {2218} INFO - iteration 490, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:03] {2391} INFO -  at 727.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:03] {2218} INFO - iteration 491, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:03] {2391} INFO -  at 727.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:03] {2218} INFO - iteration 492, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:04] {2391} INFO -  at 728.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:04] {2218} INFO - iteration 493, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:47:08] {2391} INFO -  at 731.8s,\testimator rf's best error=69.4437,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:08] {2218} INFO - iteration 494, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:08] {2391} INFO -  at 732.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:08] {2218} INFO - iteration 495, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:09] {2391} INFO -  at 733.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:09] {2218} INFO - iteration 496, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:10] {2391} INFO -  at 733.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:10] {2218} INFO - iteration 497, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:10] {2391} INFO -  at 734.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:10] {2218} INFO - iteration 498, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:11] {2391} INFO -  at 735.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:11] {2218} INFO - iteration 499, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:12] {2391} INFO -  at 735.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:12] {2218} INFO - iteration 500, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:12] {2391} INFO -  at 736.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:12] {2218} INFO - iteration 501, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:13] {2391} INFO -  at 737.2s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:13] {2218} INFO - iteration 502, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:14] {2391} INFO -  at 737.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:14] {2218} INFO - iteration 503, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:14] {2391} INFO -  at 738.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:14] {2218} INFO - iteration 504, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:15] {2391} INFO -  at 739.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:15] {2218} INFO - iteration 505, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:16] {2391} INFO -  at 739.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:16] {2218} INFO - iteration 506, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:16] {2391} INFO -  at 740.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:16] {2218} INFO - iteration 507, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:17] {2391} INFO -  at 741.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:17] {2218} INFO - iteration 508, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:18] {2391} INFO -  at 741.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:18] {2218} INFO - iteration 509, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:18] {2391} INFO -  at 742.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:18] {2218} INFO - iteration 510, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:19] {2391} INFO -  at 743.3s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:19] {2218} INFO - iteration 511, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:20] {2391} INFO -  at 743.9s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:20] {2218} INFO - iteration 512, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:20] {2391} INFO -  at 744.6s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:20] {2218} INFO - iteration 513, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:21] {2391} INFO -  at 745.2s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:21] {2218} INFO - iteration 514, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:22] {2391} INFO -  at 745.9s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:22] {2218} INFO - iteration 515, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:22] {2391} INFO -  at 746.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:22] {2218} INFO - iteration 516, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:23] {2391} INFO -  at 747.2s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:23] {2218} INFO - iteration 517, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:24] {2391} INFO -  at 747.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:24] {2218} INFO - iteration 518, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:47:26] {2391} INFO -  at 750.3s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:26] {2218} INFO - iteration 519, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:27] {2391} INFO -  at 751.0s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:27] {2218} INFO - iteration 520, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:27] {2391} INFO -  at 751.6s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:27] {2218} INFO - iteration 521, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:28] {2391} INFO -  at 752.3s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:28] {2218} INFO - iteration 522, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:29] {2391} INFO -  at 752.9s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:29] {2218} INFO - iteration 523, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:29] {2391} INFO -  at 753.6s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:29] {2218} INFO - iteration 524, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:30] {2391} INFO -  at 754.3s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:30] {2218} INFO - iteration 525, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:47:30] {2391} INFO -  at 754.4s,\testimator xgb_limitdepth's best error=71.2641,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:30] {2218} INFO - iteration 526, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:31] {2391} INFO -  at 755.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:31] {2218} INFO - iteration 527, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:32] {2391} INFO -  at 755.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:32] {2218} INFO - iteration 528, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:32] {2391} INFO -  at 756.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:32] {2218} INFO - iteration 529, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:33] {2391} INFO -  at 757.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:33] {2218} INFO - iteration 530, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:34] {2391} INFO -  at 757.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:34] {2218} INFO - iteration 531, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:47:38] {2391} INFO -  at 762.4s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:38] {2218} INFO - iteration 532, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:39] {2391} INFO -  at 763.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:39] {2218} INFO - iteration 533, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:47:44] {2391} INFO -  at 768.3s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:44] {2218} INFO - iteration 534, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:45] {2391} INFO -  at 769.0s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:45] {2218} INFO - iteration 535, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:45] {2391} INFO -  at 769.6s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:45] {2218} INFO - iteration 536, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:46] {2391} INFO -  at 770.3s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:46] {2218} INFO - iteration 537, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:47] {2391} INFO -  at 770.9s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:47] {2218} INFO - iteration 538, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:47] {2391} INFO -  at 771.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:47] {2218} INFO - iteration 539, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:48] {2391} INFO -  at 772.3s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:48] {2218} INFO - iteration 540, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:49] {2391} INFO -  at 773.0s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:49] {2218} INFO - iteration 541, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:49] {2391} INFO -  at 773.6s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:49] {2218} INFO - iteration 542, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:50] {2391} INFO -  at 774.3s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:50] {2218} INFO - iteration 543, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:51] {2391} INFO -  at 775.0s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:51] {2218} INFO - iteration 544, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:47:57] {2391} INFO -  at 781.1s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:57] {2218} INFO - iteration 545, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:58] {2391} INFO -  at 781.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:58] {2218} INFO - iteration 546, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:58] {2391} INFO -  at 782.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:58] {2218} INFO - iteration 547, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:59] {2391} INFO -  at 783.0s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:59] {2218} INFO - iteration 548, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:47:59] {2391} INFO -  at 783.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:47:59] {2218} INFO - iteration 549, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:00] {2391} INFO -  at 784.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:00] {2218} INFO - iteration 550, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:01] {2391} INFO -  at 785.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:01] {2218} INFO - iteration 551, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:48:03] {2391} INFO -  at 786.8s,\testimator lgbm's best error=69.0728,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:03] {2218} INFO - iteration 552, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:03] {2391} INFO -  at 787.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:03] {2218} INFO - iteration 553, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:04] {2391} INFO -  at 788.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:04] {2218} INFO - iteration 554, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:05] {2391} INFO -  at 788.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:05] {2218} INFO - iteration 555, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:05] {2391} INFO -  at 789.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:05] {2218} INFO - iteration 556, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:06] {2391} INFO -  at 790.2s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:06] {2218} INFO - iteration 557, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:07] {2391} INFO -  at 790.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:07] {2218} INFO - iteration 558, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:07] {2391} INFO -  at 791.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:07] {2218} INFO - iteration 559, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:08] {2391} INFO -  at 792.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:08] {2218} INFO - iteration 560, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:08] {2391} INFO -  at 792.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:08] {2218} INFO - iteration 561, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:09] {2391} INFO -  at 793.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:09] {2218} INFO - iteration 562, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:10] {2391} INFO -  at 794.0s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:10] {2218} INFO - iteration 563, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:10] {2391} INFO -  at 794.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:10] {2218} INFO - iteration 564, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:11] {2391} INFO -  at 795.3s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:11] {2218} INFO - iteration 565, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:12] {2391} INFO -  at 796.0s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:12] {2218} INFO - iteration 566, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:48:17] {2391} INFO -  at 800.8s,\testimator lgbm's best error=68.8596,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:17] {2218} INFO - iteration 567, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:17] {2391} INFO -  at 801.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:17] {2218} INFO - iteration 568, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:18] {2391} INFO -  at 802.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:18] {2218} INFO - iteration 569, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:48:25] {2391} INFO -  at 809.6s,\testimator lgbm's best error=68.8596,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:25] {2218} INFO - iteration 570, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:26] {2391} INFO -  at 810.2s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:26] {2218} INFO - iteration 571, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:27] {2391} INFO -  at 810.9s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:27] {2218} INFO - iteration 572, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:27] {2391} INFO -  at 811.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:27] {2218} INFO - iteration 573, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:28] {2391} INFO -  at 812.2s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:28] {2218} INFO - iteration 574, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:29] {2391} INFO -  at 812.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:29] {2218} INFO - iteration 575, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:48:32] {2391} INFO -  at 816.1s,\testimator lgbm's best error=68.8596,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:32] {2218} INFO - iteration 576, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:32] {2391} INFO -  at 816.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:32] {2218} INFO - iteration 577, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:33] {2391} INFO -  at 817.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:33] {2218} INFO - iteration 578, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:34] {2391} INFO -  at 818.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:34] {2218} INFO - iteration 579, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:34] {2391} INFO -  at 818.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:34] {2218} INFO - iteration 580, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:35] {2391} INFO -  at 819.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:35] {2218} INFO - iteration 581, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:36] {2391} INFO -  at 820.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:36] {2218} INFO - iteration 582, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:37] {2391} INFO -  at 820.8s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:37] {2218} INFO - iteration 583, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:37] {2391} INFO -  at 821.5s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:37] {2218} INFO - iteration 584, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:38] {2391} INFO -  at 822.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:38] {2218} INFO - iteration 585, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:38] {2391} INFO -  at 822.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:38] {2218} INFO - iteration 586, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:39] {2391} INFO -  at 823.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:39] {2218} INFO - iteration 587, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:48:45] {2391} INFO -  at 829.1s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:45] {2218} INFO - iteration 588, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:45] {2391} INFO -  at 829.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:45] {2218} INFO - iteration 589, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:46] {2391} INFO -  at 830.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:46] {2218} INFO - iteration 590, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:47] {2391} INFO -  at 831.0s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:47] {2218} INFO - iteration 591, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:47] {2391} INFO -  at 831.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:47] {2218} INFO - iteration 592, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:48] {2391} INFO -  at 832.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:48] {2218} INFO - iteration 593, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:48:49] {2391} INFO -  at 833.1s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:48:49] {2218} INFO - iteration 594, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:49:25] {2391} INFO -  at 869.6s,\testimator xgboost's best error=70.0773,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:25] {2218} INFO - iteration 595, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:49:26] {2391} INFO -  at 870.3s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:26] {2218} INFO - iteration 596, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:49:27] {2391} INFO -  at 870.9s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:27] {2218} INFO - iteration 597, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:49:27] {2391} INFO -  at 871.6s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:27] {2218} INFO - iteration 598, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:49:28] {2391} INFO -  at 872.2s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:28] {2218} INFO - iteration 599, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:49:29] {2391} INFO -  at 872.9s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:29] {2218} INFO - iteration 600, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:49:33] {2391} INFO -  at 876.9s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:33] {2218} INFO - iteration 601, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:49:36] {2391} INFO -  at 880.3s,\testimator catboost's best error=69.7429,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:36] {2218} INFO - iteration 602, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:49:39] {2391} INFO -  at 882.9s,\testimator lgbm's best error=68.8596,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:39] {2218} INFO - iteration 603, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:49:39] {2391} INFO -  at 883.6s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:39] {2218} INFO - iteration 604, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:49:53] {2391} INFO -  at 897.1s,\testimator lgbm's best error=68.8596,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:53] {2218} INFO - iteration 605, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:49:53] {2391} INFO -  at 897.7s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:53] {2218} INFO - iteration 606, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:49:54] {2391} INFO -  at 898.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:54] {2218} INFO - iteration 607, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:49:55] {2391} INFO -  at 898.9s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:55] {2218} INFO - iteration 608, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:49:55] {2391} INFO -  at 899.4s,\testimator extra_tree's best error=68.6070,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:55] {2218} INFO - iteration 609, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:49:55] {2391} INFO -  at 899.6s,\testimator xgb_limitdepth's best error=71.2641,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:55] {2218} INFO - iteration 610, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:49:56] {2391} INFO -  at 899.9s,\testimator xgb_limitdepth's best error=71.2641,\tbest estimator extra_tree's best error=68.6070\n",
      "[flaml.automl.logger: 11-12 20:49:56] {2493} INFO - selected model: ExtraTreesRegressor(max_features=0.9179006169231322, max_leaf_nodes=78,\n",
      "                    n_estimators=20, n_jobs=-1, random_state=12032022)\n",
      "[flaml.automl.logger: 11-12 20:49:56] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-12 20:49:56] {1931} INFO - Time taken to find the best model: 718.5333511829376\n",
      "[flaml.automl.logger: 11-12 20:49:56] {1941} WARNING - Time taken to find the best model is 80% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n",
      "[flaml.automl.logger: 11-12 20:50:06] {1679} INFO - task = regression\n",
      "[flaml.automl.logger: 11-12 20:50:06] {1687} INFO - Data split method: uniform\n",
      "[flaml.automl.logger: 11-12 20:50:06] {1690} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 11-12 20:50:06] {1788} INFO - Minimizing error metric: mae\n",
      "[flaml.automl.logger: 11-12 20:50:06] {1900} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2218} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2344} INFO - Estimated sufficient time budget=1206s. Estimated necessary time budget=10s.\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2391} INFO -  at 0.8s,\testimator lgbm's best error=151.2353,\tbest estimator lgbm's best error=151.2353\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2218} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2391} INFO -  at 0.9s,\testimator lgbm's best error=135.2081,\tbest estimator lgbm's best error=135.2081\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2218} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2391} INFO -  at 1.0s,\testimator lgbm's best error=135.2081,\tbest estimator lgbm's best error=135.2081\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2218} INFO - iteration 3, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2391} INFO -  at 1.1s,\testimator lgbm's best error=133.7742,\tbest estimator lgbm's best error=133.7742\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2218} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2391} INFO -  at 1.2s,\testimator lgbm's best error=94.6564,\tbest estimator lgbm's best error=94.6564\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2218} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2391} INFO -  at 1.4s,\testimator lgbm's best error=66.7633,\tbest estimator lgbm's best error=66.7633\n",
      "[flaml.automl.logger: 11-12 20:50:06] {2218} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2391} INFO -  at 1.5s,\testimator lgbm's best error=66.7633,\tbest estimator lgbm's best error=66.7633\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2218} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2391} INFO -  at 1.6s,\testimator lgbm's best error=66.7633,\tbest estimator lgbm's best error=66.7633\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2218} INFO - iteration 8, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2391} INFO -  at 1.7s,\testimator xgboost's best error=151.1638,\tbest estimator lgbm's best error=66.7633\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2218} INFO - iteration 9, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2391} INFO -  at 1.8s,\testimator xgboost's best error=135.0624,\tbest estimator lgbm's best error=66.7633\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2218} INFO - iteration 10, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2391} INFO -  at 1.9s,\testimator lgbm's best error=59.2053,\tbest estimator lgbm's best error=59.2053\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2218} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2391} INFO -  at 2.1s,\testimator extra_tree's best error=77.6340,\tbest estimator lgbm's best error=59.2053\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2218} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2391} INFO -  at 2.3s,\testimator extra_tree's best error=77.6340,\tbest estimator lgbm's best error=59.2053\n",
      "[flaml.automl.logger: 11-12 20:50:07] {2218} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:08] {2391} INFO -  at 2.4s,\testimator xgboost's best error=135.0624,\tbest estimator lgbm's best error=59.2053\n",
      "[flaml.automl.logger: 11-12 20:50:08] {2218} INFO - iteration 14, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:08] {2391} INFO -  at 2.6s,\testimator extra_tree's best error=66.8520,\tbest estimator lgbm's best error=59.2053\n",
      "[flaml.automl.logger: 11-12 20:50:08] {2218} INFO - iteration 15, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:50:08] {2391} INFO -  at 3.2s,\testimator rf's best error=80.4577,\tbest estimator lgbm's best error=59.2053\n",
      "[flaml.automl.logger: 11-12 20:50:08] {2218} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:08] {2391} INFO -  at 3.4s,\testimator lgbm's best error=58.7955,\tbest estimator lgbm's best error=58.7955\n",
      "[flaml.automl.logger: 11-12 20:50:08] {2218} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2391} INFO -  at 3.6s,\testimator extra_tree's best error=60.0754,\tbest estimator lgbm's best error=58.7955\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2218} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2391} INFO -  at 3.7s,\testimator lgbm's best error=58.7955,\tbest estimator lgbm's best error=58.7955\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2218} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2391} INFO -  at 4.0s,\testimator extra_tree's best error=60.0754,\tbest estimator lgbm's best error=58.7955\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2218} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2391} INFO -  at 4.1s,\testimator lgbm's best error=58.7955,\tbest estimator lgbm's best error=58.7955\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2218} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2391} INFO -  at 4.2s,\testimator xgboost's best error=135.0624,\tbest estimator lgbm's best error=58.7955\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2218} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2391} INFO -  at 4.4s,\testimator lgbm's best error=58.6660,\tbest estimator lgbm's best error=58.6660\n",
      "[flaml.automl.logger: 11-12 20:50:09] {2218} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:10] {2391} INFO -  at 4.6s,\testimator lgbm's best error=58.6660,\tbest estimator lgbm's best error=58.6660\n",
      "[flaml.automl.logger: 11-12 20:50:10] {2218} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:10] {2391} INFO -  at 4.8s,\testimator extra_tree's best error=60.0754,\tbest estimator lgbm's best error=58.6660\n",
      "[flaml.automl.logger: 11-12 20:50:10] {2218} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:10] {2391} INFO -  at 5.2s,\testimator extra_tree's best error=58.4890,\tbest estimator extra_tree's best error=58.4890\n",
      "[flaml.automl.logger: 11-12 20:50:10] {2218} INFO - iteration 26, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:50:11] {2391} INFO -  at 6.2s,\testimator rf's best error=80.4577,\tbest estimator extra_tree's best error=58.4890\n",
      "[flaml.automl.logger: 11-12 20:50:11] {2218} INFO - iteration 27, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:12] {2391} INFO -  at 6.5s,\testimator extra_tree's best error=58.0422,\tbest estimator extra_tree's best error=58.0422\n",
      "[flaml.automl.logger: 11-12 20:50:12] {2218} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:12] {2391} INFO -  at 6.8s,\testimator extra_tree's best error=58.0422,\tbest estimator extra_tree's best error=58.0422\n",
      "[flaml.automl.logger: 11-12 20:50:12] {2218} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:12] {2391} INFO -  at 7.0s,\testimator extra_tree's best error=58.0422,\tbest estimator extra_tree's best error=58.0422\n",
      "[flaml.automl.logger: 11-12 20:50:12] {2218} INFO - iteration 30, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:50:13] {2391} INFO -  at 7.7s,\testimator rf's best error=67.6800,\tbest estimator extra_tree's best error=58.0422\n",
      "[flaml.automl.logger: 11-12 20:50:13] {2218} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:13] {2391} INFO -  at 7.9s,\testimator lgbm's best error=58.6660,\tbest estimator extra_tree's best error=58.0422\n",
      "[flaml.automl.logger: 11-12 20:50:13] {2218} INFO - iteration 32, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:50:14] {2391} INFO -  at 8.7s,\testimator rf's best error=60.6179,\tbest estimator extra_tree's best error=58.0422\n",
      "[flaml.automl.logger: 11-12 20:50:14] {2218} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:14] {2391} INFO -  at 9.2s,\testimator extra_tree's best error=57.3735,\tbest estimator extra_tree's best error=57.3735\n",
      "[flaml.automl.logger: 11-12 20:50:14] {2218} INFO - iteration 34, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:50:15] {2391} INFO -  at 10.3s,\testimator rf's best error=60.6179,\tbest estimator extra_tree's best error=57.3735\n",
      "[flaml.automl.logger: 11-12 20:50:15] {2218} INFO - iteration 35, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:16] {2391} INFO -  at 10.6s,\testimator xgboost's best error=66.7444,\tbest estimator extra_tree's best error=57.3735\n",
      "[flaml.automl.logger: 11-12 20:50:16] {2218} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:16] {2391} INFO -  at 11.2s,\testimator extra_tree's best error=56.9628,\tbest estimator extra_tree's best error=56.9628\n",
      "[flaml.automl.logger: 11-12 20:50:16] {2218} INFO - iteration 37, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:17] {2391} INFO -  at 11.8s,\testimator xgboost's best error=66.7444,\tbest estimator extra_tree's best error=56.9628\n",
      "[flaml.automl.logger: 11-12 20:50:17] {2218} INFO - iteration 38, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:17] {2391} INFO -  at 12.2s,\testimator extra_tree's best error=56.9628,\tbest estimator extra_tree's best error=56.9628\n",
      "[flaml.automl.logger: 11-12 20:50:17] {2218} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:17] {2391} INFO -  at 12.4s,\testimator xgboost's best error=62.8048,\tbest estimator extra_tree's best error=56.9628\n",
      "[flaml.automl.logger: 11-12 20:50:17] {2218} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:18] {2391} INFO -  at 13.0s,\testimator extra_tree's best error=56.9628,\tbest estimator extra_tree's best error=56.9628\n",
      "[flaml.automl.logger: 11-12 20:50:18] {2218} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:19] {2391} INFO -  at 13.5s,\testimator extra_tree's best error=56.9628,\tbest estimator extra_tree's best error=56.9628\n",
      "[flaml.automl.logger: 11-12 20:50:19] {2218} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:19] {2391} INFO -  at 13.7s,\testimator lgbm's best error=58.1043,\tbest estimator extra_tree's best error=56.9628\n",
      "[flaml.automl.logger: 11-12 20:50:19] {2218} INFO - iteration 43, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:19] {2391} INFO -  at 14.1s,\testimator extra_tree's best error=56.9628,\tbest estimator extra_tree's best error=56.9628\n",
      "[flaml.automl.logger: 11-12 20:50:19] {2218} INFO - iteration 44, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:50:21] {2391} INFO -  at 15.6s,\testimator catboost's best error=58.7710,\tbest estimator extra_tree's best error=56.9628\n",
      "[flaml.automl.logger: 11-12 20:50:21] {2218} INFO - iteration 45, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:21] {2391} INFO -  at 16.2s,\testimator extra_tree's best error=56.8253,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:21] {2218} INFO - iteration 46, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:21] {2391} INFO -  at 16.3s,\testimator xgboost's best error=62.8048,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:21] {2218} INFO - iteration 47, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:50:22] {2391} INFO -  at 17.1s,\testimator rf's best error=60.6179,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:22] {2218} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:23] {2391} INFO -  at 17.5s,\testimator xgboost's best error=62.8048,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:23] {2218} INFO - iteration 49, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:23] {2391} INFO -  at 17.7s,\testimator lgbm's best error=58.1043,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:23] {2218} INFO - iteration 50, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:50:26] {2391} INFO -  at 21.4s,\testimator catboost's best error=58.1780,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:26] {2218} INFO - iteration 51, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:27] {2391} INFO -  at 21.8s,\testimator extra_tree's best error=56.8253,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:27] {2218} INFO - iteration 52, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:50:29] {2391} INFO -  at 23.5s,\testimator rf's best error=58.5857,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:29] {2218} INFO - iteration 53, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:50:30] {2391} INFO -  at 24.8s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:30] {2218} INFO - iteration 54, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:30] {2391} INFO -  at 24.9s,\testimator lgbm's best error=58.1043,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:30] {2218} INFO - iteration 55, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:30] {2391} INFO -  at 25.3s,\testimator lgbm's best error=58.1043,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:30] {2218} INFO - iteration 56, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:31] {2391} INFO -  at 26.0s,\testimator extra_tree's best error=56.8253,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:31] {2218} INFO - iteration 57, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:50:33] {2391} INFO -  at 27.7s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:33] {2218} INFO - iteration 58, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:50:36] {2391} INFO -  at 30.8s,\testimator catboost's best error=57.3623,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:36] {2218} INFO - iteration 59, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:36] {2391} INFO -  at 31.0s,\testimator xgboost's best error=62.8048,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:36] {2218} INFO - iteration 60, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:37] {2391} INFO -  at 31.7s,\testimator lgbm's best error=58.1043,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:37] {2218} INFO - iteration 61, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:37] {2391} INFO -  at 32.1s,\testimator xgboost's best error=59.6248,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:37] {2218} INFO - iteration 62, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:50:41] {2391} INFO -  at 35.8s,\testimator catboost's best error=57.3623,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:41] {2218} INFO - iteration 63, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:41] {2391} INFO -  at 36.3s,\testimator xgboost's best error=59.6248,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:41] {2218} INFO - iteration 64, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:42] {2391} INFO -  at 36.7s,\testimator extra_tree's best error=56.8253,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:42] {2218} INFO - iteration 65, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:42] {2391} INFO -  at 36.9s,\testimator lgbm's best error=58.1043,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:42] {2218} INFO - iteration 66, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:42] {2391} INFO -  at 37.3s,\testimator xgboost's best error=59.6248,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:42] {2218} INFO - iteration 67, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:43] {2391} INFO -  at 38.2s,\testimator extra_tree's best error=56.8253,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:43] {2218} INFO - iteration 68, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:45] {2391} INFO -  at 40.3s,\testimator xgboost's best error=58.6264,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:45] {2218} INFO - iteration 69, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:46] {2391} INFO -  at 40.6s,\testimator lgbm's best error=58.1043,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:46] {2218} INFO - iteration 70, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:46] {2391} INFO -  at 41.1s,\testimator extra_tree's best error=56.8253,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:46] {2218} INFO - iteration 71, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:47] {2391} INFO -  at 41.9s,\testimator extra_tree's best error=56.8253,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:47] {2218} INFO - iteration 72, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:50:47] {2391} INFO -  at 42.4s,\testimator xgboost's best error=58.6264,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:47] {2218} INFO - iteration 73, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:48] {2391} INFO -  at 42.7s,\testimator extra_tree's best error=56.8253,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:48] {2218} INFO - iteration 74, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:49] {2391} INFO -  at 43.8s,\testimator extra_tree's best error=56.8253,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:49] {2218} INFO - iteration 75, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:49] {2391} INFO -  at 44.2s,\testimator extra_tree's best error=56.8253,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:49] {2218} INFO - iteration 76, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:49] {2391} INFO -  at 44.4s,\testimator lgbm's best error=58.1043,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:49] {2218} INFO - iteration 77, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:50] {2391} INFO -  at 44.7s,\testimator lgbm's best error=58.1043,\tbest estimator extra_tree's best error=56.8253\n",
      "[flaml.automl.logger: 11-12 20:50:50] {2218} INFO - iteration 78, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:50] {2391} INFO -  at 45.4s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:50:50] {2218} INFO - iteration 79, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:50:53] {2391} INFO -  at 47.6s,\testimator catboost's best error=57.3623,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:50:53] {2218} INFO - iteration 80, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:50:53] {2391} INFO -  at 47.8s,\testimator lgbm's best error=58.1043,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:50:53] {2218} INFO - iteration 81, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:53] {2391} INFO -  at 48.3s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:50:53] {2218} INFO - iteration 82, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:50:56] {2391} INFO -  at 51.4s,\testimator catboost's best error=57.3623,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:50:56] {2218} INFO - iteration 83, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:58] {2391} INFO -  at 52.5s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:50:58] {2218} INFO - iteration 84, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:59] {2391} INFO -  at 54.0s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:50:59] {2218} INFO - iteration 85, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:50:59] {2391} INFO -  at 54.4s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:50:59] {2218} INFO - iteration 86, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:00] {2391} INFO -  at 55.1s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:00] {2218} INFO - iteration 87, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:01] {2391} INFO -  at 55.9s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:01] {2218} INFO - iteration 88, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:51:02] {2391} INFO -  at 57.4s,\testimator catboost's best error=57.3623,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:02] {2218} INFO - iteration 89, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:51:03] {2391} INFO -  at 58.0s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:03] {2218} INFO - iteration 90, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:04] {2391} INFO -  at 58.8s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:04] {2218} INFO - iteration 91, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:51:05] {2391} INFO -  at 59.9s,\testimator xgboost's best error=58.6264,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:05] {2218} INFO - iteration 92, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:06] {2391} INFO -  at 60.5s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:06] {2218} INFO - iteration 93, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:06] {2391} INFO -  at 61.2s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:06] {2218} INFO - iteration 94, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:07] {2391} INFO -  at 62.0s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:07] {2218} INFO - iteration 95, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:07] {2391} INFO -  at 62.2s,\testimator xgb_limitdepth's best error=60.6563,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:07] {2218} INFO - iteration 96, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:08] {2391} INFO -  at 62.5s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:08] {2218} INFO - iteration 97, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:08] {2391} INFO -  at 62.7s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:08] {2218} INFO - iteration 98, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:08] {2391} INFO -  at 62.8s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:08] {2218} INFO - iteration 99, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:10] {2391} INFO -  at 64.4s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:10] {2218} INFO - iteration 100, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:11] {2391} INFO -  at 65.7s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:11] {2218} INFO - iteration 101, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:51:13] {2391} INFO -  at 67.6s,\testimator catboost's best error=57.3623,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:13] {2218} INFO - iteration 102, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:13] {2391} INFO -  at 68.2s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:13] {2218} INFO - iteration 103, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:14] {2391} INFO -  at 68.7s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:14] {2218} INFO - iteration 104, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:51:14] {2391} INFO -  at 69.0s,\testimator lgbm's best error=58.0886,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:14] {2218} INFO - iteration 105, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:14] {2391} INFO -  at 69.1s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:14] {2218} INFO - iteration 106, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:51:18] {2391} INFO -  at 72.8s,\testimator xgboost's best error=58.5408,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:18] {2218} INFO - iteration 107, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:18] {2391} INFO -  at 73.0s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:18] {2218} INFO - iteration 108, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:19] {2391} INFO -  at 73.7s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:19] {2218} INFO - iteration 109, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:19] {2391} INFO -  at 74.3s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:19] {2218} INFO - iteration 110, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:19] {2391} INFO -  at 74.4s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:19] {2218} INFO - iteration 111, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:20] {2391} INFO -  at 75.3s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:20] {2218} INFO - iteration 112, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:51:22] {2391} INFO -  at 77.3s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:22] {2218} INFO - iteration 113, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:23] {2391} INFO -  at 77.6s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:23] {2218} INFO - iteration 114, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:23] {2391} INFO -  at 77.9s,\testimator xgb_limitdepth's best error=58.6274,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:23] {2218} INFO - iteration 115, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:24] {2391} INFO -  at 78.8s,\testimator xgb_limitdepth's best error=58.2184,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:24] {2218} INFO - iteration 116, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:51:27] {2391} INFO -  at 81.5s,\testimator catboost's best error=57.3623,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:27] {2218} INFO - iteration 117, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:51:28] {2391} INFO -  at 83.2s,\testimator catboost's best error=57.3623,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:28] {2218} INFO - iteration 118, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:29] {2391} INFO -  at 83.5s,\testimator xgb_limitdepth's best error=58.2184,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:29] {2218} INFO - iteration 119, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:30] {2391} INFO -  at 84.7s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:30] {2218} INFO - iteration 120, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:51:31] {2391} INFO -  at 86.4s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:31] {2218} INFO - iteration 121, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:32] {2391} INFO -  at 86.9s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:32] {2218} INFO - iteration 122, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:33] {2391} INFO -  at 88.0s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:33] {2218} INFO - iteration 123, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:34] {2391} INFO -  at 88.6s,\testimator xgb_limitdepth's best error=58.2184,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:34] {2218} INFO - iteration 124, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:34] {2391} INFO -  at 89.2s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:34] {2218} INFO - iteration 125, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:51:35] {2391} INFO -  at 89.9s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:35] {2218} INFO - iteration 126, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:51:36] {2391} INFO -  at 91.3s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:36] {2218} INFO - iteration 127, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:51:38] {2391} INFO -  at 92.4s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:38] {2218} INFO - iteration 128, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:51:39] {2391} INFO -  at 94.0s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:39] {2218} INFO - iteration 129, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:51:43] {2391} INFO -  at 97.5s,\testimator catboost's best error=57.3623,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:43] {2218} INFO - iteration 130, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:44] {2391} INFO -  at 98.7s,\testimator xgb_limitdepth's best error=58.2184,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:44] {2218} INFO - iteration 131, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:45] {2391} INFO -  at 99.8s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:45] {2218} INFO - iteration 132, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:46] {2391} INFO -  at 100.5s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:46] {2218} INFO - iteration 133, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:46] {2391} INFO -  at 101.2s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:46] {2218} INFO - iteration 134, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:51:48] {2391} INFO -  at 103.0s,\testimator catboost's best error=57.3623,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:48] {2218} INFO - iteration 135, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:51:51] {2391} INFO -  at 105.8s,\testimator catboost's best error=57.2765,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:51] {2218} INFO - iteration 136, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:52] {2391} INFO -  at 106.9s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:52] {2218} INFO - iteration 137, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:51:57] {2391} INFO -  at 111.6s,\testimator xgb_limitdepth's best error=57.9550,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:57] {2218} INFO - iteration 138, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:57] {2391} INFO -  at 112.2s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:57] {2218} INFO - iteration 139, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:51:57] {2391} INFO -  at 112.4s,\testimator lgbm's best error=58.0886,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:57] {2218} INFO - iteration 140, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:58] {2391} INFO -  at 113.4s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:58] {2218} INFO - iteration 141, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:51:59] {2391} INFO -  at 113.9s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:51:59] {2218} INFO - iteration 142, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:00] {2391} INFO -  at 114.7s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:00] {2218} INFO - iteration 143, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:01] {2391} INFO -  at 115.5s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:01] {2218} INFO - iteration 144, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:52:01] {2391} INFO -  at 116.3s,\testimator xgb_limitdepth's best error=57.9550,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:01] {2218} INFO - iteration 145, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:03] {2391} INFO -  at 117.5s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:03] {2218} INFO - iteration 146, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:03] {2391} INFO -  at 118.1s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:03] {2218} INFO - iteration 147, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:04] {2391} INFO -  at 119.2s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:04] {2218} INFO - iteration 148, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:05] {2391} INFO -  at 120.4s,\testimator rf's best error=58.2122,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:05] {2218} INFO - iteration 149, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:07] {2391} INFO -  at 121.8s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:07] {2218} INFO - iteration 150, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:08] {2391} INFO -  at 123.0s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:08] {2218} INFO - iteration 151, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:10] {2391} INFO -  at 124.7s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:10] {2218} INFO - iteration 152, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:11] {2391} INFO -  at 126.1s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:11] {2218} INFO - iteration 153, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:12] {2391} INFO -  at 126.7s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:12] {2218} INFO - iteration 154, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:13] {2391} INFO -  at 127.5s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:13] {2218} INFO - iteration 155, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:52:13] {2391} INFO -  at 127.8s,\testimator lgbm's best error=58.0886,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:13] {2218} INFO - iteration 156, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:15] {2391} INFO -  at 129.5s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:15] {2218} INFO - iteration 157, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:52:17] {2391} INFO -  at 132.1s,\testimator xgb_limitdepth's best error=57.9550,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:17] {2218} INFO - iteration 158, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:18] {2391} INFO -  at 132.7s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:18] {2218} INFO - iteration 159, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:19] {2391} INFO -  at 133.7s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:19] {2218} INFO - iteration 160, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:21] {2391} INFO -  at 135.5s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:21] {2218} INFO - iteration 161, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:21] {2391} INFO -  at 136.3s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:21] {2218} INFO - iteration 162, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:22] {2391} INFO -  at 137.3s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:22] {2218} INFO - iteration 163, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:23] {2391} INFO -  at 138.0s,\testimator extra_tree's best error=56.7773,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:23] {2218} INFO - iteration 164, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:52:30] {2391} INFO -  at 144.7s,\testimator xgb_limitdepth's best error=57.9550,\tbest estimator extra_tree's best error=56.7773\n",
      "[flaml.automl.logger: 11-12 20:52:30] {2218} INFO - iteration 165, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:31] {2391} INFO -  at 145.5s,\testimator extra_tree's best error=56.7102,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:31] {2218} INFO - iteration 166, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:32] {2391} INFO -  at 147.3s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:32] {2218} INFO - iteration 167, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:33] {2391} INFO -  at 148.0s,\testimator extra_tree's best error=56.7102,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:33] {2218} INFO - iteration 168, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:34] {2391} INFO -  at 148.9s,\testimator extra_tree's best error=56.7102,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:34] {2218} INFO - iteration 169, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:35] {2391} INFO -  at 149.7s,\testimator extra_tree's best error=56.7102,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:35] {2218} INFO - iteration 170, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:36] {2391} INFO -  at 150.8s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:36] {2218} INFO - iteration 171, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:52:36] {2391} INFO -  at 151.0s,\testimator lgbm's best error=58.0886,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:36] {2218} INFO - iteration 172, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:38] {2391} INFO -  at 152.6s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:38] {2218} INFO - iteration 173, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:38] {2391} INFO -  at 153.4s,\testimator extra_tree's best error=56.7102,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:38] {2218} INFO - iteration 174, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:39] {2391} INFO -  at 154.0s,\testimator extra_tree's best error=56.7102,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:39] {2218} INFO - iteration 175, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:40] {2391} INFO -  at 154.9s,\testimator extra_tree's best error=56.7102,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:40] {2218} INFO - iteration 176, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:52:42] {2391} INFO -  at 156.8s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:42] {2218} INFO - iteration 177, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:52:44] {2391} INFO -  at 158.7s,\testimator xgb_limitdepth's best error=57.9550,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:44] {2218} INFO - iteration 178, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:52:45] {2391} INFO -  at 159.6s,\testimator extra_tree's best error=56.7102,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:52:45] {2218} INFO - iteration 179, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:53:23] {2391} INFO -  at 198.3s,\testimator xgboost's best error=57.4171,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:53:23] {2218} INFO - iteration 180, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:24] {2391} INFO -  at 199.0s,\testimator extra_tree's best error=56.7102,\tbest estimator extra_tree's best error=56.7102\n",
      "[flaml.automl.logger: 11-12 20:53:24] {2218} INFO - iteration 181, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:25] {2391} INFO -  at 199.6s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:25] {2218} INFO - iteration 182, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:25] {2391} INFO -  at 200.1s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:25] {2218} INFO - iteration 183, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:26] {2391} INFO -  at 201.0s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:26] {2218} INFO - iteration 184, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:53:27] {2391} INFO -  at 202.1s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:27] {2218} INFO - iteration 185, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:28] {2391} INFO -  at 202.8s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:28] {2218} INFO - iteration 186, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:29] {2391} INFO -  at 203.5s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:29] {2218} INFO - iteration 187, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:53:32] {2391} INFO -  at 207.2s,\testimator xgboost's best error=57.4171,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:32] {2218} INFO - iteration 188, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:33] {2391} INFO -  at 207.7s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:33] {2218} INFO - iteration 189, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:53:34] {2391} INFO -  at 209.2s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:34] {2218} INFO - iteration 190, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:35] {2391} INFO -  at 209.9s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:35] {2218} INFO - iteration 191, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:36] {2391} INFO -  at 210.5s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:36] {2218} INFO - iteration 192, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:53:45] {2391} INFO -  at 220.2s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:45] {2218} INFO - iteration 193, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:46] {2391} INFO -  at 221.1s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:46] {2218} INFO - iteration 194, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:47] {2391} INFO -  at 221.8s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:47] {2218} INFO - iteration 195, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:53:48] {2391} INFO -  at 222.4s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:53:48] {2218} INFO - iteration 196, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:54:26] {2391} INFO -  at 260.9s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:54:26] {2218} INFO - iteration 197, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:54:27] {2391} INFO -  at 262.0s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:54:27] {2218} INFO - iteration 198, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:28] {2391} INFO -  at 262.7s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:54:28] {2218} INFO - iteration 199, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:28] {2391} INFO -  at 263.3s,\testimator extra_tree's best error=56.6690,\tbest estimator extra_tree's best error=56.6690\n",
      "[flaml.automl.logger: 11-12 20:54:28] {2218} INFO - iteration 200, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:29] {2391} INFO -  at 264.0s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:29] {2218} INFO - iteration 201, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:30] {2391} INFO -  at 264.6s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:30] {2218} INFO - iteration 202, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:54:31] {2391} INFO -  at 266.3s,\testimator rf's best error=57.3571,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:31] {2218} INFO - iteration 203, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:54:37] {2391} INFO -  at 272.1s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:37] {2218} INFO - iteration 204, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:38] {2391} INFO -  at 273.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:38] {2218} INFO - iteration 205, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:39] {2391} INFO -  at 273.6s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:39] {2218} INFO - iteration 206, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:39] {2391} INFO -  at 274.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:39] {2218} INFO - iteration 207, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:40] {2391} INFO -  at 275.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:40] {2218} INFO - iteration 208, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:41] {2391} INFO -  at 276.0s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:41] {2218} INFO - iteration 209, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:42] {2391} INFO -  at 276.6s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:42] {2218} INFO - iteration 210, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:42] {2391} INFO -  at 277.4s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:42] {2218} INFO - iteration 211, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:43] {2391} INFO -  at 278.0s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:43] {2218} INFO - iteration 212, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:44] {2391} INFO -  at 278.5s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:44] {2218} INFO - iteration 213, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:45] {2391} INFO -  at 279.5s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:45] {2218} INFO - iteration 214, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:45] {2391} INFO -  at 280.0s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:45] {2218} INFO - iteration 215, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:46] {2391} INFO -  at 281.0s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:46] {2218} INFO - iteration 216, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:47] {2391} INFO -  at 281.9s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:47] {2218} INFO - iteration 217, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:54:48] {2391} INFO -  at 282.5s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:54:48] {2218} INFO - iteration 218, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:55:05] {2391} INFO -  at 299.7s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:05] {2218} INFO - iteration 219, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:55:08] {2391} INFO -  at 302.8s,\testimator catboost's best error=57.2765,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:08] {2218} INFO - iteration 220, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:55:10] {2391} INFO -  at 305.1s,\testimator catboost's best error=57.2765,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:10] {2218} INFO - iteration 221, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:11] {2391} INFO -  at 305.7s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:11] {2218} INFO - iteration 222, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:55:12] {2391} INFO -  at 306.9s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:12] {2218} INFO - iteration 223, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:13] {2391} INFO -  at 307.7s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:13] {2218} INFO - iteration 224, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:13] {2391} INFO -  at 308.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:13] {2218} INFO - iteration 225, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:55:15] {2391} INFO -  at 309.6s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:15] {2218} INFO - iteration 226, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:55:21] {2391} INFO -  at 316.2s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:21] {2218} INFO - iteration 227, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:22] {2391} INFO -  at 316.9s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:22] {2218} INFO - iteration 228, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:55:23] {2391} INFO -  at 317.9s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:23] {2218} INFO - iteration 229, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:24] {2391} INFO -  at 318.6s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:24] {2218} INFO - iteration 230, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:24] {2391} INFO -  at 319.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:24] {2218} INFO - iteration 231, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:25] {2391} INFO -  at 320.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:25] {2218} INFO - iteration 232, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:26] {2391} INFO -  at 320.8s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:26] {2218} INFO - iteration 233, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:27] {2391} INFO -  at 321.7s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:27] {2218} INFO - iteration 234, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:27] {2391} INFO -  at 322.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:27] {2218} INFO - iteration 235, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:28] {2391} INFO -  at 322.9s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:28] {2218} INFO - iteration 236, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:29] {2391} INFO -  at 323.7s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:29] {2218} INFO - iteration 237, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:29] {2391} INFO -  at 324.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:29] {2218} INFO - iteration 238, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:30] {2391} INFO -  at 325.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:30] {2218} INFO - iteration 239, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:55:40] {2391} INFO -  at 334.5s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:40] {2218} INFO - iteration 240, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:40] {2391} INFO -  at 335.0s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:40] {2218} INFO - iteration 241, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:41] {2391} INFO -  at 336.0s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:41] {2218} INFO - iteration 242, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:55:41] {2391} INFO -  at 336.1s,\testimator lgbm's best error=58.0886,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:41] {2218} INFO - iteration 243, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:42] {2391} INFO -  at 336.6s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:42] {2218} INFO - iteration 244, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:43] {2391} INFO -  at 337.5s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:43] {2218} INFO - iteration 245, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:55:43] {2391} INFO -  at 338.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:55:43] {2218} INFO - iteration 246, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:56:08] {2391} INFO -  at 363.4s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:08] {2218} INFO - iteration 247, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:09] {2391} INFO -  at 364.0s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:09] {2218} INFO - iteration 248, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:10] {2391} INFO -  at 364.7s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:10] {2218} INFO - iteration 249, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:56:11] {2391} INFO -  at 366.4s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:11] {2218} INFO - iteration 250, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:12] {2391} INFO -  at 367.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:12] {2218} INFO - iteration 251, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:13] {2391} INFO -  at 367.9s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:13] {2218} INFO - iteration 252, current learner rf\n",
      "[flaml.automl.logger: 11-12 20:56:14] {2391} INFO -  at 368.7s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:14] {2218} INFO - iteration 253, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:14] {2391} INFO -  at 369.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:14] {2218} INFO - iteration 254, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:15] {2391} INFO -  at 370.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:15] {2218} INFO - iteration 255, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:16] {2391} INFO -  at 370.8s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:16] {2218} INFO - iteration 256, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 20:56:16] {2391} INFO -  at 371.2s,\testimator lgbm's best error=58.0886,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:16] {2218} INFO - iteration 257, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:56:26] {2391} INFO -  at 381.4s,\testimator xgb_limitdepth's best error=57.9550,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:26] {2218} INFO - iteration 258, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:56:29] {2391} INFO -  at 383.8s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:29] {2218} INFO - iteration 259, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:56:31] {2391} INFO -  at 386.3s,\testimator xgb_limitdepth's best error=57.3860,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:31] {2218} INFO - iteration 260, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:32] {2391} INFO -  at 387.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:32] {2218} INFO - iteration 261, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:56:37] {2391} INFO -  at 391.8s,\testimator xgb_limitdepth's best error=57.3860,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:37] {2218} INFO - iteration 262, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:38] {2391} INFO -  at 392.5s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:38] {2218} INFO - iteration 263, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:38] {2391} INFO -  at 393.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:38] {2218} INFO - iteration 264, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:56:47] {2391} INFO -  at 402.0s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:47] {2218} INFO - iteration 265, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:48] {2391} INFO -  at 402.8s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:48] {2218} INFO - iteration 266, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:56:48] {2391} INFO -  at 403.4s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:56:48] {2218} INFO - iteration 267, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:57:00] {2391} INFO -  at 414.8s,\testimator xgb_limitdepth's best error=56.6869,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:57:00] {2218} INFO - iteration 268, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:57:02] {2391} INFO -  at 417.3s,\testimator xgb_limitdepth's best error=56.6869,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:57:02] {2218} INFO - iteration 269, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:57:13] {2391} INFO -  at 428.3s,\testimator xgb_limitdepth's best error=56.6869,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:57:13] {2218} INFO - iteration 270, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:57:24] {2391} INFO -  at 439.2s,\testimator xgb_limitdepth's best error=56.6869,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:57:24] {2218} INFO - iteration 271, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:57:25] {2391} INFO -  at 439.9s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:57:25] {2218} INFO - iteration 272, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:57:47] {2391} INFO -  at 461.7s,\testimator xgb_limitdepth's best error=56.6869,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:57:47] {2218} INFO - iteration 273, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:57:47] {2391} INFO -  at 462.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:57:47] {2218} INFO - iteration 274, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:57:48] {2391} INFO -  at 463.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:57:48] {2218} INFO - iteration 275, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:57:49] {2391} INFO -  at 463.9s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:57:49] {2218} INFO - iteration 276, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:57:50] {2391} INFO -  at 464.6s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:57:50] {2218} INFO - iteration 277, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 20:58:08] {2391} INFO -  at 482.5s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:58:08] {2218} INFO - iteration 278, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:58:09] {2391} INFO -  at 483.8s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:58:09] {2218} INFO - iteration 279, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:58:09] {2391} INFO -  at 484.4s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:58:09] {2218} INFO - iteration 280, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:58:16] {2391} INFO -  at 490.7s,\testimator xgb_limitdepth's best error=56.6869,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:58:16] {2218} INFO - iteration 281, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:58:17] {2391} INFO -  at 491.9s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:58:17] {2218} INFO - iteration 282, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:58:23] {2391} INFO -  at 498.3s,\testimator catboost's best error=57.2765,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:58:23] {2218} INFO - iteration 283, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:58:24] {2391} INFO -  at 499.0s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:58:24] {2218} INFO - iteration 284, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:58:25] {2391} INFO -  at 499.9s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:58:25] {2218} INFO - iteration 285, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:58:41] {2391} INFO -  at 515.6s,\testimator xgb_limitdepth's best error=56.6147,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:58:41] {2218} INFO - iteration 286, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:58:57] {2391} INFO -  at 531.9s,\testimator xgb_limitdepth's best error=56.6147,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:58:57] {2218} INFO - iteration 287, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 20:59:49] {2391} INFO -  at 584.3s,\testimator xgb_limitdepth's best error=56.6147,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:59:49] {2218} INFO - iteration 288, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 20:59:50] {2391} INFO -  at 585.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:59:50] {2218} INFO - iteration 289, current learner catboost\n",
      "[flaml.automl.logger: 11-12 20:59:57] {2391} INFO -  at 591.6s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 20:59:57] {2218} INFO - iteration 290, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:00:00] {2391} INFO -  at 594.9s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:00:00] {2218} INFO - iteration 291, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:00:01] {2391} INFO -  at 595.7s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:00:01] {2218} INFO - iteration 292, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 21:00:49] {2391} INFO -  at 644.4s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:00:49] {2218} INFO - iteration 293, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:00:51] {2391} INFO -  at 645.5s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:00:51] {2218} INFO - iteration 294, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:00:51] {2391} INFO -  at 646.2s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:00:51] {2218} INFO - iteration 295, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:00:52] {2391} INFO -  at 647.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:00:52] {2218} INFO - iteration 296, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 21:00:56] {2391} INFO -  at 651.2s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:00:56] {2218} INFO - iteration 297, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:00:57] {2391} INFO -  at 652.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:00:57] {2218} INFO - iteration 298, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:00:58] {2391} INFO -  at 652.9s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:00:58] {2218} INFO - iteration 299, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 21:01:13] {2391} INFO -  at 668.1s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:13] {2218} INFO - iteration 300, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:01:17] {2391} INFO -  at 672.1s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:17] {2218} INFO - iteration 301, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:01:18] {2391} INFO -  at 673.1s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:18] {2218} INFO - iteration 302, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:01:22] {2391} INFO -  at 676.9s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:22] {2218} INFO - iteration 303, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:01:23] {2391} INFO -  at 678.3s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:23] {2218} INFO - iteration 304, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 21:01:28] {2391} INFO -  at 682.7s,\testimator xgb_limitdepth's best error=56.6147,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:28] {2218} INFO - iteration 305, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:01:29] {2391} INFO -  at 683.7s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:29] {2218} INFO - iteration 306, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:01:30] {2391} INFO -  at 684.4s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:30] {2218} INFO - iteration 307, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:01:31] {2391} INFO -  at 685.4s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:31] {2218} INFO - iteration 308, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:01:31] {2391} INFO -  at 686.3s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:31] {2218} INFO - iteration 309, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:01:32] {2391} INFO -  at 687.1s,\testimator extra_tree's best error=56.5437,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:32] {2218} INFO - iteration 310, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:01:34] {2391} INFO -  at 688.6s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:34] {2218} INFO - iteration 311, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 21:01:39] {2391} INFO -  at 693.9s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:39] {2218} INFO - iteration 312, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:01:42] {2391} INFO -  at 697.1s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:42] {2218} INFO - iteration 313, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:01:43] {2391} INFO -  at 698.1s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.5437\n",
      "[flaml.automl.logger: 11-12 21:01:43] {2218} INFO - iteration 314, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:01:44] {2391} INFO -  at 699.0s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:01:44] {2218} INFO - iteration 315, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:01:48] {2391} INFO -  at 702.5s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:01:48] {2218} INFO - iteration 316, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:01:48] {2391} INFO -  at 703.3s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:01:48] {2218} INFO - iteration 317, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:01:49] {2391} INFO -  at 704.1s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:01:49] {2218} INFO - iteration 318, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:01:52] {2391} INFO -  at 707.2s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:01:52] {2218} INFO - iteration 319, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:01:54] {2391} INFO -  at 708.6s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:01:54] {2218} INFO - iteration 320, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:01:55] {2391} INFO -  at 709.6s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:01:55] {2218} INFO - iteration 321, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:01:56] {2391} INFO -  at 710.6s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:01:56] {2218} INFO - iteration 322, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:01:56] {2391} INFO -  at 711.3s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:01:56] {2218} INFO - iteration 323, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:01:58] {2391} INFO -  at 712.7s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:01:58] {2218} INFO - iteration 324, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:02:03] {2391} INFO -  at 717.9s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:02:03] {2218} INFO - iteration 325, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:02:04] {2391} INFO -  at 719.1s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:02:04] {2218} INFO - iteration 326, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 21:03:09] {2391} INFO -  at 784.0s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:09] {2218} INFO - iteration 327, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:10] {2391} INFO -  at 784.9s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:10] {2218} INFO - iteration 328, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:03:13] {2391} INFO -  at 788.0s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:13] {2218} INFO - iteration 329, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:03:15] {2391} INFO -  at 789.5s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:15] {2218} INFO - iteration 330, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:16] {2391} INFO -  at 790.4s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:16] {2218} INFO - iteration 331, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:17] {2391} INFO -  at 791.6s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:17] {2218} INFO - iteration 332, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:03:18] {2391} INFO -  at 792.7s,\testimator rf's best error=57.0367,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:18] {2218} INFO - iteration 333, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:18] {2391} INFO -  at 793.4s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:18] {2218} INFO - iteration 334, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:19] {2391} INFO -  at 794.3s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:19] {2218} INFO - iteration 335, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:20] {2391} INFO -  at 795.2s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:20] {2218} INFO - iteration 336, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:03:22] {2391} INFO -  at 796.6s,\testimator rf's best error=56.9373,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:22] {2218} INFO - iteration 337, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:23] {2391} INFO -  at 797.6s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:23] {2218} INFO - iteration 338, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:03:26] {2391} INFO -  at 801.2s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:26] {2218} INFO - iteration 339, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:27] {2391} INFO -  at 802.1s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:27] {2218} INFO - iteration 340, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:28] {2391} INFO -  at 803.2s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:28] {2218} INFO - iteration 341, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:03:29] {2391} INFO -  at 803.9s,\testimator lgbm's best error=57.5178,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:29] {2218} INFO - iteration 342, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:03:29] {2391} INFO -  at 804.2s,\testimator lgbm's best error=57.5178,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:29] {2218} INFO - iteration 343, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:30] {2391} INFO -  at 805.0s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:30] {2218} INFO - iteration 344, current learner xgboost\n",
      "[flaml.automl.logger: 11-12 21:03:33] {2391} INFO -  at 808.1s,\testimator xgboost's best error=56.7051,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:33] {2218} INFO - iteration 345, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:03:36] {2391} INFO -  at 810.5s,\testimator lgbm's best error=57.5178,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:36] {2218} INFO - iteration 346, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:36] {2391} INFO -  at 811.3s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:36] {2218} INFO - iteration 347, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:37] {2391} INFO -  at 812.3s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:37] {2218} INFO - iteration 348, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:38] {2391} INFO -  at 813.2s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:38] {2218} INFO - iteration 349, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:39] {2391} INFO -  at 814.2s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:39] {2218} INFO - iteration 350, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:03:40] {2391} INFO -  at 814.4s,\testimator lgbm's best error=57.5178,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:40] {2218} INFO - iteration 351, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:03:41] {2391} INFO -  at 815.6s,\testimator rf's best error=56.9373,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:41] {2218} INFO - iteration 352, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:03:47] {2391} INFO -  at 821.5s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:47] {2218} INFO - iteration 353, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:03:51] {2391} INFO -  at 826.3s,\testimator lgbm's best error=57.5178,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:51] {2218} INFO - iteration 354, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:52] {2391} INFO -  at 827.2s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:52] {2218} INFO - iteration 355, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:03:53] {2391} INFO -  at 827.4s,\testimator lgbm's best error=57.5178,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:53] {2218} INFO - iteration 356, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:53] {2391} INFO -  at 828.3s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:53] {2218} INFO - iteration 357, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:54] {2391} INFO -  at 829.0s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:54] {2218} INFO - iteration 358, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:03:57] {2391} INFO -  at 832.1s,\testimator lgbm's best error=57.5178,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:57] {2218} INFO - iteration 359, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:03:58] {2391} INFO -  at 832.7s,\testimator lgbm's best error=57.5178,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:58] {2218} INFO - iteration 360, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:03:59] {2391} INFO -  at 833.8s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:03:59] {2218} INFO - iteration 361, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:04:00] {2391} INFO -  at 834.5s,\testimator lgbm's best error=57.5178,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:04:00] {2218} INFO - iteration 362, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:04:01] {2391} INFO -  at 835.5s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:04:01] {2218} INFO - iteration 363, current learner rf\n",
      "[flaml.automl.logger: 11-12 21:04:02] {2391} INFO -  at 837.0s,\testimator rf's best error=56.9373,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:04:02] {2218} INFO - iteration 364, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:04:03] {2391} INFO -  at 837.8s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:04:03] {2218} INFO - iteration 365, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 21:04:06] {2391} INFO -  at 840.5s,\testimator xgb_limitdepth's best error=56.6147,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:04:06] {2218} INFO - iteration 366, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:04:07] {2391} INFO -  at 841.4s,\testimator lgbm's best error=57.5178,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:04:07] {2218} INFO - iteration 367, current learner lgbm\n",
      "[flaml.automl.logger: 11-12 21:04:08] {2391} INFO -  at 843.1s,\testimator lgbm's best error=57.1190,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:04:08] {2218} INFO - iteration 368, current learner extra_tree\n",
      "[flaml.automl.logger: 11-12 21:04:09] {2391} INFO -  at 844.3s,\testimator extra_tree's best error=56.4628,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:04:09] {2218} INFO - iteration 369, current learner catboost\n",
      "[flaml.automl.logger: 11-12 21:04:14] {2391} INFO -  at 848.9s,\testimator catboost's best error=57.0255,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:04:14] {2218} INFO - iteration 370, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 11-12 21:05:05] {2391} INFO -  at 899.7s,\testimator xgb_limitdepth's best error=56.6147,\tbest estimator extra_tree's best error=56.4628\n",
      "[flaml.automl.logger: 11-12 21:05:05] {2493} INFO - selected model: ExtraTreesRegressor(max_features=0.8963598169194746, max_leaf_nodes=286,\n",
      "                    n_estimators=41, n_jobs=-1, random_state=12032022)\n",
      "[flaml.automl.logger: 11-12 21:05:05] {1930} INFO - fit succeeded\n",
      "[flaml.automl.logger: 11-12 21:05:05] {1931} INFO - Time taken to find the best model: 699.0210132598877\n",
      "[flaml.automl.logger: 11-12 21:05:05] {1941} WARNING - Time taken to find the best model is 78% of the provided time budget and not all estimators' hyperparameter search converged. Consider increasing the time budget.\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "\n",
    "FLAML_TIME_BUDGET_A = 30*60\n",
    "FLAML_TIME_BUDGET_B_C = 15*60\n",
    "\n",
    "def trainFlamAutoML(letter, preprocessor, time_budget=60):\n",
    "    X, y = pre.general_read_flaml(letter)\n",
    "    X = pre.concatenate_dfs(X)\n",
    "    X_train, y_train,X_test, y_test = pre.train_test_split_may_june_july(X,y,letter)\n",
    "    X_train = preprocessor.transform(X_train)\n",
    "    X_test = preprocessor.transform(X_test)\n",
    "    y_train = y_train[\"target\"]\n",
    "    y_test = y_test[\"target\"]\n",
    "    automl = AutoML()\n",
    "\n",
    "    automl_settings = {\n",
    "        \"time_budget\": time_budget,  # in seconds\n",
    "        \"metric\": 'mae',\n",
    "        \"task\": 'regression',\n",
    "        \"log_file_name\": f\"flaml_{letter}.log\",\n",
    "        \"seed\": RANDOM_STATE\n",
    "    }\n",
    "\n",
    "    automl.fit(X_train=X_train, y_train=y_train, X_val=X_test, y_val=y_test, **automl_settings)\n",
    "    return automl\n",
    "\n",
    "PREPROCESSORS = [\"quarters\"]\n",
    "\n",
    "for preprocessor in PREPROCESSORS:\n",
    "    flaml_preprocessor = pre.choose_transformer(preprocessor)\n",
    "    flaml_A = trainFlamAutoML(\"A\", preprocessor=flaml_preprocessor, time_budget=FLAML_TIME_BUDGET_A)\n",
    "    flaml_B = trainFlamAutoML(\"B\", preprocessor=flaml_preprocessor, time_budget=FLAML_TIME_BUDGET_B_C)\n",
    "    flaml_C = trainFlamAutoML(\"C\", preprocessor=flaml_preprocessor, time_budget=FLAML_TIME_BUDGET_B_C)\n",
    "    \n",
    "post.makePredictionWithModelAndPreprocessor(flaml_A,flaml_B,flaml_C,flaml_preprocessor,f\"{FOLDER_NAME}/flaml_{preprocessor}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jallastacking the csvfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataframes = {}\n",
    "for filename in os.listdir(FOLDER_NAME):\n",
    "    if filename.endswith('.csv'):  # Check if the file is a CSV\n",
    "        file_path = os.path.join(FOLDER_NAME, filename)\n",
    "        dataframe_name = filename.split('.')[0]  # Get the name of the file without the extension\n",
    "        dataframes[dataframe_name] = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "\n",
    "data2 = dataframes[\"DNN\"][\"prediction\"]*0.5 + dataframes[\"flaml_quarters\"][\"prediction\"]*0.5\n",
    "data2 = pd.DataFrame(data2, columns = [\"prediction\"])\n",
    "data2.index.name = \"id\"\n",
    "data2.to_csv(\"Short_notebook_2_submit.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
